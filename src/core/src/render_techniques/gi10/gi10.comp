/**********************************************************************
Copyright (c) 2024 Advanced Micro Devices, Inc. All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
********************************************************************/

#ifndef USE_INLINE_RT
#define USE_INLINE_RT 1
#endif

#include "gi10_shared.h"

//!
//! GI-1.0 shader bindings.
//!

float3 g_Eye;
float2 g_NearFar;
uint   g_GroupSize;
uint   g_FrameIndex;
float4 g_InvDeviceZ;
float3 g_PreviousEye;
int2   g_BlurDirection;
uint2  g_BufferDimensions;
uint   g_UseDirectLighting;
float3 g_PreViewTranslation;
float  g_Exposure;

Texture2D g_DepthBuffer;
Texture2D g_GeometryNormalBuffer;
Texture2D g_ShadingNormalBuffer;
Texture2D g_VelocityBuffer;
Texture2D g_RoughnessBuffer;
Texture2D g_OcclusionAndBentNormalBuffer;
Texture2D g_NearFieldGlobalIlluminationBuffer;
Texture2D g_VisibilityBuffer;
Texture2D g_PreviousDepthBuffer;
Texture2D g_PreviousNormalBuffer;
Texture2D g_PreviousDetailsBuffer;
Texture2D g_PreviousRoughnessBuffer;

StructuredBuffer<uint> g_CountBuffer;

StructuredBuffer<uint>     g_IndexBuffer;
StructuredBuffer<Vertex>   g_VertexBuffer;
StructuredBuffer<Mesh>     g_MeshBuffer;
StructuredBuffer<Instance> g_InstanceBuffer;
StructuredBuffer<Material> g_MaterialBuffer;
StructuredBuffer<float3x4> g_TransformBuffer;

RWTexture2D<float4>                     g_IrradianceBuffer;
RWTexture2D<float4>                     g_ReflectionBuffer;
Texture2D                               g_PreviousReflectionBuffer;
RWStructuredBuffer<uint4>               g_DrawCommandBuffer;
RWStructuredBuffer<DispatchCommand>     g_DispatchCommandBuffer;
RWStructuredBuffer<DispatchRaysCommand> g_DispatchRaysCommandBuffer;
RWTexture2D<float4>                     g_GlobalIlluminationBuffer;
Texture2D                               g_PrevCombinedIlluminationBuffer;

RaytracingAccelerationStructure g_Scene;

TextureCube g_EnvironmentBuffer;
TextureCube g_PrefilteredEnvironmentBuffer;
Texture2D   g_TextureMaps[] : register(space99);

SamplerState g_NearestSampler;
SamplerState g_TextureSampler; // Is a linear sampler

ConstantBuffer<GI10Constants>              g_GI10Constants;
ConstantBuffer<ScreenProbesConstants>      g_ScreenProbesConstants;
ConstantBuffer<HashGridCacheConstants>     g_HashGridCacheConstants;
ConstantBuffer<WorldSpaceReSTIRConstants>  g_WorldSpaceReSTIRConstants;
ConstantBuffer<GlossyReflectionsConstants> g_GlossyReflectionsConstants;
ConstantBuffer<GlossyReflectionsAtrousConstants> g_GlossyReflectionsAtrousConstants;

#define g_ViewProjection                g_GI10Constants.view_proj
#define g_PreviousViewProjection        g_GI10Constants.view_proj_prev
#define g_ViewProjectionInverse         g_GI10Constants.view_proj_inv
#define g_PreviousViewProjectionInverse g_GI10Constants.view_proj_inv_prev
#define g_Reprojection                  g_GI10Constants.reprojection

//!
//! GI-1.0 shader includes.
//!

#include "../../components/light_sampler_grid_stream/light_sampler_grid_stream.hlsl"
#include "../../components/blue_noise_sampler/blue_noise_sampler.hlsl"
#include "../../geometry/intersection.hlsl"
#include "../../geometry/geometry.hlsl"
#include "../../geometry/mesh.hlsl"
#include "../../lights/lights.hlsl"
#include "../../materials/materials.hlsl"
#include "../../materials/material_sampling.hlsl"
#include "../../math/color.hlsl"
#include "../../math/hash.hlsl"
#include "../../math/spherical_harmonics.hlsl"
#include "../../math/pack.hlsl"
#include "../../math/random.hlsl"

#include "gi10.hlsl"
#include "screen_probes.hlsl"
#include "hash_grid_cache.hlsl"
#include "world_space_restir.hlsl"
#include "glossy_reflections.hlsl"
#include "gi_denoiser.hlsl"

#define MAX_HIT_DISTANCE 1e9f

struct PopulateScreenProbesPayload
{
    uint2 seed;
    float3 sky_sample;
    float hit_dist;
};

struct PopulateCellsPayload
{
    uint      query_index;
    float3    world;
    float3    normal;
    float3    lighting;
    Reservoir reservoir;
};

struct TraceReflectionsPayload
{
    int2   full_pos;
    float3 radiance;
    float2 s;
    float  hit_distance;
};

//!
//! GI-1.0 kernels.
//!

[numthreads(1, 1, 1)]
void ClearCounters()
{
    g_Reservoir_HashListCountBuffer[0] = 0; // reset counters

    g_ScreenProbes_EmptyTileCountBuffer[0]                  = 0;
    g_ScreenProbes_OverrideTileCountBuffer[0]               = 0;
    g_ScreenProbes_ProbeCachedTileLRUCountBuffer[0]         = 0;
    g_ScreenProbes_ProbeCachedTileMRUCountBuffer[0]         = 0;
    g_ScreenProbes_ProbeCachedTileListElementCountBuffer[0] = 0;

    g_HashGridCache_PackedTileCountBuffer[0]    = 0;
    g_HashGridCache_UpdateTileCountBuffer[0]    = 0;
    g_HashGridCache_VisibilityCountBuffer[0]    = 0;
    g_HashGridCache_VisibilityRayCountBuffer[0] = 0;

    g_GlossyReflections_RtSampleCountBuffer[0] = 0;
}

[numthreads(1, 1, 1)]
void GenerateDraw()
{
    uint num_cells_per_tile_mip_debug[4] = {
        g_HashGridCacheConstants.num_cells_per_tile_mip0,
        g_HashGridCacheConstants.num_cells_per_tile_mip1,
        g_HashGridCacheConstants.num_cells_per_tile_mip2,
        g_HashGridCacheConstants.num_cells_per_tile_mip3
    };

    // If propagate is true, we display smaller cells with bigger cells values
    uint debug_mip_level = g_HashGridCacheConstants.debug_propagate != 0 ? 0 : g_HashGridCacheConstants.debug_mip_level;

    uint4 draw_command;
    draw_command.x = 6 * num_cells_per_tile_mip_debug[debug_mip_level] * g_HashGridCache_PackedTileCountBuffer[0];
    draw_command.y = 1;
    draw_command.z = 0;
    draw_command.w = 0;
    g_DrawCommandBuffer[0] = draw_command;
}

[numthreads(1, 1, 1)]
void GenerateDispatch()
{
    DispatchCommand dispatch_command;
    dispatch_command.num_groups_x = (g_CountBuffer[0] + g_GroupSize - 1) / g_GroupSize;
    dispatch_command.num_groups_y = 1;
    dispatch_command.num_groups_z = 1;
    dispatch_command.padding = 0;
    g_DispatchCommandBuffer[0] = dispatch_command;
}

[numthreads(1, 1, 1)]
void GenerateDispatchRays()
{
    DispatchRaysCommand dispatch_rays_command;
    dispatch_rays_command.ray_generation_shader_record = g_GI10Constants.ray_generation_shader_record;
    dispatch_rays_command.miss_shader_table = g_GI10Constants.miss_shader_table;
    dispatch_rays_command.hit_group_table = g_GI10Constants.hit_group_table;
    dispatch_rays_command.callable_shader_table = g_GI10Constants.callable_shader_table;
    dispatch_rays_command.width = g_CountBuffer[0];
    dispatch_rays_command.height = 1;
    dispatch_rays_command.depth = 1;
    dispatch_rays_command.padding[0] = 0;
    dispatch_rays_command.padding[1] = 0;
    dispatch_rays_command.padding[2] = 0;
    g_DispatchRaysCommandBuffer[0] = dispatch_rays_command;
}

//!
//! Screen probes kernels.
//!

[numthreads(8, 8, 1)]
void ClearProbeMask(in uint2 did : SV_DispatchThreadID)
{
    g_ScreenProbes_ProbeMaskBuffer[did] = kGI10_InvalidId;
}
// DEV_NOTE: Slide 24
// DEV_NOTE: uint32_t const num_groups_x = (GFX_MAX(probe_count[0] >> i, 1u) + num_threads[0] - 1) / num_threads[0];
// DEV_NOTE: uint32_t const num_groups_y = (GFX_MAX(probe_count[1] >> i, 1u) + num_threads[1] - 1) / num_threads[1];
[numthreads(8, 8, 1)]
void FilterProbeMask(in uint2 did : SV_DispatchThreadID)
{
    uint2 dims;
    g_ScreenProbes_InProbeMaskBuffer.GetDimensions(dims.x, dims.y);

    if (any((did << 1) >= dims))
    {
        return; // out of bounds
    }

    uint probe_mask = kGI10_InvalidId;

    // Here, we look for a valid probe in the 2x2 region from the upper mip in
    // order to populate the lower mips with as many valid probes as possible.
    // DEV_NOTE: takes the 1st valid probe (no randomization)
    for (uint y = 0; y < 2; ++y)
    {
        for (uint x = 0; x < 2; ++x)
        {
            uint2 pos = (did << 1) + uint2(x, y);

            probe_mask = (all(pos < dims) ? g_ScreenProbes_InProbeMaskBuffer[pos] : kGI10_InvalidId);

            if (probe_mask != kGI10_InvalidId)
            {
                break;
            }
        }

        if (probe_mask != kGI10_InvalidId)
        {
            break;
        }
    }

    g_ScreenProbes_OutProbeMaskBuffer[did] = probe_mask;
}

// Slide 26 (Persistent LRU side cache)
[numthreads(64, 1, 1)]
void InitCachedTileLRU(in uint did : SV_DispatchThreadID)
{
    g_ScreenProbes_ProbeCachedTileLRUBuffer[did] = (did | 0x80000000u); // DEV_NOTE: 0x80000000u means "invalid data"
}

// DEV_NOTE: Slide 15
[numthreads(8, 8, 1)]
void ReprojectScreenProbes(in uint2 did : SV_DispatchThreadID, in uint2 group_id : SV_GroupID, in uint2 local_id : SV_GroupThreadID, in uint linear_idx_in_group /*local_index*/ : SV_GroupIndex)
{
    float  depth        = g_DepthBuffer.Load(int3(did, 0)).x;
    float3 normal       = (all(did < g_BufferDimensions) ? g_GeometryNormalBuffer.Load(int3(did, 0)).xyz : float3(0.0f, 0.0f, 0.0f));
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    normal = normalize(2.0f * normal - 1.0f);   // decode normal

    float2 uv         = (did + 0.5f) / g_BufferDimensions;
    float3 world_pos  = InverseProject(g_ViewProjectionInverse, uv, depth);

    // DEV_NOTE: cell size increases linearly with distance to eye => seems to be the world size of a probe.
    // screen_probes_constant_data.cell_size = tanf(capsaicin.getCamera().fovY * screen_probes_.probe_size_
    //                                         * GFX_MAX(1.0f / capsaicin.getHeight(), (float)capsaicin.getHeight() / (capsaicin.getWidth() * capsaicin.getWidth())));
    float  cell_size  = distance(g_Eye, world_pos) * g_ScreenProbesConstants.cell_size;

    // DEV_NOTE:
    // gi10.cpp:
    // 
    // buffer_dimensions = 1920x1080
    // 
    // uint32_t const probe_count[] = {
    //      (buffer_dimensions[0] + screen_probes_.probe_size_ - 1) / screen_probes_.probe_size_,
    //      (buffer_dimensions[1] + screen_probes_.probe_size_ - 1) / screen_probes_.probe_size_};
    //
    // 
    //  uint32_t const *num_threads = gfxKernelGetNumThreads(gfx_, reproject_screen_probes_kernel_);
    // 
    // // num_threads = 8x8 (= numthreads of this compute)
    // 
    //  uint32_t const num_groups_x = (probe_count[0] * screen_probes_.probe_size_ + num_threads[0] - 1) / num_threads[0];
    //  uint32_t const num_groups_y = (probe_count[1] * screen_probes_.probe_size_ + num_threads[1] - 1) / num_threads[1];
    //
    // probe_count * screen_probes_.probe_size_ -> number of pixels rounded up to the probe size

    // DEV_NOTE: default probe size = 8
    uint   probe_size = g_ScreenProbesConstants.probe_size;

    // DEV_NOTE: 'cell' refers to a pixel in the hemioctahedral mapping (= a direction on the hemisphere (hemioctahedron))
    uint2 cell          = (local_id % probe_size); // DEV_NOTE: in {0, probe_size-1}x{0, probe_size-1}
    uint  cell_index    = cell.x + cell.y * probe_size; // DEV_NOTE: in {0, probe_size*probe_size-1}

    uint2 probe_block   = (local_id / probe_size); // DEV_NOTE: in {0, ceil(probe_size/8) - 1}^2 => handles the case where the probe_size does not match the thread group size (=8x8)
    uint  probe_segment = probe_block.x + (probe_block.y << 1); // DEV_NOTE: in {0, num_probes_per_thread_group-1}

    if (cell_index == 0)
    {
        // DEV_NOTE: Initialize the "best reprojected probe" score for the thread group (16 bits) | linear index in thread group (16 bits)
        // DEV_NOTE: groupshared uint   lds_ScreenProbes_Reprojection[4];
        lds_ScreenProbes_Reprojection[probe_segment] = ((f32tof16(65504.0f) << 16) | 0xFFFFu);
    }

    // DEV_NOTE: accumulator for radiance values reprojection
    // 4 channels for the radiance values
    //  0: red, 1: green, 2: blue, 3: distance to the closest surface in a given direction
    lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 0] = 0;
    lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 1] = 0;
    lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 2] = 0;
    lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 3] = 0;

    // DEV_NOTE: counter of number of reprojected samples in probe cell
    lds_ScreenProbes_RadianceSampleCounts[linear_idx_in_group] = 0;

    GroupMemoryBarrierWithGroupSync();

    // Try and find the closest matching probe in the previous frame.
    // Each probe is assigned a score and we atomically pick the best candidate
    // out of all the 8x8, i.e., 64, potential positions.
    if (!is_sky_pixel)
    {
        // DEV_NOTE: reproject current pixel
        float2 velocity     = g_VelocityBuffer.Load(int3(did, 0)).xy;
        float2 previous_uv  = uv - velocity;
        int2   previous_pos = int2(previous_uv * g_BufferDimensions);

        if (all(previous_pos >= 0) && all(previous_pos < int2(g_BufferDimensions))) // DEV_NOTE: check if inside frame
        {
            uint probe_mask = g_ScreenProbes_PreviousProbeMaskBuffer[previous_pos / probe_size]; // DEV_NOTE: check if there was a valid probe there

            if (probe_mask != kGI10_InvalidId)
            {
                // DEV_NOTE: the probe_mask contains either the screen coordinate (2xu16 packed in 1xu32) (in scene resolution) of the probe or kGI10_InvalidId (=0xFFFFFFFFu)
                float2 probe_uv     = (ScreenProbes_UnpackSeed(probe_mask) + 0.5f) / g_BufferDimensions;
                float  probe_depth  = g_PreviousDepthBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).x;
                float3 probe_normal = normalize(2.0f * g_PreviousNormalBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).xyz - 1.0f);
                float3 probe_pos    = InverseProject(g_PreviousViewProjectionInverse, probe_uv, probe_depth);

                // DEV_NOTE: check that the distance to the probe plane is smaller than a cell size and
                //           that the normal of the current pixel does not deviate too much compared to the probe normal
                if (abs(dot(probe_pos - world_pos, normal)) < cell_size && dot(normal, probe_normal) > 0.95f)
                {
                    // DEV_NOTE: probe score is normalized distance to probe
                    uint probe_score = ((f32tof16(distance(probe_pos, world_pos) / cell_size) << 16) | linear_idx_in_group);

                    InterlockedMin(lds_ScreenProbes_Reprojection[probe_segment], probe_score);
                }
            }
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // Now we map each lane to a cell in the probe and re-use the radiance values temporally
    // DEV_NOTE: retrieve the linear thread id of the "best reprojected probe"
    uint  local_lane = (lds_ScreenProbes_Reprojection[probe_segment] & 0xFFFFu);

    // DEV_NOTE: the << 3 corresponds to the group size of 8 (<< 3 <=> * 8)
    // DEV_NOTE: the  & 7 corresponds to the group size of 8 ( & 7 <=> % 8)
    // DEV_NOTE: the >> 3 corresponds to the group size of 8 (>> 3 <=> / 8)
    // DEV_NOTE: 'seed' is the pixel coords (in scene resolution) of the thread that output the "best reprojected probe" in shared mem
    //           <=> pixel coords of the "surface with the best reprojection score"
    uint2 seed       = (group_id << 3) + uint2(local_lane & 7, local_lane >> 3);

    uv = (seed + 0.5f) / g_BufferDimensions;    // center on seed

    // DEV_NOTE: compute the previous world position of the "surface with the best reprojection score"
    float2 velocity     = g_VelocityBuffer.Load(int3(seed, 0)).xy;
    float2 previous_uv  = uv - velocity;
    uint2  previous_pos = uint2(previous_uv * g_BufferDimensions);

    uint probe_mask = g_ScreenProbes_PreviousProbeMaskBuffer[previous_pos / probe_size];

    if (local_lane != 0xFFFFu) // DEV_NOTE: if we found a "best reprojected probe"
    {
        // DEV_NOTE: current depth of the "surface with the best reprojection score"
        depth     = g_DepthBuffer.Load(int3(seed, 0)).x;

        // DEV_NOTE: current normal of the "surface with the best reprojection score"
        normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);

        // DEV_NOTE: current world position of the "surface with the best reprojection score"
        world_pos = InverseProject(g_ViewProjectionInverse, uv, depth);

        // DEV_NOTE: previous screen uv of the "best reprojected probe"
        float2 probe_uv    = (ScreenProbes_UnpackSeed(probe_mask) + 0.5f) / g_BufferDimensions;

        // DEV_NOTE: previous depth of the "best reprojected probe"
        float  probe_depth = g_PreviousDepthBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).x;

        // DEV_NOTE: (previous) world position of the "best reprojected probe"
        float3 probe_pos   = InverseProject(g_PreviousViewProjectionInverse, probe_uv, probe_depth);

        // DEV_NOTE: (previous) world space normal of the "best reprojected probe"
        float3 probe_normal    = normalize(2.0f * g_PreviousNormalBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).xyz - 1.0f);

        // DEV_NOTE: previous frame radiance of the "best reprojected probe" in the given direction
        // .xyz: radiance, .w = distance to the closest surface in the given direction
        float4 probe_radiance  = g_ScreenProbes_PreviousProbeBuffer[((ScreenProbes_UnpackSeed(probe_mask) / g_ScreenProbesConstants.probe_size) * g_ScreenProbesConstants.probe_size) + cell];

        // DEV_NOTE: each thread in the group maps to a hemioctahedron direction ('cell')
        float3 probe_direction = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);

        // DEV_NOTE: hemioctahedron space -> world space
        float3 b1, b2;
        GetOrthoVectors(probe_normal, b1, b2);
        probe_direction = probe_direction.x * b1 + probe_direction.y * b2 + probe_direction.z * probe_normal;

        // DEV_NOTE: parallax correction
        // probe_radiance.w stores the distance to the closest surface in a given direction
        //  -> 'hit_point' is the position of the closest surface in the given probe direction
        float3 hit_point       = probe_pos + probe_direction * probe_radiance.w;
        float3 reprojected_dir = hit_point - world_pos; // DEV_NOTE: compute direction to the hit point from the current world position of the "surface with the best reprojection score"
        float  reprojected_len = length(reprojected_dir);

        reprojected_dir /= reprojected_len; // normalize

        if (dot(normal, reprojected_dir) > 0.0f) // DEV_NOTE: check that the parallax corrected direction is in the surface positive hemisphere
        {
            // DEV_NOTE: compute the cell in the reprojected probe corresponding to the direction from the
            //           current world position of the "surface with the best reprojection score" to the probe hit point
            float3 tangent_space_dir = mul(reprojected_dir, CreateTBN(normal));
            float2 remap_uv         = mapToHemiOctahedron(tangent_space_dir);
            uint2  remap_cell       = uint2(remap_uv * g_ScreenProbesConstants.probe_size);
            uint   remap_cell_index = remap_cell.x + remap_cell.y * g_ScreenProbesConstants.probe_size;

            // DEV_NOTE: converts radiance to uint so that it can be atomically blended
            //  -> scale by 10000 and round
            //  --> then it is stored as float16
            //  ===> max value is 65504.0f, so pre-quantization the max is 6.5504f -> NEEDS SERIOUS PRE-EXPOSURE...
            // 
            //  // The amount of float quantization for atomic updates of the probe cells as integer:
            // 
            //  #define kGI10_FloatQuantize  1e4f
            // 
            //  // Quantizes the radiance value so it can be blended atomically.
            //  uint4 ScreenProbes_QuantizeRadiance(in float4 radiance)
            //  {
            //      return uint4(round(kGI10_FloatQuantize * radiance));
            //  }
            //
            //  // Recovers the previously quantized radiance value.
            //  float4 ScreenProbes_RecoverRadiance(in uint4 quantized_radiance)
            //  {
            //      return quantized_radiance / kGI10_FloatQuantize;
            //  }
            uint4  remap_radiance   = ScreenProbes_QuantizeRadiance(float4(probe_radiance.xyz, reprojected_len));

            // DEV_NOTE: atomically accumulate radiance in probe cell since multiple reprojected radiance samples can end up in the same cell
            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 0], remap_radiance.x);
            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 1], remap_radiance.y);
            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 2], remap_radiance.z);
            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 3], remap_radiance.w);
            InterlockedAdd(lds_ScreenProbes_RadianceSampleCounts[remap_cell_index], 1);
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // Calculate the radiance backup value to be used for unvisited cells
    // DEV_NOTE: slide 21
    // > Average the radiance from traced cells (= cells with reprojected values) in LDS and distribute uniformly across the untraced ones
    {
        lds_ScreenProbes_RadianceBackup[linear_idx_in_group] = float4(ScreenProbes_RecoverRadiance(uint3(lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 0],
                                                                                                 lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 1],
                                                                                                 lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 2])),
                                                                                                 lds_ScreenProbes_RadianceSampleCounts[linear_idx_in_group] > 0.0f ? 1.0f : 0.0f);
        GroupMemoryBarrierWithGroupSync();

        // Sized for 8x8 threadgroup
        for (uint stride = 1; stride < 64; stride <<= 1)
        {
            if (linear_idx_in_group < 64 / (2 * stride))
                lds_ScreenProbes_RadianceBackup[2 * (linear_idx_in_group + 1) * stride - 1] += lds_ScreenProbes_RadianceBackup[(2 * linear_idx_in_group + 1) * stride - 1];
            GroupMemoryBarrierWithGroupSync();
        }

        if (linear_idx_in_group == 0)
        {
            float4 total_radiance   = lds_ScreenProbes_RadianceBackup[64 - 1];
            float3 radiance         = total_radiance.xyz / max(total_radiance.w, 1.0f);
            float  empty_cell_count = (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size - total_radiance.w);

            // DEV_NOTE: MAX_HIT_DISTANCE = 1e9f
            lds_ScreenProbes_RadianceBackup[0] = float4(radiance / max(empty_cell_count, 1.0f), MAX_HIT_DISTANCE);
        }
        GroupMemoryBarrierWithGroupSync();
    }

    // No probe found, this is a disocclusion
    if (local_lane == 0xFFFFu)
    {
        if (cell_index == 0)
        {
            uint2 probe  = (did / probe_size);

            if (!is_sky_pixel)
            {
                uint2 jitter = min(CalculateHaltonSequence(g_FrameIndex) * g_ScreenProbesConstants.probe_spawn_tile_size, g_ScreenProbesConstants.probe_spawn_tile_size - 1.0f);

                // Check whether this disoccluded tile won't be filled during the probe spawning pass.
                // If it won't be spawned, we append it to the list of "empty tiles" so the ray distribution can
                // get re-balanced to achieve adaptive sampling.
                // DEV_NOTE: slides 16 and 17
                if (any((jitter / probe_size) != (probe % (g_ScreenProbesConstants.probe_spawn_tile_size / probe_size))))
                {
                    uint empty_tile_index;
                    InterlockedAdd(g_ScreenProbes_EmptyTileCountBuffer[0], 1, empty_tile_index);

                    uint probe_count = (g_BufferDimensions.x + probe_size - 1) / probe_size; // DEV_NOTE: probe_count_x
                    uint probe_index = (probe.x + probe.y * probe_count);

                    g_ScreenProbes_EmptyTileBuffer[empty_tile_index] = probe_index;
                }
            }

            g_ScreenProbes_ProbeMaskBuffer[probe] = kGI10_InvalidId; // DEV_NOTE: mark probe as invalid (but might be filled during "probe patching")
        }

        // DEV_NOTE: cannot leave earlier because all threads must hit the various GroupMemoryBarrierWithGroupSync() calls above
        return; // reprojection failed :'(
    }

    // Reproject the spherical harmonics
    if (cell_index < 9) // DEV_NOTE: only 9 threads in the group will compute reproject each of the SH2 coeff
    {
        uint2 probe          = (did / probe_size);
        uint2 previous_probe = (ScreenProbes_UnpackSeed(probe_mask) / probe_size);

        uint probe_count          = (g_BufferDimensions.x + probe_size - 1) / probe_size;
        uint probe_index          = (probe.x + probe.y * probe_count);
        uint previous_probe_index = (previous_probe.x + previous_probe.y * probe_count);

        if (cell_index == 0)
        {
            g_ScreenProbes_ProbeMaskBuffer[probe] = ScreenProbes_PackSeed(seed); // DEV_NOTE: set current probe mask as valid (pixel coords of the "surface with the best reprojection score")
        }

        g_ScreenProbes_ProbeSHBuffer[9 * probe_index + cell_index] = g_ScreenProbes_PreviousProbeSHBuffer[9 * previous_probe_index + cell_index];
    }

    // And reproject the radiance
    // DEV_NOTE: goes from uint4 to float4
    // 
    //  #define kGI10_FloatQuantize  1e4f
    // 
    //  Recovers the previously quantized radiance value.
    //  float4 ScreenProbes_RecoverRadiance(in uint4 quantized_radiance)
    //  {
    //      return quantized_radiance / kGI10_FloatQuantize;
    //  }
    float4 radiance = ScreenProbes_RecoverRadiance(uint4(lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 0],
                                                         lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 1],
                                                         lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 2],
                                                         lds_ScreenProbes_RadianceValues[(linear_idx_in_group << 2) + 3]));

    uint sample_count = lds_ScreenProbes_RadianceSampleCounts[linear_idx_in_group];

    if (sample_count > 0)
    {
        radiance /= sample_count;
    }
    else
    {
        radiance = lds_ScreenProbes_RadianceBackup[0];
    }

    g_ScreenProbes_ProbeBuffer[did] = radiance;
}

// DEV_NOTE: Slide 26 (Persistent LRU side cache)
/* DEV_NOTE:
    gi10.cpp:
      uint32_t const  num_groups_x =
        (screen_probes_.probe_count_[0] * screen_probes_.probe_count_[1] + num_threads[0] - 1)
        / num_threads[0];
*/
// DEV_NOTE: 1 thread per probe
// DEV_NOTE: iterate over the whole LRU cache and select the probes that are still on screen
[numthreads(64, 1, 1)]
void CountScreenProbes(in uint did : SV_DispatchThreadID)
{
    uint2 dims;
    g_ScreenProbes_ProbeCachedTileIndexBuffer.GetDimensions(dims.x, dims.y);

    if (did >= (dims.x * dims.y))
    {
        return; // out of bounds
    }

    uint cached_tile_index = g_ScreenProbes_ProbeCachedTileLRUBuffer[did];

    if (!((cached_tile_index & 0x80000000u) != 0)) // DEV_NOTE: = if "LRU tile data is valid"
    {
        // DEV_NOTE: retrieve probe from (the "Persistent LRU side") cache (slide 26)

        uint2 cached_probe = uint2(cached_tile_index % dims.x, cached_tile_index / dims.x);

        float3 world_pos   = g_ScreenProbes_ProbeCachedTileIndexBuffer[cached_probe].xyz;
        float3 homogeneous = transformPointProjection(world_pos, g_ViewProjection);
        homogeneous.xy     = 0.5f * float2(homogeneous.x, -homogeneous.y) + 0.5f; // DEV_NOTE: = screen UV

        if (all(homogeneous > 0.0f) && all(homogeneous < 1.0f)) // DEV_NOTE: if on screen
        {
            // DEV_NOTE: select probe based on screen UV
            uint2 probe_count = (g_BufferDimensions + g_ScreenProbesConstants.probe_size - 1) / g_ScreenProbesConstants.probe_size;
            uint2 probe       = uint2(homogeneous.xy * probe_count);
            uint  probe_index = (probe.x + probe.y * probe_count.x); // 

            // DEV_NOTE: add probe to cache

            // DEV_NOTE: increment the counter of "LRU cache entries"
            uint element_index;
            InterlockedAdd(g_ScreenProbes_ProbeCachedTileListElementCountBuffer[0], 1, element_index);

            // DEV_NOTE: increment the counter of "number of probes in LRU cache" for a given probe
            //           => multiple LRU cache entry can refer to the same probe (history longer than 1 frame)
            uint index_in_tile;
            InterlockedAdd(g_ScreenProbes_ProbeCachedTileListCountBuffer[probe_index], 1, index_in_tile);

            // DEV_NOTE: store information about the did (= LRU cache entry index), the probe index and the index in the given tile (for multiple probes refering to the same probe)
            // DEV_NOTE(OPTIM): can probably be packed into less bits
            g_ScreenProbes_ProbeCachedTileListElementBuffer[element_index] = uint4(did, probe_index, index_in_tile, 0);
        }
    }

    // DEV_NOTE: flag used to know if a LRU probe has been treated (evicted, updated) -> see SampleScreenProbes
    // => "clear buffer"
    g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[did] = 1;
}

// DEV_NOTE: Between CountScreenProbes and ScatterScreenProbes, there is a prefix scan sum performed on the valid LRU cache entries

[numthreads(64, 1, 1)]
void ScatterScreenProbes(in uint did : SV_DispatchThreadID)
{
    if (did >= g_ScreenProbes_ProbeCachedTileListElementCountBuffer[0])
    {
        return; // out of bounds
    }

    // DEV_NOTE: list_element.x = did
    //           list_element.y = probe_index
    //           list_element.z = index_in_tile
    uint3 list_element  = g_ScreenProbes_ProbeCachedTileListElementBuffer[did].xyz;
    uint  scatter_index = g_ScreenProbes_ProbeCachedTileListIndexBuffer[list_element.y] + list_element.z;

    g_ScreenProbes_ProbeCachedTileListBuffer[scatter_index] = list_element.x;
}

// Slide 16
[numthreads(64, 1, 1)]
void SpawnScreenProbes(in uint did : SV_DispatchThreadID)
{
    // DEV_NOTE: probe_spawn_tile_size_ = 16 by default
    // DEV_NOTE: compute the max number of probes for X and Y dimension
    uint max_probe_spawn_width  = (g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size;
    uint max_probe_spawn_height = (g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size;

    if (did >= max_probe_spawn_width * max_probe_spawn_height)
    {
        return; // out of bounds
    }

    uint2 probe  = uint2(did % max_probe_spawn_width, did / max_probe_spawn_width); // DEV_NOTE: thread id -> 2D probe index

    // DEV_NOTE: 2D integer jitter in [0, probe_spawn_tile_size-1]
    uint2 jitter = min(CalculateHaltonSequence(g_FrameIndex) * g_ScreenProbesConstants.probe_spawn_tile_size, g_ScreenProbesConstants.probe_spawn_tile_size - 1.0f);

    // DEV_NOTE: 2D pixel coords (in scene resolution) in [0, g_BufferDimensions - 1]
    uint2 seed   = min(probe * g_ScreenProbesConstants.probe_spawn_tile_size + jitter, g_BufferDimensions - 1);

    float3 normal       = g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (!is_sky_pixel) // DEV_NOTE: do not spawn probe on sky
    {
        // DEV_NOTE: export (packed) probe scene pixel coords
        g_ScreenProbes_PreviousProbeSpawnBuffer[did] = ScreenProbes_PackSeed(seed); // DEV_NOTE: (seed.x << 16) | seed.y;
    }
  
    // DEV_NOTE: g_ScreenProbes_PreviousProbeSpawnBuffer seems to not be cleared, g_ScreenProbes_ProbeSpawnScanBuffer tells whether the entry is valid(?)

    g_ScreenProbes_ProbeSpawnScanBuffer[did] = (!is_sky_pixel ? 1 : 0); // DEV_NOTE: mark if a probe has been spawn
}

// Slide 16
[numthreads(64, 1, 1)]
void CompactScreenProbes(in uint did : SV_DispatchThreadID)
{
    uint max_probe_spawn_width  = (g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size;
    uint max_probe_spawn_height = (g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size;

    if (did >= max_probe_spawn_width * max_probe_spawn_height)
    {
        return; // out of bounds
    }

    if (g_ScreenProbes_ProbeSpawnScanBuffer[did] == 0)
    {
        return; // probe was culled
    }

    uint probe_index = g_ScreenProbes_ProbeSpawnIndexBuffer[did]; // DEV_NOTE: compacted probe index buffer
    uint probe_seed  = g_ScreenProbes_PreviousProbeSpawnBuffer[did]; // DEV_NOTE: sparse (i.e non-compacted) probe (packed) pixel coords
    uint probe_mask  = g_ScreenProbes_ProbeMaskBuffer[ScreenProbes_UnpackSeed(probe_seed) / g_ScreenProbesConstants.probe_size]; // DEV_NOTE: Probe mask

    // If we're not filling a hole from the reprojection, we can append this tile to the
    // list of "overridable tile"; that is, this is a valid candidate to be un-spawned in
    // favor of a disoccluded "empty tile" during the patching of the probes.
    if (probe_mask != uint(-1))
    {
        uint override_tile_index;
        InterlockedAdd(g_ScreenProbes_OverrideTileCountBuffer[0], 1, override_tile_index);

        // DEV_NOTE: push "converged probes/tiles" to the overrable probes/tiles queue
        // DEV_NOTE: only written to, not read from... => for debug purpose only? leftover?
        g_ScreenProbes_OverrideTileBuffer[override_tile_index] = probe_index;
    }

    g_ScreenProbes_ProbeSpawnBuffer[probe_index] = probe_seed; // DEV_NOTE: output (packed) probe pixel coords to compacted probe buffer
}

// Slide 16-17
[numthreads(64, 1, 1)]
void PatchScreenProbes(in uint did : SV_DispatchThreadID)
{
    // DEV_NOTE: number of overridable tiles
    uint override_tile_count = g_ScreenProbes_OverrideTileCountBuffer[0];

    if (override_tile_count == 0 || did >= g_ScreenProbes_EmptyTileCountBuffer[0])
    {
        return; // out of bounds
    }

    // DEV_NOTE: number of probes on horizontal axis
    uint probe_count = (g_BufferDimensions.x + g_ScreenProbesConstants.probe_size - 1) / g_ScreenProbesConstants.probe_size;

    // DEV_NOTE: index of the current empty tile/probe
    uint probe_index = g_ScreenProbes_EmptyTileBuffer[did];

    uint2 probe  = uint2(probe_index % probe_count, probe_index / probe_count); // DEV_NOTE: 2D index of the current empty tile/probe
    
    // DEV_NOTE: compute the scene resolution pixel coords of the empty probe (/!\ it seems that the computation must be in-sync with the other shaders)
    uint2 jitter = min(CalculateHaltonSequence(g_FrameIndex) * g_ScreenProbesConstants.probe_size, g_ScreenProbesConstants.probe_size - 1.0f);
    uint2  seed         = min(probe * g_ScreenProbesConstants.probe_size + jitter, g_BufferDimensions - 1);
    
    float3 normal       = g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel)
    {
        return; // sky pixel
    }

    // DEV_NOTE: select a random "valid" probe with an index in [0, override_tile_count-1]
    // DEV_NOTE: why only among the 1st 'override_tile_count' probes?
    Random random = MakeRandom(did, g_FrameIndex);
    /*DEV_CODE*/ uint random_index /*index*/ = random.randInt(override_tile_count);

    // DEV_NOTE: there seems to be missing an indirection
    /*
    *   uint overridable_tile_index = g_ScreenProbes_OverrideTileBuffer[random_index];
    *   uint prev_value;
    *   InterlockedExchange(g_ScreenProbes_ProbeSpawnBuffer[overridable_tile_index], ScreenProbes_PackSeed(seed), prev_value);
    */

    // DEV_NOTE: here it seems that we are also replacing reprojected probes that are used to fill a hole
    // -> see shader 'CompactScreenProbes' comment "If we're not filling a hole from the reprojection, ..."

    // DEV_NOTE: replace a random "valid" probe (its coords) by an empty tile/probe (its coords)
    /* DEV_CODE */ uint prev_value;
    InterlockedExchange(g_ScreenProbes_ProbeSpawnBuffer[/*DEV_CODE*/ random_index /*index*/], ScreenProbes_PackSeed(seed), /*DEV_CODE*/ prev_value /*index*/);
}

// Slide 20: "PARALLAX-CORRECTED RADIANCE REUSE"
// DEV_NOTE: uint32_t const  num_groups_x = (screen_probes_.max_ray_count + num_threads[0] - 1) / num_threads[0];
//           max_ray_count = max_probe_spawn_count * probe_size_ * probe_size_;
// DEV_NOTE(QUESTION): does it evaluates the whole 64 directions? => YES, it seems so
[numthreads(64, 1, 1)]
void SampleScreenProbes(in uint did : SV_DispatchThreadID, in uint local_id : SV_GroupThreadID)
{
    uint max_probe_spawn_count = ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size)
                               * ((g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size);

    uint probe_count           = g_ScreenProbes_ProbeSpawnScanBuffer[max_probe_spawn_count - 1]
                               + g_ScreenProbes_ProbeSpawnIndexBuffer[max_probe_spawn_count - 1];

    // DEV_NOTE: the cell corresponds to the direction in the hemioctahedral
    // uint2 ScreenProbes_GetCellAndProbeIndex(in uint query_index)
    // {
    //     return uint2(query_index % (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size),
    //                  query_index / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size));
    // }
    // DEV_NOTE: a thread group treats a single probe (same probe_index), a thread treats a direction (=cell) in the probe 
    uint2 cell_and_probe_index = ScreenProbes_GetCellAndProbeIndex(did);
    uint  cell_index           = cell_and_probe_index.x;
    uint  probe_index          = cell_and_probe_index.y;

    uint2 cell  = uint2(cell_index % g_ScreenProbesConstants.probe_size, cell_index / g_ScreenProbesConstants.probe_size);

    // DEV_NOTE: probe (packed) 2D (scene) pixel coords
    uint2 seed  = (probe_index < probe_count ? ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]) : uint2(-1, -1));

    // DEV_NOTE: 2D probe coords (in [0, numProbes-1])
    uint2 probe = (seed / g_ScreenProbesConstants.probe_size);

    // DEV_NOTE: probe cell (= direction) 2D index
    uint2 pos   = (probe * g_ScreenProbesConstants.probe_size) + cell;

    float2 uv        = (seed + 0.5f) / g_BufferDimensions;
    float  depth     = g_DepthBuffer.Load(int3(seed, 0)).x;
    float3 normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);
    float3 world_pos = InverseProject(g_ViewProjectionInverse, uv, depth);

    uint  previous_probe_mask = kGI10_InvalidId;

    // DEV_NOTE: cell size seems to be proportional to distance to camera
    float cell_size           = distance(g_Eye, world_pos) * g_ScreenProbesConstants.cell_size;

    // DEV_NOTE: probe buffer resolution
    int2  probe_res           = int2((g_BufferDimensions + g_ScreenProbesConstants.probe_size - 1) / g_ScreenProbesConstants.probe_size);

    uint2 dims;
    g_ScreenProbes_ProbeCachedTileIndexBuffer.GetDimensions(dims.x, dims.y);

    if (local_id == 0)
    {
        lds_ScreenProbes_RadianceReuseSampleCount = 0;
    }

    // DEV_NOTE: groupshared uint lds_ScreenProbes_RadianceValues[4 * 64];
    //           => the 64 here assumes that the hemioctahedron contains 64 (8x8) directions
    //           ==> gi10.h: 'static constexpr uint32_t     probe_size_   = 8;'
    // DEV_NOTE: clear shared memory
    lds_ScreenProbes_RadianceValues[(local_id << 2) + 0] = 0;
    lds_ScreenProbes_RadianceValues[(local_id << 2) + 1] = 0;
    lds_ScreenProbes_RadianceValues[(local_id << 2) + 2] = 0;
    lds_ScreenProbes_RadianceValues[(local_id << 2) + 3] = 0;
    lds_ScreenProbes_RadianceSampleCounts[local_id] = 0;
    GroupMemoryBarrierWithGroupSync();

    // DEV_NOTE: reproject and accumulate the 3x3 neighbours probes into the current (center) probe, sample in a given direction (determined by the variable 'cell')
    //           => some can of blur
    //           => takes into account parallax by reconstructing the hit point of the neighbour probe and recomputing the direction to the hit point from the current (center) probe PoV
    //           ==> Slide 20: "PARALLAX-CORRECTED RADIANCE REUSE"
    if (probe_index < probe_count)
    {
        const int kRadius = 1;

        // DEV_NOTE(OPTIM): it seems that we could skip some computation for (x == 0 && y == 0)
        for (int y = -kRadius; y <= kRadius; ++y)
        {
            for (int x = -kRadius; x <= kRadius; ++x)
            {
                int2 tap = int2(probe) + int2(x, y);

                if (any(tap < 0) || any(tap >= probe_res))
                {
                    continue;   // out of bounds
                }

                // DEV_NOTE: probe mask contains probe pixel coords
                uint probe_mask = g_ScreenProbes_ProbeMaskBuffer[tap];

                if (probe_mask == kGI10_InvalidId)
                {
                    continue;   // invalid probe
                }

                if (x == 0 && y == 0)
                {
                    previous_probe_mask = probe_mask;
                }

                float2 probe_uv    = (ScreenProbes_UnpackSeed(probe_mask) + 0.5f) / g_BufferDimensions;
                float  probe_depth = g_DepthBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).x;

                // DEV_NOTE: world probe position
                float3 probe_pos   = InverseProject(g_ViewProjectionInverse, probe_uv, probe_depth);

                if (abs(dot(probe_pos - world_pos, normal)) > cell_size)
                {
                    continue;   // prevent leaks from faraway probes
                }

                float3 probe_normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(ScreenProbes_UnpackSeed(probe_mask), 0)).xyz - 1.0f);
                float4 probe_radiance  = g_ScreenProbes_ProbeBuffer[((ScreenProbes_UnpackSeed(probe_mask) / g_ScreenProbesConstants.probe_size) * g_ScreenProbesConstants.probe_size) + cell];
                
                // DEV_NOTE: probe-local space direction in hemioctahedron
                float3 probe_direction = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);

                // DEV_NOTE: probe-local -> world space direction
                float3 b1, b2;
                GetOrthoVectors(probe_normal, b1, b2);
                probe_direction = probe_direction.x * b1 + probe_direction.y * b2 + probe_direction.z * probe_normal;

                // DEV_NOTE: probe_radiance.w contains the distance to the closest surface in the given direction
                float3 hit_point       = probe_pos + probe_direction * probe_radiance.w;

                // DEV_NOTE: reproject the sample probe direction onto the current probe
                float3 reprojected_dir = hit_point - world_pos;
                float  reprojected_len = length(reprojected_dir);

                reprojected_dir /= reprojected_len; // normalize

                // DEV_NOTE: check that the reproject direction is contained in the current probe hemisphere
                if (dot(normal, reprojected_dir) < 0.0f)
                {
                    continue;   // oriented hemispheres do not overlap
                }

                // DEV_NOTE: it seems that the only time this is skipped is when '(probe_mask == kGI10_InvalidId)' (see above)
                //           because otherwise we resample the same probe (the current probe) so the other tests (size and hemisphere should pass)
                if (x == 0 && y == 0)
                {
                    InterlockedAdd(lds_ScreenProbes_RadianceReuseSampleCount, 1);
                }

                // DEV_NOTE: 'mul(reprojected_dir, CreateTBN(normal))' => world to tangent space
                float2 remap_uv         = mapToHemiOctahedron(mul(reprojected_dir, CreateTBN(normal)));
                uint2  remap_cell       = uint2(remap_uv * g_ScreenProbesConstants.probe_size);
                uint   remap_cell_index = remap_cell.x + remap_cell.y * g_ScreenProbesConstants.probe_size;

                // DEV_NOTE: converts radiance to uint so that it can be atomically blended
                //  -> scale by 10000 and round
                //  --> then it is stored as float16
                //  ===> max value in 65
                // 
                //  // The amount of float quantization for atomic updates of the probe cells as integer:
                // 
                //  #define kGI10_FloatQuantize  1e4f
                // 
                //  // Quantizes the radiance value so it can be blended atomically.
                //  uint4 ScreenProbes_QuantizeRadiance(in float4 radiance)
                //  {
                //      return uint4(round(kGI10_FloatQuantize * radiance));
                //  }
                //
                //  // Recovers the previously quantized radiance value.
                //  float4 ScreenProbes_RecoverRadiance(in uint4 quantized_radiance)
                //  {
                //      return quantized_radiance / kGI10_FloatQuantize;
                //  }
                uint4  remap_radiance   = ScreenProbes_QuantizeRadiance(float4(probe_radiance.xyz, reprojected_len));

                // DEV_NOTE: accumulate reproject sample radiance onto the LDS screen probe radiance values
                // DEV_NOTE: '<< 2' = '* 4' --> radiance values (+ distance in .w) are stored as v0.xyzw|v1.xyzw|...|v63.xyzw
                InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 0], remap_radiance.x);
                InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 1], remap_radiance.y);
                InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 2], remap_radiance.z);
                InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 3], remap_radiance.w);
                InterlockedAdd(lds_ScreenProbes_RadianceSampleCounts[remap_cell_index], 1); // DEV_NOTE: count the number of samples added for the given cell (=direction)
            }
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // DEV_NOTE(QUESTION): this is always true except when (probe_mask == kGI10_InvalidId) so we always invalidate the previous_probe_mask?
    if (lds_ScreenProbes_RadianceReuseSampleCount > 0)
    {
        previous_probe_mask = kGI10_InvalidId;
    }

    if (probe_index < probe_count)
    {
        // DEV_NOTE(QUESTION): what happens when 'previous_probe_mask = kGI10_InvalidId' (see condition above)?
        // kGI10_InvalidId = 0xFFFFFFFFu and
        // uint2 ScreenProbes_UnpackSeed(in uint packed_seed)
        // {
        //     return uint2(packed_seed >> 16, packed_seed & 0xFFFFu);
        // }
        // so the coords returned are (65535, 65535)
        // so the uv are outside of screen

        // DEV_NOTE: previous_probe_mask either contains the current probe mask (probe_mask) or kGI10_InvalidId
        float2 previous_probe_uv     = (ScreenProbes_UnpackSeed(previous_probe_mask) + 0.5f) / g_BufferDimensions;
        float  previous_probe_depth  = g_DepthBuffer.Load(int3(ScreenProbes_UnpackSeed(previous_probe_mask), 0)).x;
        float3 previous_probe_normal = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(ScreenProbes_UnpackSeed(previous_probe_mask), 0)).xyz - 1.0f);
        float3 previous_probe_pos    = InverseProject(g_ViewProjectionInverse, previous_probe_uv, previous_probe_depth);

        uint evicted_probe_mask = kGI10_InvalidId; // DEV_NOTE: index in LRU cache of the probe to evict
        uint updated_probe_mask = kGI10_InvalidId; // DEV_NOTE: index in LRU cache of the best scoring probe

        float best_evicted_probe_score = cell_size;
        float best_updated_probe_score = cell_size;

        const int kRadius = 1;

        for (int y = -kRadius; y <= kRadius; ++y)
        {
            for (int x = -kRadius; x <= kRadius; ++x)
            {
                int2 tap = probe + int2(x, y);

                if (any(tap < 0) || any(tap >= probe_res))
                {
                    continue;   // out of bounds
                }

                uint probe_index = uint(tap.x + tap.y * probe_res.x);

                uint cached_tile_count = g_ScreenProbes_ProbeCachedTileListCountBuffer[probe_index];
                uint cached_tile_index = g_ScreenProbes_ProbeCachedTileListIndexBuffer[probe_index];

                // DEV_NOTE: iterate over probes inside LRU cache
                for (uint i = 0; i < cached_tile_count; ++i)
                {
                    uint  cached_tile  = g_ScreenProbes_ProbeCachedTileListBuffer[cached_tile_index + i];
                    uint  cached_index = g_ScreenProbes_ProbeCachedTileLRUBuffer[cached_tile];
                    uint2 cached_probe = uint2(cached_index % dims.x, cached_index / dims.x);
                    uint2 cached_pos   = (cached_probe * g_ScreenProbesConstants.probe_size) + cell;

                    float4 cached_probe_pos    = g_ScreenProbes_ProbeCachedTileIndexBuffer[cached_probe];
                    float3 cached_probe_normal = normalize(unpackNormal(asuint(cached_probe_pos.w)));

                    // DEV_NOTE: check that the LRU cache probe is close enough to the current probe
                    if (abs(dot(cached_probe_pos.xyz - world_pos, normal)) < cell_size)
                    {
                        // DEV_NOTE: compute probe score from its 3D distance from the current probe
                        float updated_probe_score = distance(cached_probe_pos.xyz, world_pos);

                        // DEV_NOTE: the best probe is the one that is closer the current probe, if its (hemisphere) orientation is close enough
                        if (updated_probe_score < best_updated_probe_score && dot(normal, cached_probe_normal) > 0.95f)
                        {
                            updated_probe_mask       = cached_tile; // DEV_NOTE: index in LRU cache
                            best_updated_probe_score = updated_probe_score;
                        }

                        float4 cached_probe_radiance  = g_ScreenProbes_ProbeCachedTileBuffer[cached_pos];

                        // DEV_NOTE: local-space direction
                        float3 cached_probe_direction = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);

                        // DEV_NOTE: local to world space direction
                        float3 b1, b2;
                        GetOrthoVectors(cached_probe_normal, b1, b2);
                        cached_probe_direction = cached_probe_direction.x * b1 + cached_probe_direction.y * b2 + cached_probe_direction.z * cached_probe_normal;

                        // DEV_NOTE: reconstruct LRU cache probe hit point in the given direction
                        float3 hit_point       = cached_probe_pos.xyz + cached_probe_direction * cached_probe_radiance.w;
                        float3 reprojected_dir = hit_point - world_pos;
                        
                        // DEV_NOTE(OPTIM): normalization can be done after "hemisphere check" (dot(normal, reprojected_dir)) below
                        float  reprojected_len = length(reprojected_dir);
                        reprojected_dir /= reprojected_len; // normalize

                        if (dot(normal, reprojected_dir) > 0.0f) // DEV_NOTE: hemisphere check
                        {
                            // DEV_NOTE: accumulate the LRU cache probe into the LDS radiance
                            float2 remap_uv         = mapToHemiOctahedron(mul(reprojected_dir, CreateTBN(normal)));
                            uint2  remap_cell       = uint2(remap_uv * g_ScreenProbesConstants.probe_size);
                            uint   remap_cell_index = remap_cell.x + remap_cell.y * g_ScreenProbesConstants.probe_size;
                            uint4  remap_radiance   = ScreenProbes_QuantizeRadiance(float4(cached_probe_radiance.xyz, reprojected_len));

                            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 0], remap_radiance.x);
                            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 1], remap_radiance.y);
                            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 2], remap_radiance.z);
                            InterlockedAdd(lds_ScreenProbes_RadianceValues[(remap_cell_index << 2) + 3], remap_radiance.w);
                            InterlockedAdd(lds_ScreenProbes_RadianceSampleCounts[remap_cell_index], 1);
                        }
                    }

                    if (previous_probe_mask != kGI10_InvalidId)
                    {
                        // DEV_NOTE: check that the LRU cache probe is close enough to the previous probe
                        if (abs(dot(cached_probe_pos.xyz - previous_probe_pos, previous_probe_normal)) < cell_size)
                        {
                            // DEV_NOTE: compute evicted probe score as distance between the LRU cache probe and the previous probe position
                            float evicted_probe_score = distance(cached_probe_pos.xyz, previous_probe_pos);

                            // DEV_NOTE: the best probe is the one that is closer the current probe, if its (hemisphere) orientation is close enough
                            // DEV_NOTE(QUESTION): this seems incorrect? We evict the "best" probe?
                            if (evicted_probe_score < best_evicted_probe_score && dot(previous_probe_normal, cached_probe_normal) > 0.95f)
                            {
                                evicted_probe_mask       = cached_tile;
                                best_evicted_probe_score = evicted_probe_score;
                            }
                        }
                    }
                }
            }
        }

        // DEV_NOTE: LRU cache eviction policy
        if (cell_index == 0) // DEV_NOTE: Only a single thread in the group (since each group treats a single probe, and each thread treats a direction (=cell))
        {
            if (previous_probe_mask != kGI10_InvalidId) // DEV_NOTE: 
            {
                if (evicted_probe_mask == kGI10_InvalidId) // DEV_NOTE: if we did not select any probe to evict
                {
                    // DEV_NOTE: evict probe whose index is the g_ScreenProbes_ProbeCachedTileLRUCountBuffer counter
                    InterlockedAdd(g_ScreenProbes_ProbeCachedTileLRUCountBuffer[0], 1, evicted_probe_mask);

                    // DEV_NOTE: mark the evicted probe as a "new probe"
                    evicted_probe_mask |= 0x80000000u;  // flag newly allocated cached probe
                }
                else // DEV_NOTE: otherwise we selected a probe to evict
                {
                    // DEV_NOTE: try to atomically replace the "flag" value of the selected LRU cache probe (flag: 1 -> 0)
                    uint cached_tile_flag;
                    InterlockedCompareExchange(g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[evicted_probe_mask], 1 /*DEV_NOTE: compare_value*/, 0 /*DEV_NOTE: new_value*/, cached_tile_flag);

                    if (cached_tile_flag != 1) // DEV_NOTE: if another thread already clear the flag of the LRU cache probe...
                    {
                        evicted_probe_mask = kGI10_InvalidId; // DEV_NOTE: ...mark the evicted probe as invalid for the thread
                    }
                }
            }

            // DEV_NOTE: updated_probe_mask = index in LRU cache of the best scoring probe
            if (updated_probe_mask != kGI10_InvalidId) // DEV_NOTE: if we did selected a probe to evict
            {
                // DEV_NOTE: try to atomically replace the "flag" value of the "best scoring probe in LRU cache" (flag: 1 -> 0)
                // -> that way only 1 thread updates the entry
                // -> will be restored in "BlendScreenProbes" pass
                uint cached_tile_flag;
                InterlockedCompareExchange(g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[updated_probe_mask], 1, 0, cached_tile_flag);

                if (cached_tile_flag != 1) // DEV_NOTE: if another thread already clear the flag of the LRU cache probe...
                {
                    updated_probe_mask = kGI10_InvalidId; // DEV_NOTE: ...mark the best scoring probe as invalid for the thread
                }
            }

            // DEV_NOTE: did / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size) => probe index
            // DEV_NOTE: for each probe, output the mask (index in the LRU cache) of the probe to evict (or kGI10_InvalidId) and of the "best scoring probe" (or kGI10_InvalidId)
            g_ScreenProbes_ProbeSpawnProbeBuffer[did / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size)] = uint2(evicted_probe_mask, updated_probe_mask);
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // DEV_NOTE: average reproject radiance (3x3 neighbourhood + LRU cache)
    float  total_weight      = float(lds_ScreenProbes_RadianceSampleCounts[local_id]);
    float4 previous_radiance = ScreenProbes_RecoverRadiance(uint4(lds_ScreenProbes_RadianceValues[(local_id << 2) + 0],
                                                                  lds_ScreenProbes_RadianceValues[(local_id << 2) + 1],
                                                                  lds_ScreenProbes_RadianceValues[(local_id << 2) + 2],
                                                                  lds_ScreenProbes_RadianceValues[(local_id << 2) + 3]));

    if (total_weight > 0.0f)
    {
        previous_radiance /= total_weight;
    }
    else
    {
        previous_radiance.w = -1.0f;
    }

    float3 direction = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);

    // DEV_NOTE: value used for CDF building: "luminance of previous radiance times cosine of angle between direction and hemisphere normal"
    float  radiance  = luminance(previous_radiance.xyz) * dot(direction, float3(0.0f, 0.0f, 1.0f));

    // DEV_NOTE: build a CDF over the radiance values (over all the 64 directions of the hemioctahedron) of the group using shared memory
    // DEV_NOTE(OPTIM): when specular lighting in enabled (and w/o MIS), could skip CDF computation if the lobe selection is performed per tile/probe
    ScreenProbes_ScanRadiance(local_id, radiance);  // build our sampling CDF

    if (probe_index >= probe_count)
    {
        return; // out of bounds
    }

    {
        // DEV_NOTE: retrieve the material of the primaray surface
        // get material
        float4 visibility = g_VisibilityBuffer.Load(int3(seed, 0));
        float2 barycentrics = visibility.xy;
        uint instanceID = asuint(visibility.z);
        uint primitiveID = asuint(visibility.w);

        Instance instance = g_InstanceBuffer[instanceID];
        Mesh mesh = g_MeshBuffer[instance.mesh_index];
        float3x4 transform = g_TransformBuffer[instance.transform_index];

        TriangleNormUV vertices = fetchVerticesNormUV(mesh, primitiveID);
        float2 mesh_uv = interpolate(vertices.uv0, vertices.uv1, vertices.uv2, barycentrics);

        float3 view_direction = normalize(g_Eye - world_pos);
        float3 shading_normal = normalize(2.0f * g_ShadingNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);

        Material material = g_MaterialBuffer[instance.material_index];
        MaterialBRDF materialBRDF = MakeMaterialBRDF(material, mesh_uv);

        // Transform the view direction into the surfaces tangent coordinate space (oriented so that z axis is aligned to normal)
        Quaternion localRotation = QuaternionRotationZ(normal);
        float3 localView = localRotation.transform(view_direction);

        Random randomNG = MakeRandom(did, g_FrameIndex);
        float2 samples = randomNG.rand2();

#ifndef DISABLE_SPECULAR_MATERIALS
        // DEV_NOTE: when specular materials are enabled, random choose between specular and diffuse layer

        // calculate diffuse, specular layer probability
        float3 specularLightDirection = calculateGGXSpecularDirection(shading_normal, view_direction, sqrt(materialBRDF.roughnessAlpha));
        float3 specularHalfVector = normalize(view_direction + specularLightDirection);
        float specularDotHV = saturate(dot(specularHalfVector, view_direction));
        float probabilityBRDF = calculateBRDFProbability(materialBRDF.F0, specularDotHV, materialBRDF.albedo);

        // specular layer case
        if (randomNG.rand() < probabilityBRDF)
        {
            // DEV_NOTE: importance sampling according to surface BRDF (not incoming radiance)
            //           => could use MIS to sample according to both BRDF and incoming radiance

            // sample direction by BRDF importance sampling
            float3 newLight = sampleGGX(materialBRDF.roughnessAlpha, localView, samples);
            direction = normalize(localRotation.inverse().transform(newLight));
        }
        // diffuse layer case
        else
#endif
        {
            // sample direction by ray guiding
            // DEV_NOTE: ScreenProbes_FindCellIndex sample the CDF (via dichtomic search)
            uint sampled_cell_index = ScreenProbes_FindCellIndex(local_id, randomNG.rand());
            uint2 sampled_cell = (total_weight > 0.0f ? uint2(sampled_cell_index % g_ScreenProbesConstants.probe_size, sampled_cell_index / g_ScreenProbesConstants.probe_size) : cell);
            direction = mapToHemiOctahedronInverse((sampled_cell + randomNG.rand2()) / g_ScreenProbesConstants.probe_size);

            float3 b1, b2;
            GetOrthoVectors(normal, b1, b2);
            direction = direction.x * b1 + direction.y * b2 + direction.z * normal;
        }
    }

    g_ScreenProbes_PreviousProbeBuffer[pos]    = previous_radiance; // DEV_NOTE: reproject radiance (3x3 neighbourhood + LRU)

    // DEV_NOTE(OPTIM): use a better packing for the direction (octahedron mapping on 32 bits for example)
    // uint2 ScreenProbes_PackSample(in float3 direction)
    // {
    //   uint3 packed_sample = f32tof16(direction);
    //   return uint2((packed_sample.x << 16) | packed_sample.y, packed_sample.z << 16);
    // }
    g_ScreenProbes_ProbeSpawnSampleBuffer[did] = ScreenProbes_PackSample(direction); // DEV_NOTE: selected direction to update
}

// DEV_NOTE: the HashGrid world space is used to feed the radiance to the screen-space radiance probe cache
void PopulateScreenProbesHandleHit(uint did, inout PopulateScreenProbesPayload payload, RayDesc ray, HitInfo hit_info)
{
    HashGridCache_Data data;
    data.eye_position = g_Eye;
    data.hit_position = ray.Origin + payload.hit_dist * ray.Direction;
    data.direction    = ray.Direction;
    data.hit_distance = payload.hit_dist;

    uint tile_index;
    bool is_new_tile;
    uint cell_index = HashGridCache_InsertCell(data, tile_index, is_new_tile);

    if (cell_index != kGI10_InvalidId)
    {
        // Bump the cell's decay to the max. now that it's been 'touched'
        uint previous_tile_decay;
        InterlockedExchange(g_HashGridCache_DecayTileBuffer[tile_index], g_FrameIndex, previous_tile_decay);

        HashGridCache_Visibility visibility;
        visibility.is_front_face   = hit_info.frontFace;
        visibility.instance_index  = hit_info.instanceIndex;
        visibility.geometry_index  = hit_info.geometryIndex;
        visibility.primitive_index = hit_info.primitiveIndex;
        visibility.barycentrics    = hit_info.barycentrics;

        // DEV_NOTE: g_HashGridCache_VisibilityCountBuffer is use for the indirect dispatch arguments setup of the GenerateReservoirs pass
        // We update the cell index for later passes
        uint visibility_index;
        InterlockedAdd(g_HashGridCache_VisibilityCountBuffer[0], 1, visibility_index);
        g_HashGridCache_VisibilityBuffer[visibility_index]      = HashGridCache_PackVisibility(visibility);
        g_HashGridCache_VisibilityCellBuffer[visibility_index]  = cell_index;
        g_HashGridCache_VisibilityQueryBuffer[visibility_index] = did;

        // Write out bounds of visibility
        // DEV_NOTE:
        // /**
        //  * Records the position of future light lookups.
        //  * @param position Current position on surface.
        //  */
        // void requestLightSampleLocation(in float3 position)
        // {
        //     const float3 position_min = WaveActiveMin(position);
        //     const float3 position_max = WaveActiveMax(position);
        //     if (WaveIsFirstLane())
        //     {
        //         uint offset;
        //         InterlockedAdd(g_LightSampler_BoundsLength[0], 1, offset);
        //         g_LightSampler_MinBounds[offset] = position_min;
        //         g_LightSampler_MaxBounds[offset] = position_max;
        //     }
        // }
        // DEV_NOTE(QUESTION): this seems to construct, for the wave, an AABB of the hit position that would be use to query lights radiance?
        requestLightSampleLocation(data.hit_position);

        // If this cell is inside a new tile, we need to add the tile to the packed storage and clear its cells.
        if (is_new_tile)
        {
            uint packed_tile_index;
            InterlockedAdd(g_HashGridCache_PackedTileCountBuffer[0], 1, packed_tile_index);
            g_HashGridCache_PackedTileIndexBuffer[packed_tile_index] = tile_index;

            // Clear mip0 cells (others will be reset anyways by UpdateTiles)
            for (int cell_offset = 0; cell_offset < g_HashGridCacheConstants.num_cells_per_tile_mip0; ++cell_offset)
            {
                uint cell_index = HashGridCache_CellIndex(cell_offset, tile_index);
                g_HashGridCache_ValueBuffer[cell_index] = uint2(0, 0);
            }
        }

        // If we're the 1st invocation touching this cell (this frame), we want to clear the
        // scratch storage that'll be used for atomically updating the radiance.
        // The accumulation will be resolved in the 'UpdateTiles()' kernel to
        // avoid integer overflow.
        if (is_new_tile || previous_tile_decay != g_FrameIndex)
        {
            uint update_tile_index;
            InterlockedAdd(g_HashGridCache_UpdateTileCountBuffer[0], 1, update_tile_index);
            g_HashGridCache_UpdateTileBuffer[update_tile_index] = tile_index;
        }

#ifdef DEBUG_HASH_CELLS
        // For debugging purposes, we need to be able to retrieve the position
        // & orientation of cells as we iterate the content of the cache.
        // So, write the packed cell descriptor out to memory in this case.
        if (is_new_tile)
        {
            // Clear debug cells (all mips)
            for (int cell_offset = 0; cell_offset < g_HashGridCacheConstants.num_cells_per_tile; ++cell_offset)
            {
                uint cell_index = HashGridCache_CellIndex(cell_offset, tile_index);
                g_HashGridCache_DebugCellBuffer[cell_index] = HashGridCache_ClearDebugCell();
            }
        }

        float4 packed_debug_cell;
        uint debug_cell_index = HashGridCache_PackDebugCell(data, tile_index, packed_debug_cell);

        // BE CAREFUL: writing to g_HashGridCache_DebugCellBuffer isn't atomic and several writings could occur
        uint previous_cell_decay;
        InterlockedExchange(g_HashGridCache_DecayCellBuffer[debug_cell_index], g_FrameIndex, previous_cell_decay);
        if (previous_cell_decay != g_FrameIndex)
        {
            g_HashGridCache_DebugCellBuffer[debug_cell_index] = packed_debug_cell;
        }
#endif // DEBUG_HASH_CELLS
    }
}

void PopulateScreenProbesHandleMiss(inout PopulateScreenProbesPayload payload, RayDesc ray)
{
    if (g_UseDirectLighting != 0)
    {
        payload.sky_sample = g_EnvironmentBuffer.SampleLevel(g_TextureSampler, ray.Direction, 0.0f).xyz;
    }
}

void PopulateScreenProbesTraceRayInline(uint did, inout PopulateScreenProbesPayload payload, RayDesc ray)
{
    ClosestRayQuery ray_query = TraceRay<ClosestRayQuery>(ray);

    // If we hit some geometry, we append a new world-space hash-grid cache query
    if (ray_query.CommittedStatus() == COMMITTED_NOTHING)
    {
        payload.hit_dist = ray_query.CommittedRayT();
        PopulateScreenProbesHandleMiss(payload, ray); // DEV_NOTE: return environment radiance on miss
    }
    else
    {
        payload.hit_dist = ray_query.CommittedRayT();
        PopulateScreenProbesHandleHit(did, payload, ray, GetHitInfoRtInlineCommitted(ray_query));
    }
}

void PopulateScreenProbesTraceRayRt(uint did, inout PopulateScreenProbesPayload payload, RayDesc ray)
{
    TraceRay(g_Scene, RAY_FLAG_NONE, 0xFFu, 0, 0, 0, ray, payload);
}

void PopulateScreenProbesTraceRay(uint did, inout PopulateScreenProbesPayload payload, RayDesc ray)
{
#if USE_INLINE_RT
    return PopulateScreenProbesTraceRayInline(did, payload, ray);
#else
    return PopulateScreenProbesTraceRayRt(did, payload, ray);
#endif
}
// DEV_NOTE: use (inline) raytracing to find intersection of sample direction + evalutate **sky** indirect radiance (direct radiance at hit point)
void PopulateScreenProbes(uint did)
{
    uint max_probe_spawn_count = ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size)
                               * ((g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size);
    uint probe_count           = g_ScreenProbes_ProbeSpawnScanBuffer[max_probe_spawn_count - 1]
                               + g_ScreenProbes_ProbeSpawnIndexBuffer[max_probe_spawn_count - 1];

    // DEV_NOTE: retrieve probe and cell (=direction) indices
    // uint2 ScreenProbes_GetCellAndProbeIndex(in uint query_index)
    // {
    //     return uint2(query_index % (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size),
    //                  query_index / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size));
    // }
    // DEV_NOTE: a thread group treats a single probe (same probe_index), a thread treats a direction (=cell) in the probe 
    uint2 cell_and_probe_index = ScreenProbes_GetCellAndProbeIndex(did);
    uint  probe_index          = cell_and_probe_index.y;

    if (probe_index >= probe_count)
    {
        return; // out of bounds
    }

    // Read the visibility buffer and decode

    // DEV_NOTE: retrieve spawn probe (scene) pixel coords
    uint2  seed         = ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]);
    float3 normal       = g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel)
    {
        return; // discard sky pixels
    }

    // DEV_NOTE: retrieve direction of probes to update
    float3 direction = ScreenProbes_UnpackSample(g_ScreenProbes_ProbeSpawnSampleBuffer[did]);
    normal           = normalize(2.0f * normal - 1.0f);

    // DEV_NOTE: reconstruct primary surface and spawn ray + trace
    float4 visibility   = g_VisibilityBuffer.Load(int3(seed, 0));
    float2 barycentrics = visibility.xy;
    uint   instanceID   = asuint(visibility.z);
    uint   primitiveID  = asuint(visibility.w);

    Instance instance  = g_InstanceBuffer[instanceID];
    Mesh     mesh      = g_MeshBuffer[instance.mesh_index];
    float3x4 transform = g_TransformBuffer[instance.transform_index];

    Triangle vertices = fetchVertices(mesh, primitiveID);
    float3 v0 = transformPoint(vertices.v0, transform);
    float3 v1 = transformPoint(vertices.v1, transform);
    float3 v2 = transformPoint(vertices.v2, transform);

    float3 world  = interpolate(v0, v1, v2, barycentrics);
    float3 origin = offsetPosition(world, normal);

    RayDesc ray_desc;
    ray_desc.Direction = direction;
    ray_desc.Origin    = origin;
    ray_desc.TMin      = 0.0f;
    ray_desc.TMax      = MAX_HIT_DISTANCE;

    PopulateScreenProbesPayload payload;
    payload.sky_sample = float3(0.0f, 0.0f, 0.0f);
    payload.seed = seed;
    PopulateScreenProbesTraceRay(did, payload, ray_desc);

    // DEV_NOTE: only sky sample value is returned (only filled on ray miss) BUT the hit_dist is the hit distance in case of hit
    g_ScreenProbes_ProbeSpawnRadianceBuffer[did] = ScreenProbes_PackRadiance(float4(payload.sky_sample, payload.hit_dist));
}

[numthreads(32, 1, 1)]
void PopulateScreenProbesMain(in uint did : SV_DispatchThreadID)
{
    PopulateScreenProbes(did);
}

// DEV_NOTE: uint32_t const  num_groups_x = (screen_probes_.max_ray_count + num_threads[0] - 1) / num_threads[0];
//           max_ray_count = max_probe_spawn_count * probe_size_ * probe_size_;
// DEV_NOTE: 64 matches the number of direction in a probe -> each thread in a group treat all the directions of a probe
[numthreads(64, 1, 1)]
void BlendScreenProbes(in uint did : SV_DispatchThreadID, in uint local_id : SV_GroupThreadID)
{
    uint max_probe_spawn_count = ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size)
                               * ((g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size);

    // DEV_NOTE(QUESTION): what are these 2 buffers?
    uint probe_count           = g_ScreenProbes_ProbeSpawnScanBuffer[max_probe_spawn_count - 1]
                               + g_ScreenProbes_ProbeSpawnIndexBuffer[max_probe_spawn_count - 1];

    // DEV_NOTE: retrieve probe and cell (=direction) indices
    // uint2 ScreenProbes_GetCellAndProbeIndex(in uint query_index)
    // {
    //     return uint2(query_index % (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size),
    //                  query_index / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size));
    // }
    // DEV_NOTE: a thread group treats a single probe (same probe_index), a thread treats a direction (=cell) in the probe 
    uint2 cell_and_probe_index = ScreenProbes_GetCellAndProbeIndex(did);
    uint  cell_index           = cell_and_probe_index.x; // DEV_NOTE: linear direction index (in "linear 1D global probe direction space" [0, (numProbes.x*probe_size*numProbes.y*probe_size)-1])
    uint  probe_index          = cell_and_probe_index.y; // DEV_NOTE: linear probe index (in "linear 1D probe space" [0, numProbes.x*numProbes.y-1])

    // DEV_NOTE: 2d direction index in "2D local probe direction space" [0, probe_size-1]^2
    uint2 cell  = uint2(cell_index % g_ScreenProbesConstants.probe_size, cell_index / g_ScreenProbesConstants.probe_size);
    
    // DEV_NOTE: (scene) pixel coords of the spawned probe in [0, sceneRes.x-1]x[0, sceneRes.y-1]
    uint2 seed  = (probe_index < probe_count ? ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]) : uint2(-1, -1));

    // DEV_NOTE: 2D probe index in "2D probe space" [0, numProbes.x-1]x[0, numProbes.y-1]
    uint2 probe = (seed / g_ScreenProbesConstants.probe_size);

    // DEV_NOTE: 2d index to select a direction in the atlas of probes (in "2D global probe direction space" [0, numProbes.x*probe_size-1]x[0, numProbes.y*probe_size-1])
    uint2 pos   = (probe * g_ScreenProbesConstants.probe_size) + cell;

    // Initialize our LDS...
    {
        lds_ScreenProbes_RadianceValues[(local_id << 2) + 0] = 0;
        lds_ScreenProbes_RadianceValues[(local_id << 2) + 1] = 0;
        lds_ScreenProbes_RadianceValues[(local_id << 2) + 2] = 0;
        lds_ScreenProbes_RadianceValues[(local_id << 2) + 3] = 0;
        lds_ScreenProbes_RadianceSampleCounts[local_id] = 0;
    }
    GroupMemoryBarrierWithGroupSync();

    // ... and accumulate into the sampled cells
    // DEV_NOTE: accumulate the radiance samples we computed this frame
    //  -> 
    if (probe_index < probe_count)
    {
        // DEV_NOTE: we use the GBuffer normal at the probe position to generate the tangent space (hemisphere) -> see CreateTBN below
        // and use it to transform the directions we compute this frame (g_ScreenProbes_ProbeSpawnSampleBuffer) in the hemisphere of the pixel/probe
        // and accumulate in LDS since multiple directions can end in the same cell of the hemioctahedron
        float3 normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);

        // DEV_NOTE: direction of radiance to update (selected in "SampleScreenProbes" via ray guiding (diffuse) / BRDF sampling (specular))
        float3 direction = ScreenProbes_UnpackSample(g_ScreenProbes_ProbeSpawnSampleBuffer[did]);
        float4 radiance  = ScreenProbes_UnpackRadiance(g_ScreenProbes_ProbeSpawnRadianceBuffer[did]);

        uint4 quantized_radiance = ScreenProbes_QuantizeRadiance(radiance);
        uint2 sampled_cell       = uint2(mapToHemiOctahedron(mul(direction, CreateTBN(normal))) * g_ScreenProbesConstants.probe_size);
        uint  sampled_cell_index = sampled_cell.x + sampled_cell.y * g_ScreenProbesConstants.probe_size;

        InterlockedAdd(lds_ScreenProbes_RadianceValues[(sampled_cell_index << 2) + 0], quantized_radiance.x);
        InterlockedAdd(lds_ScreenProbes_RadianceValues[(sampled_cell_index << 2) + 1], quantized_radiance.y);
        InterlockedAdd(lds_ScreenProbes_RadianceValues[(sampled_cell_index << 2) + 2], quantized_radiance.z);
        InterlockedAdd(lds_ScreenProbes_RadianceValues[(sampled_cell_index << 2) + 3], quantized_radiance.w);
        InterlockedAdd(lds_ScreenProbes_RadianceSampleCounts[sampled_cell_index], 1);
    }
    GroupMemoryBarrierWithGroupSync();

    // Calculate the radiance backup value to be used for untraced cells
    // DEV_NOTE: slide 21
    // > Average the radiance from traced cells (= cells with reprojected values) in LDS and distribute uniformly across the untraced ones
    {
        // DEV_NOTE: local_id = linear thread id in group
        // DEV_NOTE: store 1 in .w if the cell contains some samples, 0 otherwise -> used to count number of empty cells below
        lds_ScreenProbes_RadianceBackup[local_id] = float4(ScreenProbes_RecoverRadiance(uint3(lds_ScreenProbes_RadianceValues[(local_id << 2) + 0],
                                                                                              lds_ScreenProbes_RadianceValues[(local_id << 2) + 1],
                                                                                              lds_ScreenProbes_RadianceValues[(local_id << 2) + 2])),
                                                                                              lds_ScreenProbes_RadianceSampleCounts[local_id] > 0.0f ? 1.0f : 0.0f);
        GroupMemoryBarrierWithGroupSync();

        // DEV_NOTE: group sum reduce
        // DEV_NOTE: sized for 8x8 threadgroup
        for (uint stride = 1; stride < 64; stride <<= 1)
        {
            if (local_id < 64 / (2 * stride))
                lds_ScreenProbes_RadianceBackup[2 * (local_id + 1) * stride - 1] += lds_ScreenProbes_RadianceBackup[(2 * local_id + 1) * stride - 1];
            GroupMemoryBarrierWithGroupSync();
        }

        // DEV_NOTE: average radiance (for all the 64 directions on the hemioctahedron) over the empty cells
        if (local_id == 0)
        {
            float4 total_radiance   = lds_ScreenProbes_RadianceBackup[64 - 1];
            float3 radiance         = total_radiance.xyz / max(total_radiance.w, 1.0f);
            
            // DEV_NOTE: count the number of empty cells: 64 - #"cells with a radiance value"
            float  empty_cell_count = (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size - total_radiance.w);

            // DEV_NOTE: MAX_HIT_DISTANCE = 1e9f
            lds_ScreenProbes_RadianceBackup[0] = float4(radiance / max(empty_cell_count, 1.0f), MAX_HIT_DISTANCE);
        }
        GroupMemoryBarrierWithGroupSync();
    }

    // We can now map back to our regular probe grid
    if (probe_index >= probe_count)
    {
        return; // out of bounds
    }

    // DEV_NOTE: Recovers the previously quantized radiance value.
    //           float4 ScreenProbes_RecoverRadiance(in uint4 quantized_radiance)
    //           {
    //               return quantized_radiance / kGI10_FloatQuantize;
    //           }
    // DEV_NOTE(QUESTION): what is in .w?
    float4 radiance = ScreenProbes_RecoverRadiance(uint4(lds_ScreenProbes_RadianceValues[(local_id << 2) + 0],
                                                         lds_ScreenProbes_RadianceValues[(local_id << 2) + 1],
                                                         lds_ScreenProbes_RadianceValues[(local_id << 2) + 2],
                                                         lds_ScreenProbes_RadianceValues[(local_id << 2) + 3]));

    uint sample_count = lds_ScreenProbes_RadianceSampleCounts[local_id];

    if (sample_count > 0)
    {
        radiance /= sample_count;
    }
    else
    {
        radiance = lds_ScreenProbes_RadianceBackup[0];
    }

    float4 previous_radiance = g_ScreenProbes_PreviousProbeBuffer[pos];

    if (previous_radiance.w > 0.0f) // DEV_NOTE: if there is a previous value
    {
        float lumaA = luminance(radiance.xyz);
        float lumaB = luminance(previous_radiance.xyz);

        // Shadow-preserving biased temporal hysteresis (inspired by: https://www.youtube.com/watch?v=WzpLWzGvFK4&t=630s)
        float temporal_blend = squared(clamp(max(lumaA - lumaB - min(lumaA, lumaB), 0.0f) / max(max(lumaA, lumaB), 1e-4f), 0.0f, 0.95f));

        radiance = lerp(radiance, previous_radiance, temporal_blend);
    }

    uint2 dims;
    g_ScreenProbes_ProbeCachedTileIndexBuffer.GetDimensions(dims.x, dims.y);

    uint evicted_probe_mask = g_ScreenProbes_ProbeSpawnProbeBuffer[did / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size)].x;
    uint updated_probe_mask = g_ScreenProbes_ProbeSpawnProbeBuffer[did / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size)].y;

    // DEV_NOTE: "if we have a probe to evict in the LRU cache"
    if (evicted_probe_mask != kGI10_InvalidId && evicted_probe_mask >= g_ScreenProbes_ProbeCachedTileLRUCountBuffer[0])
    {
        if ((evicted_probe_mask & 0x80000000u) != 0)
        {
            evicted_probe_mask &= ~0x80000000u; // unmask

            // DEV_NOTE(QUESTION): it seems that all the active threads do the writes below -> should it be only (cell_index == 0)?
            g_ScreenProbes_ProbeCachedTileLRUBuffer[evicted_probe_mask]    &= ~0x80000000u; // DEV_NOTE: removes "invalid data" flag
            g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[evicted_probe_mask] = 0; // DEV_NOTE: "evicted" -> matches the test in ReorderScreenProbes
                                                                                 // --> each entry set to 0 has a MRU entry
        }

        uint  cached_index = g_ScreenProbes_ProbeCachedTileLRUBuffer[evicted_probe_mask];
        uint2 cached_probe = uint2(cached_index % dims.x, cached_index / dims.x);
        uint2 cached_pos   = (cached_probe * g_ScreenProbesConstants.probe_size) + cell;

        if (cell_index == 0)
        {
            uint previous_probe_mask = g_ScreenProbes_ProbeMaskBuffer[probe];

            uint cached_tile_mru_index;
            InterlockedAdd(g_ScreenProbes_ProbeCachedTileMRUCountBuffer[0], 1, cached_tile_mru_index);

            // DEV_NOTE: write the current probe into the "most recently used" queue
            g_ScreenProbes_ProbeCachedTileMRUBuffer[evicted_probe_mask] = cached_tile_mru_index;

            float2 previous_uv     = (ScreenProbes_UnpackSeed(previous_probe_mask) + 0.5f) / g_BufferDimensions;
            float  previous_depth  = g_DepthBuffer.Load(int3(ScreenProbes_UnpackSeed(previous_probe_mask), 0)).x;
            float3 previous_normal = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(ScreenProbes_UnpackSeed(previous_probe_mask), 0)).xyz - 1.0f);
            float3 previous_world  = InverseProject(g_ViewProjectionInverse, previous_uv, previous_depth);

            // DEV_NOTE: store world position and normal of current probe into the LRU cache
            g_ScreenProbes_ProbeCachedTileIndexBuffer[cached_probe] = float4(previous_world, asfloat(packNormal(previous_normal)));
        }

        // DEV_NOTE: pos = (scene) pixel coords of the spawned probe in [0, sceneRes.x-1]x[0, sceneRes.y-1]
        g_ScreenProbes_ProbeCachedTileBuffer[cached_pos] = g_ScreenProbes_ProbeBuffer[pos];
    }

    // DEV_NOTE: "if we have a probe to update in the LRU cache"
    // DEV_NOTE: g_ScreenProbes_ProbeCachedTileLRUCountBuffer written in 'SampleScreenProbes'
    if (updated_probe_mask != kGI10_InvalidId && updated_probe_mask >= g_ScreenProbes_ProbeCachedTileLRUCountBuffer[0])
    {
        uint  cached_index = g_ScreenProbes_ProbeCachedTileLRUBuffer[updated_probe_mask];
        uint2 cached_probe = uint2(cached_index % dims.x, cached_index / dims.x);
        uint2 cached_pos   = (cached_probe * g_ScreenProbesConstants.probe_size) + cell;

        if (cell_index == 0)
        {
            g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[updated_probe_mask] = 1; // DEV_NOTE: "valid"
        }

        g_ScreenProbes_ProbeCachedTileBuffer[cached_pos] = radiance;
    }

    // DEV_NOTE: only 1 thread update the "probe mask" buffer with seed (= (scene) pixel coords of the spawned probe in [0, sceneRes.x-1]x[0, sceneRes.y-1])
    if (cell_index == 0)
    {
        g_ScreenProbes_ProbeMaskBuffer[probe] = ScreenProbes_PackSeed(seed);
    }

    // DEV_NOTE: update the radiance in the current direction of the current probe 
    // DEV_NOTE: pos = 2d index to select a direction in the atlas of probes (in "2D global probe direction space" [0, numProbes.x*probe_size-1]x[0, numProbes.y*probe_size-1])
    g_ScreenProbes_ProbeBuffer[pos] = radiance;
}

// DEV_NOTE: Re-order the cached probes so the least-recently used entries are evicted first
// DEV_NOTE: uint32_t const  num_groups_x = (screen_probes_.probe_count_[0] * screen_probes_.probe_count_[1] + num_threads[0] - 1) / num_threads[0];
[numthreads(64, 1, 1)]
void ReorderScreenProbes(in uint did : SV_DispatchThreadID)
{
    uint2 dims;
    g_ScreenProbes_ProbeCachedTileIndexBuffer.GetDimensions(dims.x, dims.y);

    if (did >= (dims.x * dims.y))
    {
        return; // out of bounds
    }

    uint cached_tile_index  = g_ScreenProbes_ProbeCachedTileLRUBuffer[did];
    uint cached_tile_flag   = g_ScreenProbes_ProbeCachedTileLRUFlagBuffer[did];
    uint cached_tile_offset = g_ScreenProbes_ProbeCachedTileLRUIndexBuffer[did];

    if (cached_tile_flag == 0) // DEV_NOTE: "probe to evict" flag
    {
        // DEV_NOTE(QUESTION): TODO: understand how g_ScreenProbes_ProbeCachedTileLRUIndexBuffer is computed
        // -> g_ScreenProbes_ProbeCachedTileLRUIndexBuffer[dims.x * dims.y] seems to be the number of entries in the LRU cache
        // ==> place probe to evict at the end of g_ScreenProbes_PreviousProbeCachedTileLRUBuffer
        cached_tile_offset = g_ScreenProbes_ProbeCachedTileMRUBuffer[did] + g_ScreenProbes_ProbeCachedTileLRUIndexBuffer[dims.x * dims.y];
    }

    // DEV_NOTE: g_ScreenProbes_PreviousProbeCachedTileLRUBuffer points to one buffer of the double-bufferd LRU index buffer
    // DEV_NOTE: g_ScreenProbes_PreviousProbeCachedTileLRUBuffer contains indices into g_ScreenProbes_ProbeCachedTileBuffer (after conversion from 1D to 2D coords)
    g_ScreenProbes_PreviousProbeCachedTileLRUBuffer[cached_tile_offset] = cached_tile_index;
}

// DEV_NOTE: uint32_t const  num_groups_x = (screen_probes_.max_ray_count + num_threads[0] - 1) / num_threads[0];
[numthreads(64, 1, 1)]
void FilterScreenProbes(in uint did : SV_DispatchThreadID)
{
    uint max_probe_spawn_count = ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size)
                               * ((g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size);
    uint probe_count           = g_ScreenProbes_ProbeSpawnScanBuffer[max_probe_spawn_count - 1]
                               + g_ScreenProbes_ProbeSpawnIndexBuffer[max_probe_spawn_count - 1];

    // DEV_NOTE: retrieve probe and cell (=direction) indices
    // uint2 ScreenProbes_GetCellAndProbeIndex(in uint query_index)
    // {
    //     return uint2(query_index % (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size),
    //                  query_index / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size));
    // }
    // DEV_NOTE: a thread group treats a single probe (same probe_index), a thread treats a direction (=cell) in the probe 
    uint2 cell_and_probe_index = ScreenProbes_GetCellAndProbeIndex(did);
    uint  cell_index           = cell_and_probe_index.x;
    uint  probe_index          = cell_and_probe_index.y;

    if (probe_index >= probe_count)
    {
        return; // out of bounds
    }

    uint2 cell  = uint2(cell_index % g_ScreenProbesConstants.probe_size, cell_index / g_ScreenProbesConstants.probe_size);
    uint2 seed  = ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]);
    uint2 probe = (seed / g_ScreenProbesConstants.probe_size);
    uint2 pos   = (probe * g_ScreenProbesConstants.probe_size) + cell;

    float2 uv        = (seed + 0.5f) / g_BufferDimensions;
    float  depth     = g_DepthBuffer.Load(int3(seed, 0)).x;
    float3 normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);
    float3 world_pos = InverseProject(g_ViewProjectionInverse, uv, depth);
    float  cell_size = distance(g_Eye, world_pos) * g_ScreenProbesConstants.cell_size;

    float4 radiance     = g_ScreenProbes_PreviousProbeBuffer[pos];
    float3 direction    = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);
    float  hit_distance = radiance.w;
    float  total_weight = 1.0f;

    // DEV_NOTE: local direction -> world direction
    float3 b1, b2;
    GetOrthoVectors(normal, b1, b2);
    direction = direction.x * b1 + direction.y * b2 + direction.z * normal;

    const int kRadius = 3;
    const int kSize   = (kRadius << 1);

    for (int i = 0; i < kSize; ++i)
    {
        int  step       = (((i & 1) << 1) - 1) * ((i >> 1) + 1);

        // DEV_NOTE:
        // Finds the closest probe to the specified location on the probe grid.
        // Here, we start at the highest mip level in the probe mask and fall back
        // to lower mips if failing to find a valid probe seed.
        // This allows for very large probe search (up to the entire screen) very
        // efficiently and is particularly useful to find the neighbor probes in
        // disoccluded regions during the final radiance interpolation.
        uint probe_mask = ScreenProbes_FindClosestProbe(seed, step * g_BlurDirection);

        if (probe_mask == kGI10_InvalidId)
        {
            continue;   // invalid probe
        }

        uint2  probe_seed   = ScreenProbes_UnpackSeed(probe_mask);
        float2 probe_uv     = (probe_seed + 0.5f) / g_BufferDimensions;
        float  probe_depth  = g_DepthBuffer.Load(int3(probe_seed, 0)).x;
        float3 probe_normal = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(probe_seed, 0)).xyz - 1.0f);
        float3 probe_world  = InverseProject(g_ViewProjectionInverse, probe_uv, probe_depth);

        // DEV_NOTE: distance and normal consistency tests
        if (abs(dot(probe_world - world_pos, normal)) > cell_size || dot(direction, probe_normal) < 0.0f)
        {
            continue;   // oriented hemispheres do not overlap
        }

        // DEV_NOTE: parallax-correction: reproject direction into sample probe

        uint2 probe_cell = uint2(mapToHemiOctahedron(mul(direction, CreateTBN(probe_normal))) * g_ScreenProbesConstants.probe_size);
        uint2 probe_tile = (probe_seed / g_ScreenProbesConstants.probe_size);
        uint2 probe_pos  = (probe_tile * g_ScreenProbesConstants.probe_size) + probe_cell;

        GetOrthoVectors(probe_normal, b1, b2);
        float3 probe_direction = mapToHemiOctahedronInverse((probe_cell + 0.5f) / g_ScreenProbesConstants.probe_size);
        probe_direction = normalize(probe_direction.x * b1 + probe_direction.y * b2 + probe_direction.z * probe_normal);

        float  probe_hit_distance = min(g_ScreenProbes_PreviousProbeBuffer[probe_pos].w, hit_distance);
        float3 hit_point          = probe_world + probe_direction * probe_hit_distance;
        float3 reprojected_dir    = normalize(hit_point - world_pos);

        // DEV_NOTE: check that reprojected direction does not differ to much from input direction
        // DEV_NOTE: kGI10_AngleThreshold = cos(2e-2f * PI) = cos(3.6deg)
        if (dot(direction, reprojected_dir) < kGI10_AngleThreshold)
        {
            continue;   // skip probes with high angle error after hit reprojection
        }

        // DEV_NOTE: weight based on relative diff of planar distance to camera
        float weight = pow(saturate(1.0f - abs(GetLinearDepth(probe_depth) - GetLinearDepth(depth)) / GetLinearDepth(depth)), 8.0f);

        radiance     += weight * float4(GIDenoiser_RemoveNaNs(g_ScreenProbes_PreviousProbeBuffer[probe_pos].xyz), probe_hit_distance);
        total_weight += weight;

        hit_distance = radiance.w / total_weight;
    }

    g_ScreenProbes_ProbeBuffer[pos] = (radiance / total_weight);
}

// DEV_NOTE: Project the screen probes into SH basis
// DEV_NOTE: uint32_t const  num_groups_x = (screen_probes_.max_ray_count + num_threads[0] - 1) / num_threads[0];
[numthreads(64, 1, 1)]
void ProjectScreenProbes(in uint did : SV_DispatchThreadID, in uint local_id : SV_GroupThreadID)
{
    uint max_probe_spawn_count = ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size)
                               * ((g_BufferDimensions.y + g_ScreenProbesConstants.probe_spawn_tile_size - 1) / g_ScreenProbesConstants.probe_spawn_tile_size);
    uint probe_count           = g_ScreenProbes_ProbeSpawnScanBuffer[max_probe_spawn_count - 1]
                               + g_ScreenProbes_ProbeSpawnIndexBuffer[max_probe_spawn_count - 1];

    // DEV_NOTE: retrieve probe and cell (=direction) indices
    // uint2 ScreenProbes_GetCellAndProbeIndex(in uint query_index)
    // {
    //     return uint2(query_index % (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size),
    //                  query_index / (g_ScreenProbesConstants.probe_size * g_ScreenProbesConstants.probe_size));
    // }
    // DEV_NOTE: a thread group treats a single probe (same probe_index), a thread treats a direction (=cell) in the probe 
    uint2 cell_and_probe_index = ScreenProbes_GetCellAndProbeIndex(did);
    uint  cell_index           = cell_and_probe_index.x;
    uint  probe_index          = cell_and_probe_index.y;

    uint2 cell      = uint2(cell_index % g_ScreenProbesConstants.probe_size, cell_index / g_ScreenProbesConstants.probe_size);
    uint2 seed      = (probe_index < probe_count ? ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]) : uint2(-1, -1));
    uint2 probe     = (seed / g_ScreenProbesConstants.probe_size);
    uint2 probe_pos = (probe * g_ScreenProbesConstants.probe_size) + cell;

    // Compute our SH probe
    if (probe_index < probe_count)
    {
        float3 normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(seed, 0)).xyz - 1.0f);
        float3 radiance  = g_ScreenProbes_ProbeBuffer[probe_pos].xyz / g_ScreenProbesConstants.probe_size;
        float3 direction = mapToHemiOctahedronInverse((cell + 0.5f) / g_ScreenProbesConstants.probe_size);

        float3 b1, b2;
        GetOrthoVectors(normal, b1, b2);
        direction = direction.x * b1 + direction.y * b2 + direction.z * normal;

        float direction_sh[9];
        SH_GetCoefficients(direction, direction_sh);

        for (uint j = 0; j < 9; ++j)
        {
            lds_ScreenProbes_ProbeSHBuffer[9 * local_id + j] = float4(direction_sh[j] * radiance, 1.0f);
        }
    }
    GroupMemoryBarrierWithGroupSync();

    if (probe_index >= probe_count)
    {
        return; // out of bounds
    }

    // Resolve the probe and write out the SH coefficients
    uint sh_index = cell.x + cell.y * g_ScreenProbesConstants.probe_size;

    if (sh_index < 9) // DEV_NOTE: 9 threads average the each channel of the SH3
    {                 // DEV_NOTE(OPTIM): maybe 2 or 3 group sum reductions would be faster?
        float4 irradiance_sh = float4(0.0f, 0.0f, 0.0f, 0.0f);

        // DEV_NOTE: local_id & 7  <=> local_id % 8 => [0, 7]
        // DEV_NOTE: local_id >> 3 <=> local_id / 8 => [0, 7]
        // DEV_NOTE: 
        uint2 offset = (uint2(local_id & 7, local_id >> 3) / g_ScreenProbesConstants.probe_size) * g_ScreenProbesConstants.probe_size;

        for (uint y = 0; y < g_ScreenProbesConstants.probe_size; ++y)
        {
            for (uint x = 0; x < g_ScreenProbesConstants.probe_size; ++x)
            {
                uint2 pos   = uint2(x, y) + offset;
                uint  index = pos.x + (pos.y << 3);

                irradiance_sh += lds_ScreenProbes_ProbeSHBuffer[9 * index + sh_index];
            }
        }

        uint index = probe.x + probe.y * ((g_BufferDimensions.x + g_ScreenProbesConstants.probe_size - 1) / g_ScreenProbesConstants.probe_size);

        g_ScreenProbes_ProbeSHBuffer[9 * index + sh_index] = ScreenProbes_PackSHColor(irradiance_sh);
    }
}


// DEV_NOTE: uint32_t const  num_groups_x = (buffer_dimensions[0] + num_threads[0] - 1) / num_threads[0];
// DEV_NOTE: uint32_t const  num_groups_y = (buffer_dimensions[1] + num_threads[1] - 1) / num_threads[1];
// DEV_NOTE: find the 4 nearest probes around (jittered) pixel pos and perform a bilateral blur
//           using SH + bent normal/AO to compute diffuse irradiance + optional specular
[numthreads(8, 8, 1)]
void InterpolateScreenProbes(in uint2 did : SV_DispatchThreadID)
{
    float  depth        = g_DepthBuffer.Load(int3(did, 0)).x;
    float3 normal       = g_GeometryNormalBuffer.Load(int3(did, 0)).xyz;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || any(did >= g_BufferDimensions))
    {
        g_GIDenoiser_ColorBuffer[did] = float4(0.0f, 0.0f, 0.0f, 1.0f);

#ifndef DISABLE_SPECULAR_MATERIALS
        g_ReflectionBuffer[did] = float4(0.0f, 0.0f, 0.0f, 1.0f);
#endif // DISABLE_SPECULAR_MATERIALS

        return; // discard sky pixels
    }

    normal = normalize(2.0f * normal - 1.0f);   // recover normal vector

    uint2  pos       = did;
    float2 uv        = (did + 0.5f) / g_BufferDimensions;
    float3 world_pos = InverseProject(g_ViewProjectionInverse, uv, depth);
    float  cell_size = distance(g_Eye, world_pos) * g_ScreenProbesConstants.cell_size;

    // do not use the same seed value with stochastic alpha testing
    float2 s             = BlueNoise_Sample2D(did, g_FrameIndex, 1);
    int2   jitter        = (2.0f * s - 1.0f) * g_ScreenProbesConstants.probe_spawn_tile_size; // DEV_NOTE: integer jitter in [0, probe_spawn_tile_size-1]
    uint2  new_pos       = clamp(int2(did) + jitter, 0, int2(g_BufferDimensions) - 1);
    float2 new_uv        = (new_pos + 0.5f) / g_BufferDimensions;
    float  new_depth     = g_DepthBuffer.Load(int3(new_pos, 0)).x;
    float3 new_world_pos = InverseProject(g_ViewProjectionInverse, new_uv, new_depth);

    if (abs(dot(new_world_pos - world_pos, normal)) < 0.5f * cell_size)
    {
        pos = new_pos;  // only apply the jitter if the new position lies in the original pixel plane
    }

    uint4 probes;   // locate nearby probes for interpolation

    probes.x = ScreenProbes_FindClosestProbe(pos);

    if (probes.x == kGI10_InvalidId)
    {
        g_GIDenoiser_ColorBuffer[did] = float4(0.0f, 0.0f, 0.0f, 1.0f);

#ifndef DISABLE_SPECULAR_MATERIALS
        g_ReflectionBuffer[did] = float4(0.0f, 0.0f, 0.0f, 1.0f);
#endif // DISABLE_SPECULAR_MATERIALS

        return; // couldn't find any nearby probe...
    }

    uint2 seed   = ScreenProbes_UnpackSeed(probes.x);
    int2  offset = int2(pos.x < seed.x ? -1 : 1, pos.y < seed.y ? -1 : 1);

    probes.y = ScreenProbes_FindClosestProbe(pos, int2(offset.x, 0));
    probes.z = ScreenProbes_FindClosestProbe(pos, int2(0, offset.y));
    probes.w = ScreenProbes_FindClosestProbe(pos, offset);

    if (probes.y == probes.x)                                                 probes.y = kGI10_InvalidId;
    if (probes.z == probes.y || probes.z == probes.x)                         probes.z = kGI10_InvalidId;
    if (probes.w == probes.z || probes.w == probes.y || probes.w == probes.x) probes.w = kGI10_InvalidId;

    float4 w = float4(0.0f, 0.0f, 0.0f, 0.0f);  // calculate per-probe blending weights

    for (uint i = 0; i < 4; ++i)
    {
        if (probes[i] != kGI10_InvalidId)
        {
            uint2 probe_seed = ScreenProbes_UnpackSeed(probes[i]);

            float2 probe_uv    = (probe_seed + 0.5f) / g_BufferDimensions;
            float  probe_depth = g_DepthBuffer.Load(int3(probe_seed, 0)).x;
            float3 probe_pos   = InverseProject(g_ViewProjectionInverse, probe_uv, probe_depth);

            if (abs(dot(probe_pos - world_pos, normal)) > cell_size)
                w[i] = 0.0f;    // prevent probes ahead of pixel plane to leak radiance into occluded background
            else
            {
                w[i]  = saturate(1.0f - abs(GetLinearDepth(probe_depth) - GetLinearDepth(depth)) / GetLinearDepth(depth));
                w[i] *= max(dot(normal, normalize(2.0f * g_GeometryNormalBuffer.Load(int3(probe_seed, 0)).xyz - 1.0f)), 0.0f);
                w[i]  = pow(w[i], 8.0f);    // make it steep
            }
        }
    }

    bool use_backup = false;

    if (dot(w, w) == 0.0f)
    {
        w = float4(1.0f, probes.y != kGI10_InvalidId ? 1.0f : 0.0f
                       , probes.z != kGI10_InvalidId ? 1.0f : 0.0f
                       , probes.w != kGI10_InvalidId ? 1.0f : 0.0f);

        use_backup = true;  // for 'relaxed' interpolation in failure cases
    }

    w /= w.x + w.y + w.z + w.w; // weights must sum up to 1

#ifndef HAS_OCCLUSION
    float  ao         = 1.0f;
    float3 irradiance = float3(0.0f, 0.0f, 0.0f);
    normal            = normalize(2.0f * g_ShadingNormalBuffer.Load(int3(did, 0)).xyz - 1.0f);
#else // HAS_OCCLUSION
    float4 ao_and_bent_normal = g_OcclusionAndBentNormalBuffer.Load(int3(did, 0));

    float  ao         = ao_and_bent_normal.w;
    float3 irradiance = g_NearFieldGlobalIlluminationBuffer.Load(int3(did, 0)).rgb;
    normal            = normalize(2.0f * ao_and_bent_normal.xyz - 1.0f);
#endif // HAS_OCCLUSION

    for (uint j = 0; j < 4; ++j)
    {
        uint2 probe = ScreenProbes_UnpackSeed(probes[j]) / g_ScreenProbesConstants.probe_size;

        irradiance += w[j] * ScreenProbes_CalculateSHIrradiance_BentCone(normal, ao, probe);
    }

    float denoiser_hint = (use_backup ? 0.0f : 1.0f);   // hint to the denoiser that we should ideally not keep this sample...

    g_GIDenoiser_ColorBuffer[did] = float4(irradiance, denoiser_hint); // DEV_NOTE(OPTIM): pack into smaller RT format?

    // Perform "specular interpolation" for glossy reflectors
#ifndef DISABLE_SPECULAR_MATERIALS
    {
        float roughness = g_RoughnessBuffer.Load(int3(did, 0)).x;

        if (roughness <= g_GlossyReflectionsConstants.low_roughness_threshold)
        {
            if (GlossyReflections_QueueSample(did))
            {
                uint rt_sample_index;
                InterlockedAdd(g_GlossyReflections_RtSampleCountBuffer[0], 1, rt_sample_index);

                g_GlossyReflections_RtSampleBuffer[rt_sample_index] = GlossyReflections_PackSample(did);
            }

            return; // raytrace low roughness pixels at half resolution
        }
        else if (roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
        {
            g_ReflectionBuffer[did] = float4(irradiance / PI, denoiser_hint);

            return; // fall back to diffuse on high roughness surfaces
        }

        float3 radiance       = float3(0.0f, 0.0f, 0.0f);
        float3 view_direction = normalize(g_Eye - world_pos);
        float3 detail_normal  = normalize(2.0f * g_ShadingNormalBuffer.Load(int3(did, 0)).xyz - 1.0f);

        // Sample specular direction
        Quaternion localRotation = QuaternionRotationZ(detail_normal);
        float3 localView = localRotation.transform(view_direction);
        float roughnessAlpha = max(0.000001f, squared(roughness));
        float3 newLight = sampleGGX(roughnessAlpha, localView, s);
        float3 direction = normalize(localRotation.inverse().transform(newLight));

        for (uint k = 0; k < 4; ++k)
        {
            uint2  probe_seed      = ScreenProbes_UnpackSeed(probes[k]);
            float3 probe_normal    = normalize(2.0f * g_GeometryNormalBuffer.Load(int3(probe_seed, 0)).xyz - 1.0f);

            // Ignore directions in -Z hemisphere
            if (dot(direction, probe_normal) < 0.0f)
                continue;
            float3 probe_direction = mul(direction, CreateTBN(probe_normal));

            float2 probe_uv   = mapToHemiOctahedron(probe_direction);
            uint2  probe_tile = (probe_seed / g_ScreenProbesConstants.probe_size);
            uint2  probe_pos  = (probe_tile * g_ScreenProbesConstants.probe_size) + uint2(probe_uv * g_ScreenProbesConstants.probe_size);

            radiance += w[k] * g_ScreenProbes_ProbeBuffer[probe_pos].xyz;
        }

        radiance.xyz /= (1.0f + radiance.xyz);

        if (g_GlossyReflectionsConstants.half_res && GlossyReflections_QueueSample(did))
        {
            g_GlossyReflections_SpecularBuffer[did >> 1]  = float4(radiance, denoiser_hint);
            g_GlossyReflections_DirectionBuffer[did >> 1] = float4(direction, 0.f);             // BE CAREFUL: no parallax correction
        }
        else
        {
            g_GlossyReflections_SpecularBuffer[did]  = float4(radiance, denoiser_hint);
            g_GlossyReflections_DirectionBuffer[did] = float4(direction, 0.f);                  // BE CAREFUL: no parallax correction
        }
    }
#endif // DISABLE_SPECULAR_MATERIALS
}

//!
//! Hash-grid cache kernels.
//!

[numthreads(64, 1, 1)]
void PurgeTiles(in uint did : SV_DispatchThreadID)
{
    if (did >= g_HashGridCache_PreviousPackedTileCountBuffer[0])
    {
        return; // out of bounds
    }

    // We opt for calculating the decay of each tile from the
    // current frame index, as it saves many writes per frame
    // and is quite a bit faster than having to decrement all
    // cell's decay values.
    uint tile_index = g_HashGridCache_PreviousPackedTileIndexBuffer[did];
    uint tile_decay = g_HashGridCache_DecayTileBuffer[tile_index];

    if (g_FrameIndex < tile_decay)   // account for integer wraparound case
    {
        tile_decay = ((0xFFFFFFFFu - tile_decay) + g_FrameIndex + 1);
    }
    else
    {
        tile_decay = (g_FrameIndex - tile_decay);
    }

    if (tile_decay >= kHashGridCache_TileDecay)
    {
        g_HashGridCache_HashBuffer[tile_index] = 0;

#ifdef DEBUG_HASH_CELLS
        // Clear all mipmaps
        for (int cell_offset = 0; cell_offset < g_HashGridCacheConstants.num_cells_per_tile; ++cell_offset)
        {
            uint cell_index = HashGridCache_CellIndex(cell_offset, tile_index);
            g_HashGridCache_DecayCellBuffer[cell_index] = 0xFFFFFFFFu;
        }
#endif // DEBUG_HASH_CELLS

        return; // kill the tile
    }

    uint packed_tile_index;
    InterlockedAdd(g_HashGridCache_PackedTileCountBuffer[0], 1, packed_tile_index);
    g_HashGridCache_PackedTileIndexBuffer[packed_tile_index] = tile_index;
}

// DEV_NOTE: hit means "shadowed"
void PopulateCellsHandleHit(uint did, inout PopulateCellsPayload payload, RayDesc ray)
{
    payload.lighting    = float3(0.0f, 0.0f, 0.0f);

    Reservoir reservoir = payload.reservoir;
    // Update our reservoir cache for next frame's temporal resampling
#ifdef USE_RESAMPLING
    reservoir.W = 0.0f; // invalidate the reservoir

    g_Reservoir_IndirectSampleReservoirBuffer[did] = packReservoir(reservoir);
#endif // USE_RESAMPLING
}

// DEV_NOTE: miss means "light is visible"
void PopulateCellsHandleMiss(uint did, inout PopulateCellsPayload payload, RayDesc ray)
{
    float3       light_radiance = payload.lighting;
    float        light_weight   = payload.reservoir.W;
    uint         probe_index    = ScreenProbes_GetCellAndProbeIndex(payload.query_index).y;
    uint2        seed           = ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]);

    // DEV_NOTE: a "compressed" material representation is refetched here (stored in 'GenerateReservoirs')
    MaterialBRDF material       = unpackMaterial(g_Reservoir_IndirectSampleMaterialBuffer[did]);

    // Recover the ray origin
    float  depth  = g_DepthBuffer.Load(int3(seed, 0)).x;
    float2 uv     = (seed + 0.5f) / g_BufferDimensions;
    float3 origin = InverseProject(g_ViewProjectionInverse, uv, depth);

    // And evaluate our lighting
    payload.lighting =
        evaluateBRDF(material, payload.normal, normalize(origin - payload.world), ray.Direction)
        * light_radiance * light_weight;
}

void PopulateCellsTraceRayInline(uint did, inout PopulateCellsPayload payload, RayDesc ray)
{
    ShadowRayQuery ray_query = TraceRay<ShadowRayQuery>(ray);

    if (ray_query.CommittedStatus() == COMMITTED_NOTHING)
    {
        PopulateCellsHandleMiss(did, payload, ray);
    }
    else
    {
        PopulateCellsHandleHit(did, payload, ray);
    }
}

void PopulateCellsTraceRayRt(uint did, inout PopulateCellsPayload payload, RayDesc ray)
{
    TraceRay(g_Scene, RAY_FLAG_ACCEPT_FIRST_HIT_AND_END_SEARCH, 0xFFu, 0, 0, 0, ray, payload);
}

void PopulateCellsTraceRay(uint did, inout PopulateCellsPayload payload, RayDesc ray)
{
#if USE_INLINE_RT
    return PopulateCellsTraceRayInline(did, payload, ray);
#else
    return PopulateCellsTraceRayRt(did, payload, ray);
#endif
}

void PopulateCells(uint did)
{
    if (did >= g_HashGridCache_VisibilityRayCountBuffer[0])
    {
        return; // out of bounds
    }

    // DEV_NOTE: 0x80000000u is used as a flag to bypass radiance cache
    uint                     visibility_index = (g_HashGridCache_VisibilityRayBuffer[did] & ~0x80000000u);
    HashGridCache_Visibility visibility       = HashGridCache_UnpackVisibility(g_HashGridCache_VisibilityBuffer[visibility_index]);

    uint query_index = g_HashGridCache_VisibilityQueryBuffer[visibility_index];

    // Reconstruct world-space position and normal
    Instance instance  = g_InstanceBuffer[visibility.instance_index];
    Mesh     mesh      = g_MeshBuffer[instance.mesh_index + visibility.geometry_index];
    float3x4 transform = g_TransformBuffer[instance.transform_index];

    Triangle vertices = fetchVertices(mesh, visibility.primitive_index);

    vertices.v0 = transformPoint(vertices.v0, transform) - g_PreViewTranslation;
    vertices.v1 = transformPoint(vertices.v1, transform) - g_PreViewTranslation;
    vertices.v2 = transformPoint(vertices.v2, transform) - g_PreViewTranslation;
    float3 world = interpolate(vertices.v0, vertices.v1, vertices.v2, visibility.barycentrics);
    float3 edge10 = vertices.v1 - vertices.v0;
    float3 edge20 = vertices.v2 - vertices.v0;
    float3 normal = normalize(transformNormal(cross(edge10, edge20) * (visibility.is_front_face ? 1.0f : -1.0f), transform));

    // Retrieve the light sample that we should use for our shadow ray
    Reservoir reservoir    = unpackReservoir(g_Reservoir_IndirectSampleReservoirBuffer[did]);

    // Decode the light sample from our reservoir
    float3 direction, light_position;
    // Approximate visible light surface based on number of samples being used
    // DEV_NOTE: the solid_angle is use to compute the ray "angular footprint" in order to sample the proper mip level (for area lights and env maps)
    const float solid_angle = FOUR_PI / (kReservoir_SampleCount * 12000.0f); // DEV_NOTE(QUESTION): why 12000.f?
    Light selected_light = getLight(reservoir.lightSample.index);
    float3 light_radiance = evaluateLightConeSampled(selected_light, world, reservoir.lightSample.sampleParams, solid_angle, direction, light_position);

    // DEV_NOTE: shadow ray

    // Traverse the BVH
    RayDesc ray_desc;
    ray_desc.Direction = direction;
    ray_desc.Origin    = offsetPosition(world + g_PreViewTranslation, normal);
    ray_desc.TMin      = 0.0f;
    ray_desc.TMax      = hasLightPosition(selected_light) ? length(light_position - ray_desc.Origin) : FLT_MAX; // DEV_NOTE: FLT_MAX -> directional light

    PopulateCellsPayload payload;
    payload.query_index = query_index;
    payload.world       = world;
    payload.normal      = normal;
    payload.lighting    = light_radiance;
    payload.reservoir   = reservoir;
    PopulateCellsTraceRay(did, payload, ray_desc);

    // And update the hash-grid cell payload
    uint  cell_index         = g_HashGridCache_VisibilityCellBuffer[visibility_index]; // DEV_NOTE: index of cell in hash grid

    // DEV_NOTE: uint4 HashGridCache_QuantizeRadiance(in float3 radiance)
    //           {
    //               return uint4(uint(round(kHashGridCache_FloatQuantize * radiance.x)),
    //                            uint(round(kHashGridCache_FloatQuantize * radiance.y)),
    //                            uint(round(kHashGridCache_FloatQuantize * radiance.z)), 1);
    //           }
    uint4 quantized_radiance = HashGridCache_QuantizeRadiance(payload.lighting);

    if (dot(payload.lighting, payload.lighting) > 0.0f) // DEV_NOTE: check non-zero radiance
    {
        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 0], quantized_radiance.x);
        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 1], quantized_radiance.y);
        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 2], quantized_radiance.z);
    }

    // DEV_NOTE: quantized_radiance.w contains 1, so its count the number of samples accumulated
    InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 3], quantized_radiance.w);

    // In some cases, we want to bypass the cache to avoid light leaks;
    // so we simply patch the screen probes directly and invalidate the
    // cache connection.
    // DEV_NOTE: correspond flag set in 'GenerateReservoirs' to bypass cache when distance to surface smaller that grid cell
    // if (ray_length < cell_size)
    // {
    //     g_HashGridCache_VisibilityRayBuffer[ray_index] |= 0x80000000u;
    // }
    bool is_bypass_cache = ((g_HashGridCache_VisibilityRayBuffer[did] >> 31) != 0);

    if (is_bypass_cache)
    {
        // DEV_NOTE: // Removes NaNs from the color values.
        //           float4 GIDenoiser_RemoveNaNs(in float4 color)
        //           {
        //               color /= (1.0f + color);
        //               color  = saturate(color);
        //               color /= max(1.0f - color, 1e-4f);
        //           
        //               return color;
        //           }
        // DEV_NOTE: directly fill screen-space probe buffer radiance
        //           void ScreenProbes_AccumulateRadiance(in uint query_index, in float3 radiance)
        //           {
        //               if (dot(radiance, radiance) > 0.0f) // avoid accumulating null contribution(s)
        //               {
        //                   float4 radiance_and_ray_distance = ScreenProbes_UnpackRadiance(g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index]);
        //           
        //                   radiance_and_ray_distance.xyz += radiance;  // accumulate contribution
        //           
        //                   g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index] = ScreenProbes_PackRadiance(radiance_and_ray_distance);
        //               }
        //           }
        ScreenProbes_AccumulateRadiance(query_index, GIDenoiser_RemoveNaNs(payload.lighting));
    }
}

[numthreads(32, 1, 1)]
void PopulateCellsMain(in uint did : SV_DispatchThreadID)
{
    PopulateCells(did);
}

// BE CAREFUL: we assume
//             UPDATE_TILES_NOT_SLICED_GROUP_* >= g_HashGridCacheConstants.size_tile_mip0
//             UPDATE_TILES_NOT_SLICED_GROUP_*  % g_HashGridCacheConstants.size_tile_mip0 == 0
//
#define UPDATE_TILES_GROUP_X 8
#define UPDATE_TILES_GROUP_Y 8
#define UPDATE_TILES_GROUP_SIZE (UPDATE_TILES_GROUP_X * UPDATE_TILES_GROUP_Y)

groupshared uint2 lds_UpdateTiles_ValueBuffer[UPDATE_TILES_GROUP_X][UPDATE_TILES_GROUP_Y];

[numthreads(1, 1, 1)]
void GenerateUpdateTilesDispatch()
{
    uint num_tiles_by_group = UPDATE_TILES_GROUP_SIZE / g_HashGridCacheConstants.num_cells_per_tile_mip0;

    DispatchCommand dispatch_command;
    dispatch_command.num_groups_x = (g_HashGridCache_UpdateTileCountBuffer[0] + num_tiles_by_group - 1) / num_tiles_by_group;
    dispatch_command.num_groups_y = 1;
    dispatch_command.num_groups_z = 1;
    dispatch_command.padding = 0;
    g_DispatchCommandBuffer[0] = dispatch_command;
}

[numthreads(UPDATE_TILES_GROUP_X, UPDATE_TILES_GROUP_Y, 1)]
void UpdateTiles(in uint group_id : SV_GroupID, in uint2 group_thread_id : SV_GroupThreadID)
{
    // A group cover from 1 tile/subgroup (8x8) to 64 tiles/subgroups (1x1)
    uint2 subgroup_id        = group_thread_id / g_HashGridCacheConstants.size_tile_mip0;
    uint2 subgroup_thread_id = group_thread_id % g_HashGridCacheConstants.size_tile_mip0;
    uint2 subgroup_size      = uint2(UPDATE_TILES_GROUP_X, UPDATE_TILES_GROUP_Y) / g_HashGridCacheConstants.size_tile_mip0;
    uint  update_tile_index  = group_id * subgroup_size.x * subgroup_size.y +
                               subgroup_id.y * subgroup_size.x +
                               subgroup_id.x;

    if (update_tile_index >= g_HashGridCache_UpdateTileCountBuffer[0])
    {
        return;
    }

    uint tile_index = g_HashGridCache_UpdateTileBuffer[update_tile_index];

    // MIP 0
    {
        uint cell_index  = HashGridCache_CellIndex(subgroup_thread_id, tile_index, 0);

        // Temporal accumulation
        float4 radiance     = HashGridCache_UnpackRadiance(g_HashGridCache_ValueBuffer[cell_index]);
        float4 new_radiance = HashGridCache_RecoverRadiance(uint4(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 0],
                                                                  g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 1],
                                                                  g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 2],
                                                                  g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 3]));

        float sample_count = min(radiance.w + new_radiance.w, g_HashGridCacheConstants.max_sample_count);

        radiance     /= max(radiance.w, 1.0f);
        new_radiance /= max(new_radiance.w, 1.0f);

        if (radiance.w <= 0.0f)
        {
            radiance = new_radiance;
        }
        else
        {
            radiance = lerp(radiance, new_radiance, 1.0f / sample_count);
        }

        // DEV_NOTE: some kind of "premultiply" -> properly weighted sum when averaging (when generating the mips)
        radiance *= sample_count;   // sample count is used as a hint for picking prefiltering amount

        // Pack
        uint2 packed_radiance = HashGridCache_PackRadiance(radiance);
        lds_UpdateTiles_ValueBuffer[group_thread_id.x][group_thread_id.y] = packed_radiance;
        g_HashGridCache_ValueBuffer[cell_index] = packed_radiance;

        // Clear scratch
        g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 0] = 0;
        g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 1] = 0;
        g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 2] = 0;
        g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 3] = 0;
    }

    // MIP 1
    GroupMemoryBarrierWithGroupSync();
    [branch]
    if(g_HashGridCacheConstants.size_tile_mip1 > 0 && all((group_thread_id % 2) == 0))
    {
        uint cell_index = HashGridCache_CellIndex(subgroup_thread_id, tile_index, 1);

        // Box filter
        uint2 packed_radiance00 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 0];
        uint2 packed_radiance10 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 1][group_thread_id.y + 0];
        uint2 packed_radiance01 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 1];
        uint2 packed_radiance11 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 1][group_thread_id.y + 1];

        float4 radiance = float4(0.f, 0.f, 0.f, 0.f);
        radiance += HashGridCache_UnpackRadiance(packed_radiance00);
        radiance += HashGridCache_UnpackRadiance(packed_radiance10);
        radiance += HashGridCache_UnpackRadiance(packed_radiance01);
        radiance += HashGridCache_UnpackRadiance(packed_radiance11);

        // Pack
        uint2 packed_radiance = HashGridCache_PackRadiance(radiance);
        lds_UpdateTiles_ValueBuffer[group_thread_id.x][group_thread_id.y] = packed_radiance;
        g_HashGridCache_ValueBuffer[cell_index] = packed_radiance;
    }

    // MIP 2
    GroupMemoryBarrierWithGroupSync();
    [branch]
    if(g_HashGridCacheConstants.size_tile_mip2 > 0 && all((group_thread_id % 4) == 0))
    {
        uint cell_index = HashGridCache_CellIndex(subgroup_thread_id, tile_index, 2);

        // Box filter
        uint2 packed_radiance00 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 0];
        uint2 packed_radiance20 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 2][group_thread_id.y + 0];
        uint2 packed_radiance02 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 2];
        uint2 packed_radiance22 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 2][group_thread_id.y + 2];

        float4 radiance = float4(0.f, 0.f, 0.f, 0.f);
        radiance += HashGridCache_UnpackRadiance(packed_radiance00);
        radiance += HashGridCache_UnpackRadiance(packed_radiance20);
        radiance += HashGridCache_UnpackRadiance(packed_radiance02);
        radiance += HashGridCache_UnpackRadiance(packed_radiance22);

        // Pack
        uint2 packed_radiance = HashGridCache_PackRadiance(radiance);
        lds_UpdateTiles_ValueBuffer[group_thread_id.x][group_thread_id.y] = packed_radiance;
        g_HashGridCache_ValueBuffer[cell_index] = packed_radiance;
    }

    // MIP 3
    GroupMemoryBarrierWithGroupSync();
    [branch]
    if(g_HashGridCacheConstants.size_tile_mip3 > 0 && all((group_thread_id % 8) == 0))
    {
        uint cell_index = HashGridCache_CellIndex(subgroup_thread_id, tile_index, 3);

        // Box filter
        uint2 packed_radiance00 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 0];
        uint2 packed_radiance40 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 4][group_thread_id.y + 0];
        uint2 packed_radiance04 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 0][group_thread_id.y + 4];
        uint2 packed_radiance44 = lds_UpdateTiles_ValueBuffer[group_thread_id.x + 4][group_thread_id.y + 4];

        float4 radiance = float4(0.f, 0.f, 0.f, 0.f);
        radiance += HashGridCache_UnpackRadiance(packed_radiance00);
        radiance += HashGridCache_UnpackRadiance(packed_radiance40);
        radiance += HashGridCache_UnpackRadiance(packed_radiance04);
        radiance += HashGridCache_UnpackRadiance(packed_radiance44);

        // Pack
        g_HashGridCache_ValueBuffer[cell_index] = HashGridCache_PackRadiance(radiance);
    }
}

[numthreads(64, 1, 1)]
void ResolveCells(in uint did : SV_DispatchThreadID)
{
    if (did >= g_HashGridCache_VisibilityRayCountBuffer[0])
    {
        return; // out of bounds
    }

    uint visibility_index = g_HashGridCache_VisibilityRayBuffer[did];

    if ((visibility_index >> 31) != 0)
    {
        return; // do not use filtered radiance
    }

    uint cell_index  = g_HashGridCache_VisibilityCellBuffer[visibility_index];
    uint query_index = g_HashGridCache_VisibilityQueryBuffer[visibility_index];

    // DEV_NOTE: Select the "best mip", i.e the highest resolution that has an "effective" sample count above a threshold
    //          float4 HashGridCache_FilteredRadiance(uint cell_index_mip0, bool debug_mip_level)
    //          {
    //              uint2 cell_offset_mip0;
    //              uint  tile_index      = HashGridCache_CellOffsetMip0(cell_index_mip0, cell_offset_mip0);
    //              uint  cell_index_mip1 = g_HashGridCacheConstants.size_tile_mip1 > 0 ? HashGridCache_CellIndex(cell_offset_mip0, tile_index, 1) : kGI10_InvalidId;
    //              uint  cell_index_mip2 = g_HashGridCacheConstants.size_tile_mip2 > 0 ? HashGridCache_CellIndex(cell_offset_mip0, tile_index, 2) : kGI10_InvalidId;
    //              uint  cell_index_mip3 = g_HashGridCacheConstants.size_tile_mip3 > 0 ? HashGridCache_CellIndex(cell_offset_mip0, tile_index, 3) : kGI10_InvalidId;
    //          
    //              // Select best mip
    //              float4 radiance;
    //              bool   use_mip;
    //          
    //              // Mip 0
    //              radiance = HashGridCache_UnpackRadiance(g_HashGridCache_ValueBuffer[cell_index_mip0]);
    //              radiance = debug_mip_level            ? float4(HashGridCache_HeatColor(1.000f), radiance.w) : radiance;
    //          
    //              // Mip 1
    //              use_mip  = radiance.w < g_HashGridCacheConstants.max_sample_count && cell_index_mip1 != kGI10_InvalidId;
    //              radiance = use_mip ? HashGridCache_UnpackRadiance(g_HashGridCache_ValueBuffer[cell_index_mip1]) : radiance;
    //              radiance = debug_mip_level && use_mip ? float4(HashGridCache_HeatColor(0.666f), radiance.w) : radiance;
    //          
    //              // Mip 2
    //              use_mip  = radiance.w < g_HashGridCacheConstants.max_sample_count && cell_index_mip2 != kGI10_InvalidId;
    //              radiance = use_mip ? HashGridCache_UnpackRadiance(g_HashGridCache_ValueBuffer[cell_index_mip2]) : radiance;
    //              radiance = debug_mip_level && use_mip ? float4(HashGridCache_HeatColor(0.333f), radiance.w) : radiance;
    //          
    //              // Mip 3
    //              use_mip  = radiance.w < g_HashGridCacheConstants.max_sample_count && cell_index_mip3 != kGI10_InvalidId;
    //              radiance = use_mip ? HashGridCache_UnpackRadiance(g_HashGridCache_ValueBuffer[cell_index_mip3]) : radiance;
    //              radiance = debug_mip_level && use_mip ? float4(HashGridCache_HeatColor(0.000f), radiance.w) : radiance;
    //          
    //              // Done
    //              return radiance;
    //          }
    float4 radiance = HashGridCache_FilteredRadiance(cell_index, false);

    // DEV_NOTE: average accumulated samples (radiance.w contains the number of accumulated samples)
    // DEV_NOTE: directly fill screen-space probe buffer radiance
    //           void ScreenProbes_AccumulateRadiance(in uint query_index, in float3 radiance)
    //           {
    //               if (dot(radiance, radiance) > 0.0f) // avoid accumulating null contribution(s)
    //               {
    //                   float4 radiance_and_ray_distance = ScreenProbes_UnpackRadiance(g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index]);
    //           
    //                   radiance_and_ray_distance.xyz += radiance;  // accumulate contribution
    //           
    //                   g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index] = ScreenProbes_PackRadiance(radiance_and_ray_distance);
    //               }
    //           }
    ScreenProbes_AccumulateRadiance(query_index, radiance.xyz / max(radiance.w, 1.0f));
}

//!
//! World-space ReSTIR kernels.
//!

[numthreads(64, 1, 1)]
void ClearReservoirs(in uint did : SV_DispatchThreadID)
{
    g_Reservoir_HashBuffer[did]      = 0;
    g_Reservoir_HashCountBuffer[did] = 0;
}

[numthreads(64, 1, 1)]
void GenerateReservoirs(in uint did : SV_DispatchThreadID)
{
    if (did >= g_HashGridCache_VisibilityCountBuffer[0])
    {
        return; // out of bounds
    }

    // Load our visibility sample
    float4                   packed_visibility = g_HashGridCache_VisibilityBuffer[did];
    HashGridCache_Visibility visibility        = HashGridCache_UnpackVisibility(packed_visibility);

    // Reconstruct world-space position and normal
    Instance instance  = g_InstanceBuffer[visibility.instance_index];
    Mesh     mesh      = g_MeshBuffer[instance.mesh_index + visibility.geometry_index];
    float3x4 transform = g_TransformBuffer[instance.transform_index];

    TriangleNormUV vertices = fetchVerticesNormUV(mesh, visibility.primitive_index);

    vertices.v0 = transformPoint(vertices.v0, transform) - g_PreViewTranslation;
    vertices.v1 = transformPoint(vertices.v1, transform) - g_PreViewTranslation;
    vertices.v2 = transformPoint(vertices.v2, transform) - g_PreViewTranslation;

    vertices.n0 = transformNormal(vertices.n0, transform);
    vertices.n1 = transformNormal(vertices.n1, transform);
    vertices.n2 = transformNormal(vertices.n2, transform);

    // DEV_NOTE: world radiance cache position
    float3   world    =                                                       interpolate(vertices.v0, vertices.v1, vertices.v2, visibility.barycentrics);
    float3   normal   = (visibility.is_front_face ? 1.0f : -1.0f) * normalize(interpolate(vertices.n0, vertices.n1, vertices.n2,   visibility.barycentrics));
    Material material = g_MaterialBuffer[instance.material_index];

    // Recover the ray origin
    uint query_index = g_HashGridCache_VisibilityQueryBuffer[did];
    uint probe_index = ScreenProbes_GetCellAndProbeIndex(query_index).y;

    // DEV_NOTE: (scene) pixel coords of the origin probe
    uint2  seed    = ScreenProbes_UnpackSeed(g_ScreenProbes_ProbeSpawnBuffer[probe_index]);
    float  depth   = g_DepthBuffer.Load(int3(seed, 0)).x;
    float2 uv      = (seed + 0.5f) / g_BufferDimensions;
    float3 origin  = InverseProject(g_ViewProjectionInverse, uv, depth); // DEV_NOTE: world space position of origin probe
    float2 mesh_uv = interpolate(vertices.uv0, vertices.uv1, vertices.uv2, visibility.barycentrics);

    // Patch the screen probes with some emissivity information:
    // We bypass the hash-grid cache entirely here, as adding emissive information to the cells
    // effectively enlarges the area light (due to the spatial nature of the grid) and leads to
    // light leaks and generally poorer visuals.
    // DEV_NOTE(QUESTION): so the world-space hashgrid does not contain any emissive?
    if (g_UseDirectLighting != 0 && visibility.is_front_face && dot(material.emissivity.xyz, material.emissivity.xyz) > 0.0f)
    {
        MaterialEmissive emissive = MakeMaterialEmissive(material, mesh_uv);

        // DEV_NOTE: directly fill screen-space probe buffer radiance
        //           void ScreenProbes_AccumulateRadiance(in uint query_index, in float3 radiance)
        //           {
        //               if (dot(radiance, radiance) > 0.0f) // avoid accumulating null contribution(s)
        //               {
        //                   float4 radiance_and_ray_distance = ScreenProbes_UnpackRadiance(g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index]);
        //           
        //                   radiance_and_ray_distance.xyz += radiance;  // accumulate contribution
        //           
        //                   g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index] = ScreenProbes_PackRadiance(radiance_and_ray_distance);
        //               }
        //           }
        ScreenProbes_AccumulateRadiance(query_index, emissive.emissive);

        return; // do not continue past an emissive surface
    }

    // We can perform some temporal radiance feedback from last frame if direct lighting was
    // evaluated.
    // If successful, we inject the reprojected radiance into the cache so it can be re-used
    // by neighbor vertices but bypass the filtered readback as the sample is already denoised.
    // DEV_NOTE: check if the world-space radiance cache sample position is on screen, then it tries to find it in the previous
    // frame and sample the previous frame illumination buffer to add it to the cache (hence the "temporal radiance feedback")
    if (g_UseDirectLighting != 0)
    {
        // DEV_NOTE(QUESTION): project the world radiance cache position onto the screen?
        float3 homogeneous = transformPointProjection(world, g_ViewProjection);

        uv    = 0.5f * float2(homogeneous.x, -homogeneous.y) + 0.5f;
        depth = homogeneous.z;

        // DEV_NOTE(QUESTION): check if the projected world radiance cache position is inside the view volume?
        if (all(uv > 0.0f) && all(uv < 1.0f) && depth > 0.0f && depth < 1.0f)
        {
            float2 previous_uv = uv - g_VelocityBuffer.SampleLevel(g_NearestSampler, uv, 0.0f).xy;

            if (all(previous_uv > 0.0f) && all(previous_uv < 1.0f))
            {
                float3 homogeneous2 = transformPointProjection(float3(2.0f * float2(uv.x, 1.0f - uv.y) - 1.0f, depth), g_Reprojection);
                homogeneous2.z      = GetLinearDepth(homogeneous2.z);

                float  previous_depth  = GetLinearDepth(g_PreviousDepthBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).x);
                float3 previous_normal = normalize(2.0f * g_PreviousNormalBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).xyz - 1.0f);

                if (dot(previous_normal, normal) > 5e-1f && abs(previous_depth - homogeneous2.z) / homogeneous2.z < 5e-2f)
                {
                    // DEV_NOTE: sample previous frame resolved illumination buffer
                    float3 previous_lighting = g_PrevCombinedIlluminationBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).xyz;

                    uint  cell_index         = g_HashGridCache_VisibilityCellBuffer[did];
                    // DEV_NOTE: uint4 HashGridCache_QuantizeRadiance(in float3 radiance)
                    //           {
                    //               return uint4(uint(round(kHashGridCache_FloatQuantize * radiance.x)),
                    //                            uint(round(kHashGridCache_FloatQuantize * radiance.y)),
                    //                            uint(round(kHashGridCache_FloatQuantize * radiance.z)), 1);
                    //           }
                    uint4 quantized_radiance = HashGridCache_QuantizeRadiance(previous_lighting);

                    // DEV_NOTE: directly fill screen-space probe buffer radiance
                    // void ScreenProbes_AccumulateRadiance(in uint query_index, in float3 radiance)
                    // {
                    //     if (dot(radiance, radiance) > 0.0f) // avoid accumulating null contribution(s)
                    //     {
                    //         float4 radiance_and_ray_distance = ScreenProbes_UnpackRadiance(g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index]);
                    // 
                    //         radiance_and_ray_distance.xyz += radiance;  // accumulate contribution
                    // 
                    //         g_ScreenProbes_ProbeSpawnRadianceBuffer[query_index] = ScreenProbes_PackRadiance(radiance_and_ray_distance);
                    //     }
                    // }
                    ScreenProbes_AccumulateRadiance(query_index, previous_lighting);

                    if (dot(previous_lighting, previous_lighting) > 0.0f) // DEV_NOTE: check non-zero radiance
                    {
                        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 0], quantized_radiance.x);
                        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 1], quantized_radiance.y);
                        InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 2], quantized_radiance.z);
                    }

                    // DEV_NOTE: quantized_radiance.w contains 1, so its count the number of samples accumulated
                    InterlockedAdd(g_HashGridCache_UpdateCellValueBuffer[4 * cell_index + 3], quantized_radiance.w);

                    return; // we can skip the shadow ray for this sample :)
                }
            }
        }
    }

    float3 view_direction = normalize(origin - world);
    
    // DEV_NOTE: sample a light using reservoir sampling
 
    // Sample new lights
    const float solid_angle = FOUR_PI / (kReservoir_SampleCount * 1.5f);
    MaterialEvaluated material2 = MakeMaterialEvaluated(material, mesh_uv);
#ifndef DISABLE_SPECULAR_MATERIALS
    // Force diffuse lighting on secondary bounce to reduce noise
    material2.metallicity = 0.0f;
    material2.roughness = 1.0f;
#endif // DISABLE_SPECULAR_MATERIALS
    MaterialBRDF materialBRDF = MakeMaterialBRDF(material2);
    Random random = MakeRandom(did, g_FrameIndex);
    LightSampler lightSampler = MakeLightSampler(random);
    Reservoir reservoir = lightSampler.sampleLightListCone<kReservoir_SampleCount>( world, normal, view_direction, solid_angle, materialBRDF);

    if (!reservoir.isValid())
    {
        return;
    }

    // Append our resampled shadow ray
    uint ray_index;
    InterlockedAdd(g_HashGridCache_VisibilityRayCountBuffer[0], 1, ray_index);

    g_HashGridCache_VisibilityRayBuffer[ray_index] = did;   // compact the surviving shadow rays

    // Here, we check that the ray has traversed at least a full hash cell
    // before hitting something.
    // If it hasn't, we bypass the filtering from the cache (although we
    // still accumulate the contribution into the cell).
    //
    // This avoids possible light leaks in the following configuration:
    //
    //    bright area   +--------------+
    //                  |    dark area |
    //                  | |            |
    //                  | x            |
    //                  |/|            |
    //                 /|\             |
    //                / | eye          |
    // bright radiance  +--------------+
    //
    // Here the point 'x' is reached after bouncing from the first vertex.
    // (i.e., it is a 2nd vertex, the ones filtered through the hash grid)
    // Because it is close to the wall and has a similar direction to the
    // 'bright radiance' event, both vertices will share the same hash cell
    // leading to a light leak on the bounced lighting from the inner wall.
    //
    // Such a scenario mostly occurs if the length of the ray connecting
    // the 2nd vertex is less than the size of the hash cell being used.
    // So, we detect this case and flag a bypass of the filtered readback.
    float cell_size  = HashGridCache_GetCellSize(world);
    float ray_length = distance(origin, world);

    if (ray_length < cell_size)
    {
        g_HashGridCache_VisibilityRayBuffer[ray_index] |= 0x80000000u;
    }

    // Insert the reservoir into the hash table
#ifdef USE_RESAMPLING
    float3 b1, b2;
    GetOrthoVectors(normal, b1, b2);
    float2 jitter = 2.0f * random.rand2() - 1.0f;
    jitter *= Reservoir_GetCellSize(world) * kReservoir_SpatialJitter;
    Reservoir_InsertEntry(ray_index, world + jitter.x * b1 + jitter.y * b2);

    g_Reservoir_IndirectSampleBuffer[ray_index]       = Reservoir_PackIndirectSample(origin, world);
    g_Reservoir_IndirectSampleNormalBuffer[ray_index] = packNormal(normal);
#endif // USE_RESAMPLING

    // Write the results out to memory
    g_Reservoir_IndirectSampleMaterialBuffer[ray_index]  = packMaterial(material2);  // cannot afford to re-fetch the full material each time, so we need to approximate it...
    g_Reservoir_IndirectSampleReservoirBuffer[ray_index] = packReservoir(reservoir);
}

[numthreads(64, 1, 1)]
void CompactReservoirs(in uint did : SV_DispatchThreadID)
{
    if (did >= g_Reservoir_HashListCountBuffer[0])
    {
        return; // out of bounds
    }

    uint4 list_element = g_Reservoir_HashListBuffer[did];
    uint  value_index  = g_Reservoir_HashIndexBuffer[list_element.y] + list_element.z;

    g_Reservoir_HashValueBuffer[value_index] = list_element.x;
}

[numthreads(64, 1, 1)]
void ResampleReservoirs(in uint did : SV_DispatchThreadID)
{
    if (did >= g_HashGridCache_VisibilityRayCountBuffer[0])
    {
        return; // out of bounds
    }

    // Load our shading information
    float3 origin, world;
    Reservoir_UnpackIndirectSample(g_Reservoir_IndirectSampleBuffer[did], origin, world);

    float3       normal    = unpackNormal(g_Reservoir_IndirectSampleNormalBuffer[did]);
    MaterialBRDF material  = unpackMaterial(g_Reservoir_IndirectSampleMaterialBuffer[did]);
    Reservoir    reservoir = unpackReservoir(g_Reservoir_IndirectSampleReservoirBuffer[did]);

    // Normalize the sample count M (a.k.a. confidence weight) with the initial sample count for simplicity.
    reservoir.M = 1.0f;

    Random random = MakeRandom(did, g_FrameIndex);

    // Locate our hash table cell
    float3 b1, b2;
    GetOrthoVectors(normal, b1, b2);
    float2 jitter = 2.0f * random.rand2() - 1.0f;
    jitter *= Reservoir_GetCellSize(world) * kReservoir_SpatialJitter;
    uint entry_index = Reservoir_FindPreviousEntry(world + jitter.x * b1 + jitter.y * b2);

    if (entry_index == kGI10_InvalidId)
    {
        return; // no previous reservoir cell - temporal resampling failed :'(
    }

    uint index = g_Reservoir_PreviousHashIndexBuffer[entry_index];
    uint count = g_Reservoir_PreviousHashCountBuffer[entry_index];

    // Stochastically iterate the cell content
    uint max_count = 4;
    uint increment = (count + max_count - 1) / max_count;
    uint offset    = random.randInt(increment);

    // And combine the reservoirs
    float3 view_direction = normalize(origin - world);
    const float solid_angle = FOUR_PI / (kReservoir_SampleCount * 12000.0f);
    ReservoirUpdater updater = MakeReservoirUpdater();
    mergeReservoirsCone(updater, reservoir, random, material, world, normal, view_direction, solid_angle);
    for (uint i = 0; i < count; i += increment)
    {
        // Load up the iterated reservoir
        uint      reservoir_index = g_Reservoir_PreviousHashValueBuffer[index + ((i + offset) % count)];
        Reservoir reservoir2      = unpackReservoir(g_Reservoir_PreviousIndirectSampleReservoirBuffer[reservoir_index]);
        float3    filter_normal   = unpackNormal(g_Reservoir_PreviousIndirectSampleNormalBuffer[reservoir_index]);

        if (!reservoir2.isValid())
        {
            continue;   // skip invalid reservoir(s)
        }

        // Bilaterally filter the neighbor reservoir
        float bilateral_weight = max(dot(normal, filter_normal), 0.0f);
        bilateral_weight = squared(squared(bilateral_weight)); // make it steep
        if (bilateral_weight < kReservoir_BilateralThreshold) continue;

        // And combine it with our current reservoir
        Reservoir_ClampPrevious(reservoir2);
        mergeReservoirsCone(updater, reservoir2, random, material, world, normal, view_direction, solid_angle);
    }

    if (!updater.reservoir.M)
    {
        return; // reprojection failed
    }

    // Finalize our reservoir
    reservoir = updater.reservoir;

    // And write it out to memory
    g_Reservoir_IndirectSampleReservoirBuffer[did] = packReservoir(reservoir);
}

//!
//! Glossy reflections kernels.
//!

// BE CAREFUL: pick FP16 friendly values
#define TRACE_NONE_DISTANCE -1.f
#define TRACE_SKY_DISTANCE  65519.f

void TraceReflectionsHandleHit(uint did, inout TraceReflectionsPayload payload, RayDesc ray, HitInfo hit_info, float hit_distance)
{
    float3 hit_position     = (ray.Origin + hit_distance * ray.Direction);

    uint hit_instance_index  = hit_info.instanceIndex;
    uint hit_geometry_index  = hit_info.geometryIndex;
    uint hit_primitive_index = hit_info.primitiveIndex;
    bool hit_is_front_face   = hit_info.frontFace;
    float2 hit_barycentrics  = hit_info.barycentrics;

    Instance hit_instance  = g_InstanceBuffer[hit_instance_index];
    Mesh     hit_mesh      = g_MeshBuffer[hit_instance.mesh_index + hit_geometry_index];
    float3x4 hit_transform = g_TransformBuffer[hit_instance.transform_index];
    Material hit_material  = g_MaterialBuffer[hit_instance.material_index];

    TriangleNormUV vertices2 = fetchVerticesNormUV(hit_mesh, hit_primitive_index);

    vertices2.n0 = transformNormal(vertices2.n0, hit_transform);
    vertices2.n1 = transformNormal(vertices2.n1, hit_transform);
    vertices2.n2 = transformNormal(vertices2.n2, hit_transform);

    float3 hit_normal = (hit_is_front_face ? 1.0f : -1.0f) * normalize(interpolate(vertices2.n0, vertices2.n1, vertices2.n2, hit_barycentrics));
    float2 hit_mesh_uv = interpolate(vertices2.uv0, vertices2.uv1, vertices2.uv2, hit_barycentrics);

    float3 homogeneous = transformPointProjection(hit_position, g_ViewProjection);
    float2 uv          = 0.5f * float2(homogeneous.x, -homogeneous.y) + 0.5f;
    float depth        = homogeneous.z;

    // Evaluate direct illumination from area light
    if(g_UseDirectLighting != 0 && hit_is_front_face && dot(hit_material.emissivity.xyz, hit_material.emissivity.xyz) > 0.0f)
    {
        MaterialEmissive emissive = MakeMaterialEmissive(hit_material, hit_mesh_uv);
        payload.hit_distance = hit_distance;
        payload.radiance = emissive.emissive;
    }
    // Evaluate indirect illumination
    else
    {
        // Use previous frame lighting when available
        bool previous_frame_available = false;
        if (all(uv > 0.0f) && all(uv < 1.0f) && depth > 0.0f && depth < 1.0f)
        {
            float2 previous_uv = uv - g_VelocityBuffer.SampleLevel(g_NearestSampler, uv, 0.0f).xy;
            if (all(previous_uv > 0.0f) && all(previous_uv < 1.0f))
            {
                float  previous_depth  = GetLinearDepth(g_PreviousDepthBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).x);
                float3 previous_normal = normalize(2.0f * g_PreviousNormalBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).xyz - 1.0f);

                float3 homogeneous2 = transformPointProjection(float3(2.0f * float2(uv.x, 1.0f - uv.y) - 1.0f, depth), g_Reprojection);
                homogeneous2.z      = GetLinearDepth(homogeneous2.z);

                if (abs(homogeneous2.z - previous_depth) / homogeneous2.z < 1e-2f && dot(hit_normal, previous_normal) > 0.95f)
                {
                    float3 previous_lighting = g_PrevCombinedIlluminationBuffer.SampleLevel(g_NearestSampler, previous_uv, 0.0f).xyz;
                    payload.hit_distance     = hit_distance;
                    payload.radiance         = previous_lighting;
                    previous_frame_available = true;
                }
            }
        }

        // Use hash grid cache when previous frame lighting is not available
        if (!previous_frame_available)
        {
            // jitter hit position to reduce tiled artifacts
            float2 jitter = (2.0f * payload.s - 1.0f);
            jitter       *= HashGridCache_GetCellSize(hit_position);

            float3 t, b;
            GetOrthoVectors(hit_normal, t, b);

            HashGridCache_Data data;
            data.eye_position = g_Eye;
            data.hit_position = hit_position + jitter.x * t + jitter.y * b;
            data.direction    = ray.Direction;
            data.hit_distance = hit_distance;

            uint tile_index;
            uint cell_index = HashGridCache_FindCell(data, tile_index);

            if (cell_index != kGI10_InvalidId)
            {
                // Bump the cell's decay to the max. now that it's been 'touched'
                uint previous_tile_decay;
                InterlockedExchange(g_HashGridCache_DecayTileBuffer[tile_index], g_FrameIndex, previous_tile_decay);

                float4 li            = HashGridCache_FilteredRadiance(cell_index, false);
                payload.radiance     = (li.xyz / max(li.w, 1.0f));
                payload.hit_distance = hit_distance;
            }
        }
    }
}

void TraceReflectionsHandleMiss(uint did, inout TraceReflectionsPayload payload, RayDesc ray)
{
    // Evaluate direct illumination from envmap
    if (g_UseDirectLighting != 0)
    {
        payload.radiance     = g_EnvironmentBuffer.SampleLevel(g_NearestSampler, ray.Direction, 0.0f).xyz;
        payload.hit_distance = TRACE_SKY_DISTANCE;
    }
}

void TraceReflectionsTraceRayInline(uint did, inout TraceReflectionsPayload payload, RayDesc ray)
{
    ClosestRayQuery ray_query = TraceRay<ClosestRayQuery>(ray);

    if (ray_query.CommittedStatus() == COMMITTED_TRIANGLE_HIT)
    {
        TraceReflectionsHandleHit(did, payload, ray, GetHitInfoRtInlineCommitted(ray_query), ray_query.CommittedRayT());
    }
    else
    {
        TraceReflectionsHandleMiss(did, payload, ray);
    }
}

void TraceReflectionsTraceRayRt(uint did, inout TraceReflectionsPayload payload, RayDesc ray)
{
    TraceRay(g_Scene, RAY_FLAG_NONE, 0xFFu, 0, 0, 0, ray, payload);
}

void TraceReflectionsTraceRay(uint did, inout TraceReflectionsPayload payload, RayDesc ray)
{
#if USE_INLINE_RT
    return TraceReflectionsTraceRayInline(did, payload, ray);
#else
    return TraceReflectionsTraceRayRt(did, payload, ray);
#endif
}

void TraceReflections(in uint did)
{
    if (did >= g_GlossyReflections_RtSampleCountBuffer[0])
    {
        return; // out of bounds
    }

    int2   full_pos     = GlossyReflections_UnpackSample(g_GlossyReflections_RtSampleBuffer[did]);
    float3 normal       = g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel)
    {
        return; // discard sky pixels
    }

    normal = normalize(2.0f * normal - 1.0f);

    // Texture coordinates
    float4 visibility   = g_VisibilityBuffer[full_pos];
    float2 barycentrics = visibility.xy;
    uint   instanceID   = asuint(visibility.z);
    uint   primitiveID  = asuint(visibility.w);

    Instance instance = g_InstanceBuffer[instanceID];
    Mesh     mesh     = g_MeshBuffer[instance.mesh_index];

    Triangle vertices = fetchVertices(mesh, primitiveID);

    // Reconstruct world space position from barycentrics
    float3x4 transform = g_TransformBuffer[instance.transform_index];
    vertices.v0 = transformPoint(vertices.v0, transform) - g_PreViewTranslation;
    vertices.v1 = transformPoint(vertices.v1, transform) - g_PreViewTranslation;
    vertices.v2 = transformPoint(vertices.v2, transform) - g_PreViewTranslation;

    // Frame
    float2 uv    = (full_pos + 0.5f) / g_BufferDimensions;
    float  depth = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 world = interpolate(vertices.v0, vertices.v1, vertices.v2, barycentrics);

    // Robust ray origin offset
    float3 origin         = offsetPosition(world + g_PreViewTranslation, normal);
    float3 view_direction = normalize(g_Eye - origin);
    float3 detail_normal  = normalize(2.0f * g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.0f);

    float  roughness = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    // do not use the same seed value with stochastic alpha testing
    float2 s = BlueNoise_Sample2D(full_pos, g_FrameIndex, 2);

    // Sample specular direction
    Quaternion localRotation = QuaternionRotationZ(detail_normal);
    float3 localView = localRotation.transform(view_direction);
    float roughnessAlpha = max(0.000001f, squared(roughness));
    float3 newLight = sampleGGX(roughnessAlpha, localView, s);
    float3 direction = normalize(localRotation.inverse().transform(newLight));

    // Get sampled direction PDF
    float roughnessAlphaSqr = max(0.000001f, squared(roughnessAlpha));
    float3 halfVector = normalize(localView + newLight);
    float dotNH = clamp(halfVector.z, -1.0f,1.0f);
    float dotNV = clamp(localView.z, -1.0f,1.0f);
    float specular_pdf = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

    RayDesc ray_desc;
    ray_desc.Origin    = origin;
    ray_desc.Direction = direction;
    ray_desc.TMin      = 0.0f;
    ray_desc.TMax      = MAX_HIT_DISTANCE;

    TraceReflectionsPayload payload;
    payload.full_pos     = full_pos;
    payload.radiance     = 0.f;
    payload.s            = s;
    payload.hit_distance = TRACE_NONE_DISTANCE;

    TraceReflectionsTraceRay(did, payload, ray_desc);

    payload.radiance /= (1.0f + payload.radiance);

    int2 half_pos = GlossyReflections_FullToHalfRes(full_pos);
    g_GlossyReflections_SpecularBuffer[half_pos]  = float4(payload.radiance, payload.hit_distance);
    g_GlossyReflections_DirectionBuffer[half_pos] = payload.hit_distance > 0.f && payload.hit_distance < 100.f
                                                    ? float4(world + payload.hit_distance * direction - g_Eye, 1.f)
                                                    : float4(direction, 0.f);
}

[numthreads(64, 1, 1)]
void TraceReflectionsMain(in uint did : SV_DispatchThreadID)
{
    TraceReflections(did);
}

float RatioEstimator_GaussianFilter(in float x, in float radius)
{
    float sigma = 0.375f * radius;
    return /*(radius / (sqrt(2.f * PI) * sigma)) */ exp(-(x * x) / (2.f * sigma * sigma));
}

[numthreads(8, 8, 1)]
void ResolveReflections_SplitRatioEstimatorX(in int2 did : SV_DispatchThreadID)
{
    int2   split_pos = did;
    if (any(split_pos >= GlossyReflections_SplitRes()))
    {
        return; // out of bounds
    }

    int2   full_pos     = GlossyReflections_SplitToFullRes(split_pos);
    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    normal = normalize(2.0f * normal - 1.0f);

    float2 uv             = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth   = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 center_world   = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal  = normalize(2.f * g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.f);
    float  center_view_depth = GetLinearDepth(center_depth);
    float3 view_direction = normalize(g_Eye - center_world);
    Quaternion localRotation = QuaternionRotationZ(normal);
    float3 localView = localRotation.transform(view_direction);

    float4 reflection_x                             = 0.f;
    float3 reflection_average_squared_x             = 0.f;
    float  reflection_weight_x                      = 0.f;

    // Micro-facet alpha is equal to roughness^2
    float roughnessAlpha = roughness * roughness;
    roughnessAlpha = max(0.000001f, roughnessAlpha); // fix for GGX not being able to handle 0 roughness
    float roughnessAlphaSqr = max(0.000001f, roughnessAlpha * roughnessAlpha);

    int2 half_pos    = GlossyReflections_FullToHalfRes(full_pos);
    int  full_radius = GlossyReflections_FullRadius();            // Default was 7
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);

    for (int half_offset_x = -half_radius; half_offset_x <= +half_radius; half_offset_x += 1)
    {
        int2 half_sample_pos = half_pos + int2(half_offset_x, 0);
        int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
        if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()) ||
            g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x > g_GlossyReflectionsConstants.high_roughness_threshold)
        {
            continue;   // out of bounds
        }

        // Compute pdf for reused sample (don't evaluate GGX)
        float4 light_direction_or_hit_position = g_GlossyReflections_DirectionBuffer[half_sample_pos];
        float3 light_direction                 = light_direction_or_hit_position.w > 0.5f ? normalize(light_direction_or_hit_position.xyz + g_Eye - center_world) : light_direction_or_hit_position.xyz;
        float3 halfVector                      = normalize(view_direction + light_direction.xyz);
        float  dotNH                           = clamp(dot(normal, halfVector), -1.0f, 1.0f); // Maybe we can remove this clamping.
        float  dotNV                           = clamp(dot(normal, view_direction), -1.0f, 1.0f); // Maybe we can remove this clamping.
        float  pdf_weight                      = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

        // Plane weight
        float  sample_depth = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
        float2 sample_uv    = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
        float3 sample_world = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
        float  plane_weight = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

        // Gaussian
        int2   filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
        float  filter_weight = RatioEstimator_GaussianFilter(filter_pos.x, full_radius);

        // Filter
        // BE CAREFUL: adding the ratio estimator in the neighborhood helps with ghosting but reduce stability...
        float4 radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_sample_pos];
        float  weight                    = filter_weight * plane_weight * pdf_weight;
        reflection_x                    += radiance_and_hit_distance * weight;
        reflection_average_squared_x    += radiance_and_hit_distance.xyz * radiance_and_hit_distance.xyz * weight;
        reflection_weight_x             += weight;
    }

    // BE CAREFUL: we reuse a discarded sample (plane_weight near 0 on edges with upsampling)
    // when no sample were used for removing black pixels at grazing angles on object borders...
    if (reflection_weight_x < 1e-3f)
    {
        for (int half_offset_x = -1; half_offset_x <= +1; half_offset_x += 1)
        {
            int2 half_sample_pos = half_pos + int2(half_offset_x, 0);
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()) ||
                g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                continue;   // out of bounds
            }

            // Filter
            float4 radiance_and_hit_distance          = g_GlossyReflections_SpecularBuffer[half_sample_pos];
            float  weight                             = 1.f;
            reflection_x                             += radiance_and_hit_distance * weight;
            reflection_average_squared_x             += radiance_and_hit_distance.xyz * radiance_and_hit_distance.xyz * weight;
            reflection_weight_x                      += weight;
        }
    }

    if (reflection_weight_x > 0.f)
    {
        reflection_x                 /= reflection_weight_x;
        reflection_average_squared_x /= reflection_weight_x;
    }

    g_GlossyReflections_ReflectionsBufferX[split_pos]    = reflection_x;
    g_GlossyReflections_AverageSquaredBufferX[split_pos] = float4(sqrt(reflection_average_squared_x), 1.f);
}

[numthreads(8, 8, 1)]
void ResolveReflections_SplitRatioEstimatorY(in uint2 did : SV_DispatchThreadID)
{
    int2   full_pos = did;
    if (any(full_pos >= GlossyReflections_FullRes()))
    {
        return; // out of bounds
    }

    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);
    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    normal = normalize(2.0f * normal - 1.0f);

    float2 uv             = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth   = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 center_world   = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal  = normalize(2.f * g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.f);
    float  center_view_depth = GetLinearDepth(center_depth);
    float3 view_direction = normalize(g_Eye - center_world);
    Quaternion localRotation = QuaternionRotationZ(normal);
    float3 localView = localRotation.transform(view_direction);

    float4 reflection                             = 0.f;
    float3 reflection_average_squared             = 0.f;
    float  reflection_weight                      = 0.f;

    // Micro-facet alpha is equal to roughness^2
    float roughnessAlpha = roughness * roughness;
    roughnessAlpha = max(0.000001f, roughnessAlpha); // fix for GGX not being able to handle 0 roughness
    float roughnessAlphaSqr = max(0.000001f, roughnessAlpha * roughnessAlpha);

    int2 half_pos    = GlossyReflections_FullToHalfRes(full_pos);
    int  full_radius = GlossyReflections_FullRadius();            // Default was 7
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);
    // BE CAREFUL: needed for filtering out stripes with temporal accumulation (overblur for near mirror surfaces)
    int2 half_jitter = floor((BlueNoise_Sample2D(full_pos, g_FrameIndex) - 0.5f) * 2 + 0.5f);
    for (int half_offset_y = -half_radius; half_offset_y <= +half_radius; half_offset_y += 1)
    {
        int2 half_sample_pos  = half_pos + int2(half_jitter.x, half_offset_y);
        int2 full_sample_pos  = GlossyReflections_HalfToFullRes(half_sample_pos);
        if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()) ||
            g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x > g_GlossyReflectionsConstants.high_roughness_threshold)
        {
            continue;   // out of bounds
        }

        // Compute pdf for reused sample (don't evaluate GGX)
        float4 light_direction_or_hit_position = g_GlossyReflections_DirectionBuffer[half_sample_pos];
        float3 light_direction                 = light_direction_or_hit_position.w > 0.5f ? normalize(light_direction_or_hit_position.xyz + g_Eye - center_world) : light_direction_or_hit_position.xyz;
        float3 halfVector                      = normalize(view_direction + light_direction.xyz);
        float  dotNH                           = clamp(dot(normal, halfVector), -1.0f, 1.0f); // Maybe we can remove this clamping.
        float  dotNV                           = clamp(dot(normal, view_direction), -1.0f, 1.0f); // Maybe we can remove this clamping.
        float  pdf_weight                      = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

        // Plane weight
        float  sample_depth = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
        float2 sample_uv    = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
        float3 sample_world = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
        float  plane_weight = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

        // Gaussian
        int2   filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
        float  filter_weight = RatioEstimator_GaussianFilter(filter_pos.y, full_radius);

        // Filter
        // BE CAREFUL: adding the ratio estimator in the neighborhood helps with ghosting but reduce stability...
        int2   split_sample_pos              = int2(full_sample_pos.x, half_sample_pos.y);
        float4 reflection_x                  = g_GlossyReflections_ReflectionsBufferX[split_sample_pos];
        float  weight                        = filter_weight * plane_weight * pdf_weight;
        float3 reflection_average_squared_x  = pow(g_GlossyReflections_AverageSquaredBufferX[split_sample_pos].xyz, 2.f);
        reflection                          += reflection_x * weight;
        reflection_average_squared          += reflection_average_squared_x * weight;
        reflection_weight                   += weight;
    }

    // BE CAREFUL: we reuse discarded samples (plane_weight near 0 on edges with upsampling)
    // when no sample were used for removing black pixels at grazing angles on object borders...
    if (reflection_weight < 1e-3f)
    {
        for (int half_offset_y = -1; half_offset_y <= +1; half_offset_y += 1)
        {
            int2 half_sample_pos  = half_pos + int2(0, half_offset_y);
            int2 full_sample_pos  = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()) ||
                g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                continue;   // out of bounds
            }

            // Filter
            int2   split_sample_pos             = int2(full_sample_pos.x, half_sample_pos.y);
            float4 reflection_x                 = g_GlossyReflections_ReflectionsBufferX[split_sample_pos];
            float3 reflection_average_squared_x = pow(g_GlossyReflections_AverageSquaredBufferX[split_sample_pos].xyz, 2.f);
            float  weight                       = 1.f;
            reflection                         += reflection_x * weight;
            reflection_average_squared         += reflection_average_squared_x * weight;
            reflection_weight                  += weight;
        }
    }

    if (reflection_weight > 0.f)
    {
        reflection                 /= reflection_weight;
        reflection_average_squared /= reflection_weight;
    }

    float3 reflection_average = reflection.xyz;
    float3 reflection_std     = sqrt(max(abs(reflection_average_squared - reflection_average * reflection_average), 0));

    reflection.xyz         /= max(1.0f - reflection.xyz, 1e-3f);
    reflection_std.xyz     /= max(1.0f - reflection_std.xyz, 1e-3f);

    g_GlossyReflections_ReflectionsBuffer[full_pos] = reflection;
    g_GlossyReflections_StandardDevBuffer[full_pos] = float4(reflection_std, 1.f);
}

[numthreads(8, 8, 1)]
void ReprojectReflections(in uint2 did : SV_DispatchThreadID)
{
    uint2 full_pos = did;
    if (any(full_pos >= GlossyReflections_FullRes()))
    {
        return; // out of bounds
    }

    float4 color_and_hit_distance = g_GlossyReflections_ReflectionsBuffer[full_pos];
    float3 color                  = color_and_hit_distance.rgb;
    float  hit_distance           = color_and_hit_distance.a;

    float4 lighting           = float4(0.0f, 0.0f, 0.0f, 0.0f);
    float  alpha_blend        = 1.0f;
    float  parallax_threshold = 0.0f;

    float2 uv                   = (full_pos + 0.5f) / g_BufferDimensions;
    float3 normal               = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness            = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel         = (dot(normal, normal) == 0.0f ? true : false);
           normal               = 2.0f * normal - 1.0f;

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        g_GlossyReflections_ReflectionsBuffer[full_pos] = float4(color, 1.f);
        return; // pixel was already updated
    }

    {
        float  depth        = g_DepthBuffer.Load(int3(full_pos, 0)).x;
        float  linear_depth = GetLinearDepth(depth);
        float3 world        = InverseProject(g_GI10Constants.view_proj_inv, uv, depth);
        float3 ray_dir      = world - g_Eye;

        // We start out with reconstructing the ray length
        // This includes the portion from the camera to the reflecting surface as well as the portion from the surface to the hit position
        float  surface_depth = length(ray_dir);
        float  ray_length    = surface_depth + hit_distance;

        // We then perform a parallax correction by shooting a ray of the same length "straight through" the reflecting surface
        // and reprojecting the tip of that ray to the previous frame
        float3 world_hit_position = g_Eye + (ray_dir / surface_depth) * ray_length;

        // Previous hit
        float4 previous_hit_pos         = mul(g_PreviousViewProjection, float4(world_hit_position, 1.0));
        float2 previous_hit_uv          = float2(0.5f, -0.5f) * (previous_hit_pos.xy / previous_hit_pos.w) + 0.5f;
        float3 previous_hit_normal      = g_PreviousDetailsBuffer.SampleLevel(g_TextureSampler, previous_hit_uv, 0.0f).xyz;
               previous_hit_normal      = 2.f * previous_hit_normal - 1.f;

        float4 previous_hit_depths        = g_PreviousDepthBuffer.Gather(g_TextureSampler, previous_hit_uv);   // (-,+),(+,+),(+,-),(-,-)
        float4 previous_hit_linear_depths = GetLinearDepth(previous_hit_depths);
        float4 previous_hit_dissoclusions = exp(-abs(1.f - max(0.f, dot(normal, previous_hit_normal))) * 1.4f) *
                                            exp(-abs(previous_hit_linear_depths - linear_depth.xxxx) / linear_depth.xxxx * 1.0f);

        float4 previous_hit_color_and_count = 0;
        if (all(previous_hit_dissoclusions > 0.9))
        {
            previous_hit_color_and_count = g_PreviousReflectionBuffer.SampleLevel(g_TextureSampler, previous_hit_uv, 0.0f);
        }
        else if (any(previous_hit_dissoclusions > 0.9f))
        {
            int   max_index = 0;
            float max_dissoclusion = previous_hit_dissoclusions[max_index];
            for (int i = 1; i < 4; ++i)
            {
                if (previous_hit_dissoclusions[i] > max_dissoclusion)
                {
                    max_index = i;
                    max_dissoclusion = previous_hit_dissoclusions[max_index];
                }
            }

            int2 offsets[] = {
                {0, 1},
                {1, 1},
                {1, 0},
                {0, 0}
            };

            int2 previous_hit_px = int2(previous_hit_uv * g_BufferDimensions) + offsets[max_index];
            previous_hit_color_and_count   = g_PreviousReflectionBuffer.Load(int3(previous_hit_px, 0));
        }

        float3 previous_hit_color = previous_hit_color_and_count.xyz / max(previous_hit_color_and_count.w, 1.f);
        float  previous_hit_count = previous_hit_color_and_count.w;

        // Previous
        float2 velocity                 = g_VelocityBuffer.SampleLevel(g_NearestSampler, uv, 0.0f).xy;
        float2 previous_uv              = (uv - velocity);
        float3 previous_normal          = g_PreviousDetailsBuffer.SampleLevel(g_TextureSampler, previous_uv, 0.0f).xyz;
               previous_normal          = 2.f * previous_normal - 1.f;

        float4 previous_depths        = g_PreviousDepthBuffer.Gather(g_TextureSampler, previous_uv);   // (-,+),(+,+),(+,-),(-,-)
        float4 previous_linear_depths = GetLinearDepth(previous_depths);
        float4 previous_dissoclusions = exp(-abs(1.f - max(0.f, dot(normal, previous_normal))) * 1.4f) *
                                        exp(-abs(previous_linear_depths - linear_depth.xxxx) / linear_depth.xxxx * 1.0f);

        float4 previous_color_and_count = 0;
        if (all(previous_dissoclusions > 0.9))
        {
            previous_color_and_count = g_PreviousReflectionBuffer.SampleLevel(g_TextureSampler, previous_uv, 0.0f);
        }
        else if (any(previous_dissoclusions > 0.9f))
        {
            int   max_index = 0;
            float max_dissoclusion = previous_dissoclusions[max_index];
            for (int i = 1; i < 4; ++i)
            {
                if (previous_dissoclusions[i] > max_dissoclusion)
                {
                    max_index = i;
                    max_dissoclusion = previous_dissoclusions[max_index];
                }
            }

            int2 offsets[] = {
                {0, 1},
                {1, 1},
                {1, 0},
                {0, 0}
            };

            int2 previous_px = int2(previous_uv * g_BufferDimensions) + offsets[max_index];
            previous_color_and_count   = g_PreviousReflectionBuffer.Load(int3(previous_px, 0));
        }

        float3 previous_color = previous_color_and_count.xyz / max(previous_color_and_count.w, 1.f);
        float  previous_count = previous_color_and_count.w;

        // Local neighborhood
        float3 neighborhood_average   = color;
        float3 neighborhood_std       = g_GlossyReflections_StandardDevBuffer[full_pos].xyz;

        // BE CAREFUL: depending on noise amount, this can create large blocky or boily artifacts (depends on ratio estimator filter)
        float  neighborhood_std_scale = 1.f;    // 2.f == 75%, 3.f == 89%, 4.f == 94%
        float3 neighborhood_min       = neighborhood_average - neighborhood_std_scale * neighborhood_std;
        float3 neighborhood_max       = neighborhood_average + neighborhood_std_scale * neighborhood_std;

        // Dual source blending
        // BE CAREFUL: this logic breaks if neighborhood_average isn't stable enough (too much input noise)
        float  luminance_diff_scale = -1e2f * exp2(g_Exposure); // BE CAREFUL: depends on Median heavily
        float  previous_hit_weight  = (previous_hit_count > 0.f ? 1.f : 0.f) * saturate(exp2(luminance_diff_scale * luminance(previous_hit_color - neighborhood_average)));
        float  previous_weight      = (previous_count     > 0.f ? 1.f : 0.f) * saturate(exp2(luminance_diff_scale * luminance(previous_color     - neighborhood_average)));
        float  dual_weight          = max(previous_hit_weight + previous_weight, 1e-7f);
        float3 dual_color           = (previous_hit_weight * clamp(previous_hit_color, neighborhood_min, neighborhood_max) +
                                       previous_weight     * clamp(previous_color, neighborhood_min, neighborhood_max)) / dual_weight;
        float  dual_count           = (previous_hit_weight * previous_hit_count + previous_weight * previous_count) / dual_weight;

        lighting = float4(dual_color * dual_count, dual_count);
    }

    lighting += float4(color, 1.f);

    float2 vignette_uv      = uv * (1.0f - uv.yx);
    float  vignette         = pow(15.0f * vignette_uv.x * vignette_uv.y, 0.25f);
    float  max_sample_count = max(8.0f * vignette, 1.0f);

    if (lighting.w > max_sample_count)  // evict old samples from the history
    {
        lighting *= (max_sample_count / lighting.w);
    }

    g_ReflectionBuffer[did] = float4(GIDenoiser_RemoveNaNs(lighting.xyz), lighting.w);  // Don't propagate NaNs
}

float AtrousRatioEstimator_GaussianFilter(float x, float step)
{
    float sigma = 1.065f * step;    // 1.f, 2.f, 4.f, 8.f...
    return (step / (sqrt(2.f * PI) * sigma)) * exp(-(x * x) / (2.f * sigma * sigma));
}

[numthreads(8, 8, 1)]
void ResolveReflections_AtrousRatioEstimator_First(in uint2 did : SV_DispatchThreadID)
{
    int2   half_pos = did;
    if (any(half_pos >= GlossyReflections_HalfRes()))
    {
        return; // out of bounds
    }

    int2   full_pos     = GlossyReflections_HalfToFullRes(half_pos);
    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    normal = normalize(2.0f * normal - 1.0f);

    float2 uv             = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth   = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 center_world   = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal  = normalize(2.f * g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.f);
    float  center_view_depth = GetLinearDepth(center_depth);
    float3 view_direction = normalize(g_Eye - center_world);
    Quaternion localRotation = QuaternionRotationZ(normal);
    float3 localView = localRotation.transform(view_direction);

    float4 reflection_0                 = 0.f;
    float3 reflection_average_squared_0 = 0.f;
    float  reflection_weight_0          = 0.f;

    // Micro-facet alpha is equal to roughness^2
    float roughnessAlpha = roughness * roughness;
    roughnessAlpha = max(0.000001f, roughnessAlpha); // fix for GGX not being able to handle 0 roughness
    float roughnessAlphaSqr = max(0.000001f, roughnessAlpha * roughnessAlpha);

    int  full_step   = g_GlossyReflectionsAtrousConstants.full_step;
    int  full_radius = 2 * full_step;
    int  half_step   = GlossyReflections_FullToHalfRadius(full_step);
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);
    for (int half_offset_x = -half_radius; half_offset_x <= +half_radius; half_offset_x += half_step)
    {
        for (int half_offset_y = -half_radius; half_offset_y <= +half_radius; half_offset_y += half_step)
        {
            int2 half_sample_pos = half_pos + int2(half_offset_x, half_offset_y);
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()))
            {
                // BE CAREFUL: out of screen
                continue;
            }

            float sample_depth = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_depth >= 1.0)
            {
                // BE CAREFUL: we can't rely on plane_weight for sky pixels, it can create NaN values...
                continue;
            }

            float sample_roughness = g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                // BE CAREFUL: diffuse enought surfaces
                continue;
            }

            // Compute pdf for reused sample (don't evaluate GGX)
            float4 light_direction_or_hit_position = g_GlossyReflections_DirectionBuffer[half_sample_pos];
            float3 light_direction                 = light_direction_or_hit_position.w > 0.5f ? normalize(light_direction_or_hit_position.xyz + g_Eye - center_world) : light_direction_or_hit_position.xyz;
            float3 halfVector                      = normalize(view_direction + light_direction.xyz);
            float  dotNH                           = clamp(dot(normal, halfVector), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  dotNV                           = clamp(dot(normal, view_direction), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  pdf_weight                      = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

            // Plane weight
            float2 sample_uv    = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
            float3 sample_world = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
            float  plane_weight = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

            // Gaussian
            int2   filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
            float  filter_weight = AtrousRatioEstimator_GaussianFilter(filter_pos.x, full_step)
                                 * AtrousRatioEstimator_GaussianFilter(filter_pos.y, full_step);

            // Filter
            // BE CAREFUL: adding the ratio estimator in the neighborhood helps with ghosting but reduce stability...
            float4 radiance_and_hit_distance  = g_GlossyReflections_SpecularBuffer[half_sample_pos];
            float  weight                     = filter_weight * plane_weight * pdf_weight;
            reflection_0                     += radiance_and_hit_distance * weight;
            reflection_average_squared_0     += radiance_and_hit_distance.xyz * radiance_and_hit_distance.xyz * weight;
            reflection_weight_0              += weight;
        }
    }

    if (reflection_weight_0 > 1e-3f)
    {
        reflection_0                 /= reflection_weight_0;
        reflection_average_squared_0 /= reflection_weight_0;
    }

    g_GlossyReflections_ReflectionsBuffer0[half_pos]    = reflection_0;
    g_GlossyReflections_AverageSquaredBuffer0[half_pos] = float4(sqrt(reflection_average_squared_0), 1.f);
}

[numthreads(8, 8, 1)]
void ResolveReflections_AtrousRatioEstimator_Iter(in uint2 did : SV_DispatchThreadID)
{
    int2   half_pos = did;
    if (any(half_pos >= GlossyReflections_HalfRes()))
    {
        return; // out of bounds
    }

    int2   full_pos     = GlossyReflections_HalfToFullRes(half_pos);
    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    normal = normalize(2.0f * normal - 1.0f);

    float2 uv             = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth   = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 center_world   = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal  = normalize(2.f * g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.f);
    float  center_view_depth = GetLinearDepth(center_depth);
    float3 view_direction = normalize(g_Eye - center_world);
    Quaternion localRotation = QuaternionRotationZ(normal);
    float3 localView = localRotation.transform(view_direction);

    float4 reflection_1                     = 0.f;
    float3 reflection_average_1             = 0.f;
    float3 reflection_average_squared_1     = 0.f;
    float  reflection_weight_1              = 0.f;
    float  reflection_neighborhood_weight_1 = 0.f;

    // Micro-facet alpha is equal to roughness^2
    float roughnessAlpha = roughness * roughness;
    roughnessAlpha = max(0.000001f, roughnessAlpha); // fix for GGX not being able to handle 0 roughness
    float roughnessAlphaSqr = max(0.000001f, roughnessAlpha * roughnessAlpha);

    int  full_step   = g_GlossyReflectionsAtrousConstants.full_step;
    int  full_radius = 2 * full_step;
    int  half_step   = GlossyReflections_FullToHalfRadius(full_step);
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);
    for (int half_offset_x = -half_radius; half_offset_x <= +half_radius; half_offset_x += half_step)
    {
        for (int half_offset_y = -half_radius; half_offset_y <= +half_radius; half_offset_y += half_step)
        {
            int2 half_sample_pos = half_pos + int2(half_offset_x, half_offset_y);
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()))
            {
                // BE CAREFUL: out of screen
                continue;
            }

            float sample_depth = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_depth >= 1.0)
            {
                // BE CAREFUL: we can't rely on plane_weight for sky pixels, it can create NaN values...
                continue;
            }

            float sample_roughness = g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                // BE CAREFUL: diffuse enought surfaces
                continue;
            }

            // Compute pdf for reused sample (don't evaluate GGX)
            float4 light_direction_or_hit_position = g_GlossyReflections_DirectionBuffer[half_sample_pos];
            float3 light_direction                 = light_direction_or_hit_position.w > 0.5f ? normalize(light_direction_or_hit_position.xyz + g_Eye - center_world) : light_direction_or_hit_position.xyz;
            float3 halfVector                      = normalize(view_direction + light_direction.xyz);
            float  dotNH                           = clamp(dot(normal, halfVector), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  dotNV                           = clamp(dot(normal, view_direction), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  pdf_weight                      = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

            // Plane weight
            float2 sample_uv    = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
            float3 sample_world = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
            float  plane_weight = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

            // Gaussian
            int2   filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
            float  filter_weight = AtrousRatioEstimator_GaussianFilter(filter_pos.x, full_step)
                                 * AtrousRatioEstimator_GaussianFilter(filter_pos.y, full_step);

            // Filter
            // BE CAREFUL: adding the ratio estimator in the neighborhood helps with ghosting but reduce stability...
            float4 reflection_0                 = g_GlossyReflections_ReflectionsBuffer0[half_sample_pos];
            float3 reflection_average_squared_0 = pow(g_GlossyReflections_AverageSquaredBuffer0[half_sample_pos].xyz, 2.f);
            float  weight                       = filter_weight * plane_weight * pdf_weight;
            reflection_1                       += reflection_0 * weight;
            reflection_average_squared_1       += reflection_average_squared_0 * weight;
            reflection_weight_1                += weight;
        }
    }

    if (reflection_weight_1 > 1e-3f)
    {
        reflection_1                 /= reflection_weight_1;
        reflection_average_squared_1 /= reflection_weight_1;
    }

    g_GlossyReflections_ReflectionsBuffer1[half_pos]    = reflection_1;
    g_GlossyReflections_AverageSquaredBuffer1[half_pos] = float4(sqrt(reflection_average_squared_1), 1.f);
}

[numthreads(8, 8, 1)]
void ResolveReflections_AtrousRatioEstimator_Last(in uint2 did : SV_DispatchThreadID)
{
    int2   full_pos = did;
    if (any(full_pos >= GlossyReflections_FullRes()))
    {
        return; // out of bounds
    }

    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    normal = normalize(2.0f * normal - 1.0f);

    float2 uv             = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth   = g_DepthBuffer.Load(int3(full_pos, 0)).x;
    float3 center_world   = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal  = normalize(2.f * g_GeometryNormalBuffer.Load(int3(full_pos, 0)).xyz - 1.f);
    float  center_view_depth = GetLinearDepth(center_depth);
    float3 view_direction = normalize(g_Eye - center_world);
    Quaternion localRotation = QuaternionRotationZ(normal);
    float3 localView = localRotation.transform(view_direction);

    float4 reflection                 = 0.f;
    float3 reflection_average_squared = 0.f;
    float  reflection_weight          = 0.f;

    // Micro-facet alpha is equal to roughness^2
    float roughnessAlpha = roughness * roughness;
    roughnessAlpha = max(0.000001f, roughnessAlpha); // fix for GGX not being able to handle 0 roughness
    float roughnessAlphaSqr = max(0.000001f, roughnessAlpha * roughnessAlpha);

    int  full_step   = g_GlossyReflectionsAtrousConstants.full_step;
    int  full_radius = 2 * full_step;
    int2 half_pos    = GlossyReflections_FullToHalfRes(full_pos);
    int  half_step   = GlossyReflections_FullToHalfRadius(full_step);
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);

    // Roughness
    float  roughness_average         = 0.f;
    float  roughness_average_squared = 0.f;
    float  roughness_weight          = 0.f;

    for (int full_offset_x = -4; full_offset_x <= +4; full_offset_x += 2)
    {
        for (int full_offset_y = -4; full_offset_y <= +4; full_offset_y += 2)
        {
            int2 full_sample_pos = full_pos + int2(full_offset_x, full_offset_y);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()))
                continue;

            float roughness = g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x;

            roughness_average         += roughness;
            roughness_average_squared += roughness * roughness;
            roughness_weight          += 1.f;
        }
    }

    if (roughness_weight > 1e-3f)
    {
        roughness_average         /= roughness_weight;
        roughness_average_squared /= roughness_weight;
    }

    float roughness_std = sqrt(max(abs(roughness_average_squared - roughness_average * roughness_average), 0.f));

    // BE CAREFUL: half_step needed for filtering out patterns when roughness is varying with temporal accumulation
    float jitter_scale = clamp((4.0 * roughness_std) / roughness_average, 0.f, 1.f);
    int2  half_jitter  = floor((BlueNoise_Sample2D(full_pos, g_FrameIndex) - 0.5f) * lerp(0.f, half_step, jitter_scale) + 0.5f);

    for (int half_offset_x = -half_radius; half_offset_x <= +half_radius; half_offset_x += half_step)
    {
        for (int half_offset_y = -half_radius; half_offset_y <= +half_radius; half_offset_y += half_step)
        {
            int2 half_sample_pos = half_pos + int2(half_offset_x, half_offset_y) + half_jitter;
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()))
            {
                // BE CAREFUL: out of screen
                continue;
            }

            float sample_depth = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_depth >= 1.0)
            {
                // BE CAREFUL: we can't rely on plane_weight for sky pixels, it can create NaN values...
                continue;
            }

            float sample_roughness = g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x;
            if (sample_roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                // BE CAREFUL: diffuse enought surfaces
                continue;
            }

            // Compute pdf for reused sample (don't evaluate GGX)
            float4 light_direction_or_hit_position = g_GlossyReflections_DirectionBuffer[half_sample_pos];
            float3 light_direction                 = light_direction_or_hit_position.w > 0.5f ? normalize(light_direction_or_hit_position.xyz + g_Eye - center_world) : light_direction_or_hit_position.xyz;
            float3 halfVector                      = normalize(view_direction + light_direction.xyz);
            float  dotNH                           = clamp(dot(normal, halfVector), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  dotNV                           = clamp(dot(normal, view_direction), -1.0f, 1.0f); // Maybe we can remove this clamping.
            float  pdf_weight                      = sampleGGXPDF(roughnessAlphaSqr, dotNH, dotNV, localView);

            // Plane weight
            float2 sample_uv    = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
            float3 sample_world = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
            float  plane_weight = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

            // Gaussian
            int2   filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
            float  filter_weight = AtrousRatioEstimator_GaussianFilter(filter_pos.x, full_step)
                                 * AtrousRatioEstimator_GaussianFilter(filter_pos.y, full_step);

            // Filter
            // BE CAREFUL: adding the ratio estimator in the neighborhood helps with ghosting but reduce stability...
            float4 reflection_1                 = g_GlossyReflections_ReflectionsBuffer1[half_sample_pos];
            float3 reflection_average_squared_1 = pow(g_GlossyReflections_AverageSquaredBuffer1[half_sample_pos].xyz, 2.f);
            float  weight                       = filter_weight * plane_weight * pdf_weight;
            reflection                         += reflection_1 * weight;
            reflection_average_squared         += reflection_average_squared_1 * weight;
            reflection_weight                  += weight;
        }
    }

    if (reflection_weight > 0.f)
    {
        reflection                 /= reflection_weight;
        reflection_average_squared /= reflection_weight;
    }

    float3 reflection_average = reflection.xyz;
    float3 reflection_std     = sqrt(max(abs(reflection_average_squared - reflection_average * reflection_average), 0));

    reflection.xyz /= max(1.0f - reflection.xyz, 1e-3f);
    reflection_std /= max(1.0f - reflection_std, 1e-3f);

    g_GlossyReflections_ReflectionsBuffer[full_pos] = reflection;
    g_GlossyReflections_StandardDevBuffer[full_pos] = float4(reflection_std, 1.f);
}

float MarkFireflies_BoxFilter(in int pos, in int radius)
{
    return abs(pos) <= radius ? 1.f : 0.f;
}

[numthreads(8, 8, 1)]
void MarkFireflies(in uint2 did : SV_DispatchThreadID)
{
    int2   half_pos = did;
    if (any(half_pos >= GlossyReflections_HalfRes()))
    {
        return; // out of bounds
    }

    int2   full_pos     = GlossyReflections_HalfToFullRes(half_pos);
    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    float4 radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_pos];
    if (radiance_and_hit_distance.w < 0.f)
    {
        // TRACE_SKY_DISTANCE or TRACE_NONE_DISTANCE
        g_GlossyReflections_FirefliesBuffer[half_pos] = 1.f;
        return;
    }

    float center_luminance = luminance(radiance_and_hit_distance.xyz);
    float luminance_lower  = 0.f;
    float luminance_higher = 0.f;

    int  full_radius = GlossyReflections_MarkFireflies_FullRadius();        // Default was 3
    int  half_radius = GlossyReflections_FullToHalfRadius(full_radius);
    for (int half_offset_x = -half_radius; half_offset_x <= +half_radius; half_offset_x += 1)
    {
        for (int half_offset_y = -half_radius; half_offset_y <= +half_radius; half_offset_y += 1)
        {
            if (half_offset_x == 0 && half_offset_y == 0)
                continue;

            int2 half_sample_pos = int2(half_pos) + int2(half_offset_x, half_offset_y);
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);
            if (any(full_sample_pos < 0) || any(full_sample_pos >= GlossyReflections_FullRes()) ||
                g_RoughnessBuffer.Load(int3(full_sample_pos, 0)).x > g_GlossyReflectionsConstants.high_roughness_threshold)
            {
                continue;   // out of bounds
            }

            float4 sample_radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_sample_pos];
            float  sample_luminance                 = luminance(sample_radiance_and_hit_distance.xyz);

            int2  filter_pos    = GlossyReflections_HalfToFullRes(half_sample_pos) - full_pos;
            float sample_weight = MarkFireflies_BoxFilter(filter_pos.x, full_radius)
                                * MarkFireflies_BoxFilter(filter_pos.y, full_radius);

            if (sample_luminance < center_luminance)
                luminance_higher += sample_weight;          // BE CAREFUL: we count when center_luminance is higher
            else if (sample_luminance > center_luminance)
                luminance_lower += sample_weight;           // BE CAREFUL: we count when center_luminance is lower
        }
    }

    float luminance_weight = luminance_lower + luminance_higher;

    g_GlossyReflections_FirefliesBuffer[half_pos] =
        luminance_lower  < GlossyReflections_MarkFireflies_LowThreshold()  * luminance_weight ||       // BE CAREFUL: these thresholds depends on radius
        luminance_higher > GlossyReflections_MarkFireflies_HighThreshold() * luminance_weight ?
        1.f : 0.f;
}

float CleanupFireflies_NeighborhoodFilter(in float i, in float radius)
{
    const float k = 1.f;                // BE CAREFUL: somehow truncated gaussian, k depends on radius...
    return exp(-k * (i * i) / pow(radius + 1.0f, 2.0f));
}

[numthreads(8, 8, 1)]
void CleanupFireflies(in uint2 did : SV_DispatchThreadID)
{
    int2   half_pos = did;
    if (any(half_pos >= GlossyReflections_HalfRes()))
    {
        return; // out of bounds
    }

    // Mark weight
    float mark_weight = g_GlossyReflections_FirefliesBuffer[did];
    if (mark_weight < 0.5f)
    {
        return;
    }

    int2   full_pos          = GlossyReflections_HalfToFullRes(half_pos);
    float2 uv                = (full_pos + 0.5f) / GlossyReflections_FullRes();
    float  center_depth      = g_DepthBuffer[full_pos].x;
    float3 center_world      = InverseProject(g_GI10Constants.view_proj_inv, uv, center_depth);
    float3 center_normal     = normalize(2.f * g_GeometryNormalBuffer[full_pos].xyz - 1.f);       // BE CAREFUL: no normal maps
    float  center_view_depth = GetLinearDepth(center_depth);

    float4 specular                = 0.f;
    float  specular_weight         = 0.f;

    int  full_radius = GlossyReflections_CleanupFireflies_FullRadius();    // Default was 1
    for (int offset_x = -full_radius; offset_x <= +full_radius; offset_x += 1)
    {
        for (int offset_y = -full_radius; offset_y <= +full_radius; offset_y += 1)
        {
            int2 half_sample_pos = int2(half_pos) + int2(offset_x, offset_y);
            int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);

            // Mark weight
            float mark_weight    = 1.f - g_GlossyReflections_FirefliesBuffer[half_sample_pos];

            // Plane weight
            float  sample_depth  = g_DepthBuffer.Load(int3(full_sample_pos, 0)).x;
            float2 sample_uv     = (full_sample_pos + 0.5f) / GlossyReflections_FullRes();
            float3 sample_world  = InverseProject(g_GI10Constants.view_proj_inv, sample_uv, sample_depth);
            float  plane_weight  = 1.f - saturate(abs(dot(center_normal, center_world - sample_world) / center_view_depth) * 200.0f - 0.0f);

            // Smooth
            float  filter_weight = CleanupFireflies_NeighborhoodFilter(offset_x, full_radius)
                                 * CleanupFireflies_NeighborhoodFilter(offset_y, full_radius);

            // Filter
            float4 radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_sample_pos];
            float  weight                    = mark_weight * plane_weight * filter_weight;
            specular                        += radiance_and_hit_distance * weight;
            specular_weight                 += weight;
        }
    }

    if (abs(specular_weight) < 1e-3f)
    {
        // BE CAREFUL: No sample could be used for cleanup, just pass through the center value
        int2 half_sample_pos = int2(half_pos);
        int2 full_sample_pos = GlossyReflections_HalfToFullRes(half_sample_pos);

        float4 radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_sample_pos];
        specular                        += radiance_and_hit_distance;
        specular_weight                 += 1.f;
    }

    if (specular_weight > 0.0f)
    {
        specular /= specular_weight;
    }

    // BE CAREFUL: we don't want to propagate rare NaNs contained by g_GlossyReflections_SpecularBuffer
    g_GlossyReflections_SpecularBuffer[half_pos] = GIDenoiser_RemoveNaNs(specular);
}

[numthreads(8, 8, 1)]
void NoDenoiserReflections(in uint2 did : SV_DispatchThreadID)
{
    uint2 full_pos = did;
    if (any(full_pos >= GlossyReflections_FullRes()))
    {
        return; // out of bounds
    }

    float3 normal       = g_ShadingNormalBuffer.Load(int3(full_pos, 0)).xyz;
    float  roughness    = g_RoughnessBuffer.Load(int3(full_pos, 0)).x;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (is_sky_pixel || roughness > g_GlossyReflectionsConstants.high_roughness_threshold)
    {
        return; // pixel was already updated
    }

    int2 half_pos                    = GlossyReflections_FullToHalfRes(full_pos);
    float4 radiance_and_hit_distance = g_GlossyReflections_SpecularBuffer[half_pos];
    float3 radiance                  = radiance_and_hit_distance.xyz;
    float4 light_direction_and_pdf   = g_GlossyReflections_DirectionBuffer[half_pos];
    float  specular_pdf              = light_direction_and_pdf.w;

    radiance                    /= max(1.0f - radiance, 1e-3f);
#if 0
    // BE CAREFUL: this is needed to mimic denoiser but noise is so strong (fireflies being visible over diffuse for matte surfaces),
    //             temporal feedback just bring fireflies it into global illumination and everything is white
    radiance                    /= max(specular_pdf, 1e-3f);
#endif
    g_ReflectionBuffer[full_pos] = float4(GIDenoiser_RemoveNaNs(radiance), 1.f);        // Don't propagate NaNs
}

//!
//! GI-1.0 denoiser kernels.
//!

[numthreads(8, 8, 1)]
void ReprojectGI(in uint2 did : SV_DispatchThreadID)
{
    if (all(did == 0))
    {
        g_GIDenoiser_BlurSampleCountBuffer[0] = 0;
    }

    if (any(did >= g_BufferDimensions))
    {
        return; // out of bounds
    }

    float4 color    = g_GIDenoiser_ColorBuffer[did];
    float4 lighting = float4(0.0f, 0.0f, 0.0f, 0.0f);
    float3 normal   = g_ShadingNormalBuffer.Load(int3(did, 0)).xyz;

    float  alpha_blend  = 1.0f;
    float  color_delta  = 0.0f;
    float2 uv           = (did + 0.5f) / g_BufferDimensions;
    bool   is_sky_pixel = (dot(normal, normal) == 0.0f ? true : false);

    if (!is_sky_pixel)
    {
        float2 velocity    = g_VelocityBuffer.SampleLevel(g_NearestSampler, uv, 0.0f).xy;
        float2 previous_uv = (uv - velocity);

        float depth = g_DepthBuffer.Load(int3(did, 0)).x;
        normal = 2.0f * normal - 1.0f;

        if (all(previous_uv > 0.0f) && all(previous_uv < 1.0f))
        {
            float3 world     = InverseProject(g_GI10Constants.view_proj_inv, uv, depth);
            float  cell_size = distance(g_Eye, world) * g_ScreenProbesConstants.cell_size;

            cell_size *= lerp(1.0f, 5.0f, pow(1.0f - max(dot(normalize(g_Eye - world), normalize(normal)), 0.0f), 6.0f));

            float  weight     = 0.0f;
            float2 texel_size = 1.0f / g_BufferDimensions;

            const float kOneOverSqrtOfTwo = 0.707107f;

            for (float y = -1.0f; y <= 1.0f; ++y)
            {
                for (float x = -1.0f; x <= 1.0f; ++x)
                {
                    float2 st              = previous_uv + float2(x, y) * texel_size;
                    float4 c               = g_GIDenoiser_PreviousColorBuffer.SampleLevel(g_NearestSampler, st, 0.0f);
                    float3 previous_normal = g_PreviousDetailsBuffer.SampleLevel(g_NearestSampler, st, 0.0f).xyz;

                    if (c.w < 1.0f || dot(previous_normal, previous_normal) == 0.0f)
                    {
                        continue;   // skip invalid sample(s)
                    }

                    previous_normal = 2.0f * previous_normal - 1.0f;

                    float  previous_depth = g_PreviousDepthBuffer.SampleLevel(g_NearestSampler, st, 0.0f).x;
                    float3 previous_world = InverseProject(g_PreviousViewProjectionInverse, st, previous_depth);

                    if (distance(world, previous_world) < cell_size && dot(normal, previous_normal) > 0.95f)
                    {
                        float subpixel_dist = distance(floor(st * g_BufferDimensions) + 0.5f, previous_uv * g_BufferDimensions);
                        float w             = saturate(1.0f - subpixel_dist * kOneOverSqrtOfTwo);

                        color_delta += w * g_GIDenoiser_PreviousColorDeltaBuffer.SampleLevel(g_NearestSampler, st, 0.0f).x;
                        lighting    += w * c;
                        weight      += w;
                    }
                }
            }

            if (weight > 0.0f)
            {
                float w = sign(color_delta);
                color_delta  = GIDenoiser_RemoveNaNs(abs(color_delta) / weight);
                color_delta *= w;   // restore delta

                lighting = GIDenoiser_RemoveNaNs(lighting / weight);
            }

            if (color.w > 0.0f)
            {
                float lumaA = luminance(color.xyz);
                float lumaB = luminance(lighting.xyz / max(lighting.w, 1.0f));

                color_delta = lerp(color_delta, lumaA - lumaB, 1.0f / 8.0f);    // smoothed delta
                alpha_blend = saturate(1.0f - abs(color_delta) / max(lumaB, 1e-4f));
            }
        }
    }

    float blur_mask = (!is_sky_pixel ? max(8.0f - lighting.w, 0.0f) : -1.0f);

    if (color.w > 0.0f || lighting.w < 1.0f)    // append new sample
    {
        lighting += float4(color.xyz, color.w > 0.0f ? 1.0f : -1.0f);
    }

    float2 vignette_uv      = uv * (1.0f - uv.yx);
    float  vignette         = pow(15.0f * vignette_uv.x * vignette_uv.y, 0.25f);
    float  max_sample_count = max(lerp(4.0f, 8.0f * min(abs(lighting.w), 8.0f), alpha_blend) * vignette, 1.0f);

    if (lighting.w > max_sample_count)  // evict old samples from the history
    {
        lighting *= (max_sample_count / lighting.w);
    }

    g_GIDenoiser_BlurMask[did]         = blur_mask * kGIDenoiser_BlurMaskPack;
    g_GIDenoiser_ColorBuffer[did]      = lighting;
    g_GIDenoiser_ColorDeltaBuffer[did] = color_delta;
}

[numthreads(kGIDenoiser_BlurGroupSize, kGIDenoiser_BlurGroupSize, 1)]
void FilterBlurMask(in uint2 did : SV_DispatchThreadID, in uint2 lid : SV_GroupThreadID, in uint local_id : SV_GroupIndex, in uint2 gid : SV_GroupID)
{
    if (local_id == 0)
    {
        lds_GIDenoiser_BlurSampleCount = 0;
    }

    if (local_id < kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 4)
    {
        int2 anchor = int2(gid) * kGIDenoiser_BlurGroupSize - kGIDenoiser_BlurRadius;

        int2 coord1 = anchor + int2( local_id % kGIDenoiser_BlurTileDim,                                                               local_id / kGIDenoiser_BlurTileDim                                                             );
        int2 coord2 = anchor + int2((local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 4)     % kGIDenoiser_BlurTileDim, (local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 4)     / kGIDenoiser_BlurTileDim);
        int2 coord3 = anchor + int2((local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 2)     % kGIDenoiser_BlurTileDim, (local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 2)     / kGIDenoiser_BlurTileDim);
        int2 coord4 = anchor + int2((local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim * 3 / 4) % kGIDenoiser_BlurTileDim, (local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim * 3 / 4) / kGIDenoiser_BlurTileDim);

        float blur_mask_0 = g_GIDenoiser_BlurMask[clamp(coord1, 0, int2(g_BufferDimensions) - 1)].x * kGIDenoiser_BlurMaskUnpack;
        float blur_mask_1 = g_GIDenoiser_BlurMask[clamp(coord2, 0, int2(g_BufferDimensions) - 1)].x * kGIDenoiser_BlurMaskUnpack;
        float blur_mask_2 = g_GIDenoiser_BlurMask[clamp(coord3, 0, int2(g_BufferDimensions) - 1)].x * kGIDenoiser_BlurMaskUnpack;
        float blur_mask_3 = g_GIDenoiser_BlurMask[clamp(coord4, 0, int2(g_BufferDimensions) - 1)].x * kGIDenoiser_BlurMaskUnpack;

        lds_GIDenoiser_BlurMask[local_id]                                                             = blur_mask_0;
        lds_GIDenoiser_BlurMask[local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 4]     = blur_mask_1;
        lds_GIDenoiser_BlurMask[local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim / 2]     = blur_mask_2;
        lds_GIDenoiser_BlurMask[local_id + kGIDenoiser_BlurTileDim * kGIDenoiser_BlurTileDim * 3 / 4] = blur_mask_3;
    }
    GroupMemoryBarrierWithGroupSync();

    float2 tile_pos  = (lid + kGIDenoiser_BlurRadius + 0.5f);
    float  blur_mask = GIDenoiser_TapBlurMask(tile_pos);    // load center value

    if (blur_mask < 0.0f || any(did >= g_BufferDimensions))
    {
        blur_mask = 0.0f;   // sky pixel
    }
    else
    {
        float norm = 1.0f / sqrt(2.0f * squared(kGIDenoiser_BlurRadius));

        for (int y = -kGIDenoiser_BlurRadius; y <= kGIDenoiser_BlurRadius; ++y)
        {
            for (int x = -kGIDenoiser_BlurRadius; x <= kGIDenoiser_BlurRadius; ++x)
            {
                if(x != 0 || y != 0) // center element was already processed
                {
                    float s = GIDenoiser_TapBlurMask(tile_pos + float2(x, y));
                    float d = sqrt(float(x * x + y * y));

                    s *= saturate(1.0f - d * norm); // distance-weighted

                    blur_mask = max(blur_mask, round(s));
                }
            }
        }
    }
    InterlockedAdd(lds_GIDenoiser_BlurSampleCount, blur_mask > 0.0f ? uint(squared(2.0f * blur_mask + 1.0f)) : 0);
    GroupMemoryBarrierWithGroupSync();

    if (local_id == 0)
    {
        InterlockedAdd(g_GIDenoiser_BlurSampleCountBuffer[0], lds_GIDenoiser_BlurSampleCount);
    }

    g_GIDenoiser_BlurredBlurMask[did] = blur_mask * kGIDenoiser_BlurMaskPack;
}

[numthreads(8, 8, 1)]
void FilterGI(in uint2 did : SV_DispatchThreadID)
{
    if (any(did >= g_BufferDimensions))
    {
        return; // out of bounds
    }

    float4 lighting    = g_GIDenoiser_PreviousColorBuffer.Load(int3(did, 0));
    int    blur_radius = GIDenoiser_GetBlurRadius(did);

    if (blur_radius > 0)
    {
        float  weight = 1.0f;
        float3 color  = lighting.xyz / max(lighting.w, 1.0f);

        float  center_depth  = GetLinearDepth(g_DepthBuffer.Load(int3(did, 0)).x);
        float3 center_normal = 2.0f * g_ShadingNormalBuffer.Load(int3(did, 0)).xyz - 1.0f;

        for (int r = -blur_radius; r <= blur_radius; ++r)
        {
            int2   pos = clamp(int2(did) + r * g_BlurDirection, 0, int2(g_BufferDimensions) - 1);
            float4 c   = g_GIDenoiser_PreviousColorBuffer.Load(int3(pos, 0));

            if (c.w > 0.0f)
            {
                float  depth  = GetLinearDepth(g_DepthBuffer.Load(int3(pos, 0)).x);
                float3 normal = 2.0f * g_ShadingNormalBuffer.Load(int3(pos, 0)).xyz - 1.0f;

                float depth_diff    = 1.0f - (center_depth / depth);
                float depth_factor  = exp2(-(lighting.w > 0.0f ? 2e2f : 2e1f) * abs(depth_diff));
                float normal_factor = max(dot(normal, center_normal), 0.0f);
                normal_factor *= normal_factor; normal_factor *= normal_factor;

                float  w = depth_factor * (lighting.w > 0.0f ? normal_factor : 1.0f);

                color  += w * (c.xyz / max(c.w, 1.0f));
                weight += w;
            }
        }

        lighting.xyz = (color / weight) * max(lighting.w, 1.0f);
    }

    if (g_BlurDirection.y > 0)
    {
        g_IrradianceBuffer[did] = float4(lighting.xyz / max(lighting.w, 1.0f), 1.0f);
    }

    g_GIDenoiser_ColorBuffer[did] = lighting;
}

[numthreads(64, 1, 1)]
void ClearBucketOverflowCount(in uint did : SV_DispatchThreadID)
{
    uint bucket_index = did;
    if (bucket_index >= g_HashGridCacheConstants.num_buckets)
    {
        return;
    }

    g_HashGridCache_BucketOverflowCountBuffer[bucket_index] = 0;
}

[numthreads(64, 1, 1)]
void ClearBucketOccupancy(in uint did : SV_DispatchThreadID)
{
    uint bucket_occupancy = did;
    if (bucket_occupancy >= g_HashGridCacheConstants.debug_bucket_occupancy_histogram_size)
    {
        return;
    }

    if (did == 0)
    {
        g_HashGridCache_FreeBucketCountBuffer[0] = 0;
        g_HashGridCache_UsedBucketCountBuffer[0] = 0;
    }

    g_HashGridCache_BucketOccupancyBuffer[bucket_occupancy] = 0;
}

[numthreads(64, 1, 1)]
void ClearBucketOverflow(in uint did : SV_DispatchThreadID)
{
    uint bucket_overflow = did;
    if (bucket_overflow >= g_HashGridCacheConstants.debug_bucket_overflow_histogram_size)
    {
        return;
    }

    g_HashGridCache_BucketOverflowBuffer[bucket_overflow] = 0;
}

[numthreads(64, 1, 1)]
void BuildBucketStatistics(in uint did : SV_DispatchThreadID)
{
    uint bucket_index = did;
    if (bucket_index >= g_HashGridCacheConstants.num_buckets)
    {
        return;
    }

    uint bucket_offset;
    for (bucket_offset = 0; bucket_offset < g_HashGridCacheConstants.num_tiles_per_bucket; ++bucket_offset)
    {
        uint tile_index   = bucket_offset + bucket_index * g_HashGridCacheConstants.num_tiles_per_bucket;
        uint current_hash = g_HashGridCache_HashBuffer[tile_index];
        if (current_hash == 0)
        {
            break;  // free tile
        }
    }

    uint previous_value;
    uint bucket_occupancy = min(bucket_offset, g_HashGridCacheConstants.debug_bucket_occupancy_histogram_size - 1);
    InterlockedAdd(g_HashGridCache_BucketOccupancyBuffer[bucket_occupancy], 1, previous_value);

    uint bucket_overflow_count = min(g_HashGridCache_BucketOverflowCountBuffer[bucket_index], g_HashGridCacheConstants.debug_bucket_overflow_histogram_size - 1);
    InterlockedAdd(g_HashGridCache_BucketOverflowBuffer[bucket_overflow_count], 1, previous_value);

    if (bucket_occupancy < 1)
    {
        InterlockedAdd(g_HashGridCache_FreeBucketCountBuffer[0], 1, previous_value);
    }
    else
    {
        InterlockedAdd(g_HashGridCache_UsedBucketCountBuffer[0], 1, previous_value);
    }
}

[numthreads(64, 1, 1)]
void FormatBucketOccupancy(in uint did : SV_DispatchThreadID)
{
    uint bucket_occupancy = did;
    if (bucket_occupancy >= g_HashGridCacheConstants.debug_bucket_occupancy_histogram_size)
    {
        return;
    }

    uint stats_cursor = 0;
    if (did == 0)
    {
        g_HashGridCache_StatsBuffer[stats_cursor + 0] = float(g_HashGridCache_FreeBucketCountBuffer[0]);
        g_HashGridCache_StatsBuffer[stats_cursor + 1] = float(g_HashGridCache_UsedBucketCountBuffer[0]);
    }

    stats_cursor += 2;
    g_HashGridCache_StatsBuffer[stats_cursor + bucket_occupancy] = float(g_HashGridCache_BucketOccupancyBuffer[bucket_occupancy]);
}

[numthreads(64, 1, 1)]
void FormatBucketOverflow(in uint did : SV_DispatchThreadID)
{
    uint bucket_overflow = did;
    if (bucket_overflow >= g_HashGridCacheConstants.debug_bucket_overflow_histogram_size)
    {
        return;
    }

    uint stats_cursor = 2 + g_HashGridCacheConstants.debug_bucket_occupancy_histogram_size;
    g_HashGridCache_StatsBuffer[stats_cursor + bucket_overflow] = float(g_HashGridCache_BucketOverflowBuffer[bucket_overflow]);
}
